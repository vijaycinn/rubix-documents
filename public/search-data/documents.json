[
  {
    "slug": "/architecture",
    "title": "Architectural Analysis",
    "description": "Azure Well-Architected Framework analysis and recommendations for CJN Dakota County RMS",
    "content": "# CJN Dakota County - RMS Architecture\n\n**Date:** February 20, 2026\r\n**Customer:** CJN Dakota County (Tim Anderberg, Nathan Noll)\r\n**Project:** Records Management System (RMS) on Azure Commercial GCC\n\n***\n\n## Executive Summary\n\n### Well-Architected Framework Maturity\n\n> *Estimated maturity levels based on architectural review. We recommend completing the [Azure Well-Architected Review](https://learn.microsoft.com/assessments/?mode=pre-assessment\\&session=local) for a formal baseline.*\n\n| Pillar | Current | Target | Gap |\r\n|--------|---------|--------|-----|\r\n| **Reliability** | 6/10 | 8.5/10 | DR strategy, geo-replication, health probes |\r\n| **Security** | 7/10 | 9/10 | Managed identities, Private Link, Always Encrypted |\r\n| **Operational Excellence** | 6.5/10 | 8.5/10 | Distributed tracing, dashboards, runbooks |\r\n| **Performance Efficiency** | 6/10 | 8/10 | Caching, auto-scaling, query optimization |\r\n| **Overall** | **6.4/10** | **8.0/10** | Achievable with phased implementation |\n\n### Architecture Strengths\n\n* PaaS-first approach minimizing operational overhead\n* Event-driven architecture using Azure Service Bus with session support\n* Multi-tenant isolation through resource groups\n* Infrastructure-as-Code with Bicep\n* CJIS compliance awareness and security-first design\n* Microservices pattern with clear domain separation\n\n***\n\n## 1. System Architecture Overview\n\n<ZoomableImage src=\"/images/arch/top-down-topology.png\" alt=\"CJN Dakota RMS System Architecture\" caption=\"CJN Dakota RMS System Architecture - Top-down topology showing resource groups, services, and security zones\" />\n\n### Architecture Analysis\n\nThe system architecture diagram above illustrates the complete Azure-based Records Management System deployed in Azure Commercial GCC to meet CJIS compliance requirements. This topology represents a mature microservices architecture with clear separation of concerns across four distinct resource groups, each serving a specific domain within the RMS ecosystem.\n\n**Resource Group Separation Strategy:** The architecture implements a rigorous isolation model with dedicated resource groups for **RMS Core** (case management and core record operations), **Routing Services** (external system integration and message distribution), **Search Services** (indexing and query operations), and **Shared Infrastructure** (SQL Database, Key Vault, Service Bus Premium). This separation enables independent lifecycle management, granular RBAC assignments, and blast radius containment in the event of a security incident or operational failure.\n\n**CJIS Component Identification:** Services marked with \"- CJI\" annotations in the topology handle Criminal Justice Information and are subject to CJIS Security Policy 5.0 requirements. These include all App Services (RMS, Routing, Search), Azure Functions, SignalR Hub, Service Bus topics, and the SQL Database. The diagram clearly delineates the trust boundary—all CJI components reside within the VNet-integrated application tier or are accessed via Private Endpoints, ensuring no public internet exposure to sensitive law enforcement data.\n\n**Service Dependencies and Data Flow:** The topology visualizes the hub-and-spoke pattern where the RMS App Service acts as the primary orchestrator, coordinating with Routing and Search services through Azure API Management. All compute services maintain direct connections to Azure SQL Database for transactional consistency, while Key Vault provides centralized secrets management using Managed Identity authentication (eliminating stored credentials). The Service Bus Premium instances (Route\\_SB and Search\\_SB) enable asynchronous, event-driven communication between services, supporting session-based ordering per case or destination.\n\n**Edge Security and Gateway Layers:** User requests traverse multiple security checkpoints before reaching application services. Azure Front Door provides global DDoS protection, Web Application Firewall (WAF), and TLS 1.2 termination at the edge. Azure API Management enforces rate limiting, JWT validation, and request throttling before forwarding traffic to backend services. This defense-in-depth approach—detailed further in the **Network Topology & Security Zones** section below—ensures that even if one security layer is compromised, additional controls remain in place.\n\nFor detailed capability mapping, refer to the **Key Capabilities** table below. For technology rationale and version specifications, see the **Technology Stack** section. The network security implementation of this architecture is visualized in Section 2.\n\n**Legend:** CJI = Criminal Justice Information | Blue = Data & storage | Green = Compute | Yellow = Integration | Light Blue = Edge\n\n### Technology Stack\n\n| Layer | Technology | Purpose |\r\n|-------|------------|---------|\r\n| **Identity** | Entra ID B2B + Conditional Access | User authentication, MFA |\r\n| **Edge & CDN** | Azure Front Door | Global load balancing, DDoS protection |\r\n| **API Gateway** | Azure API Management | Rate limiting, throttling, API versioning |\r\n| **Web App** | Azure Static Web Apps | Modern SPA hosting |\r\n| **Compute** | Azure App Services + Functions | Microservices (RMS, Routing, Search) |\r\n| **Messaging** | Azure Service Bus (Premium) | Event-driven architecture, session-based messaging |\r\n| **Real-Time** | Azure SignalR Service | Live notifications and updates |\r\n| **Database** | Azure SQL Database (PaaS) | Transactional data with TDE encryption |\r\n| **Caching** | Azure Cache for Redis | Distributed cache for performance |\r\n| **Secrets** | Azure Key Vault Premium | Customer-managed keys, HSM-backed |\r\n| **Observability** | Application Insights + Azure Monitor | Distributed tracing, metrics, logs |\r\n| **Security** | Microsoft Sentinel | SIEM/SOAR for threat detection |\r\n| **Network** | Azure Virtual Network + Private Link | Network isolation, no public internet exposure |\r\n| **IaC** | Bicep + Azure DevOps | Infrastructure as code, CI/CD pipelines |\n\n### Key Capabilities\n\n| Capability | Description |\r\n|-----------|-------------|\r\n| **Secure Data Management** | CJIS-compliant encryption at rest/transit, immutable audit logs, data residency in Azure GCC |\r\n| **Real-Time Operations** | SignalR Hub + Service Bus for live officer notifications and event-driven processing |\r\n| **Enterprise Integration** | 9+ external systems (MNCIS, NIBRS, eCitations, eCharging, MNCrash, MAARC, DPS, Hennepin, LOGIS) |\r\n| **Business Continuity** | SQL geo-replication, automated backup, point-in-time restore, documented DR |\r\n| **Operational Visibility** | Distributed tracing, custom workbooks, Sentinel SIEM, proactive health monitoring |\r\n| **Performance at Scale** | Redis cache, auto-scaling, Front Door CDN, microservices independent scaling |\r\n| **AI-Ready Foundation** | CJIS/non-CJIS data segregation, anonymization pipeline, Azure AI Search readiness |\n\n***\n\n## 1.5 Resource Group Architecture\n\n<ZoomableImage src=\"/images/arch/RMS%20Resource%20Group-2026-02-23-165317.png\" alt=\"RMS Resource Group Architecture\" caption=\"Resource Group Architecture showing organizational structure and deployment dependencies\" />\n\n### Resource Organization and Deployment Strategy\n\nThe Resource Group Architecture diagram illustrates the foundational organizational structure that underpins the CJN Dakota RMS deployment, implementing Azure's resource management best practices to enable granular access control, independent lifecycle management, and comprehensive cost allocation. This architecture directly supports the **Multi-tenant isolation through resource groups** strength highlighted in Section 1's Architecture Strengths, establishing clear security boundaries that contain blast radius in the event of service compromise or operational failure.\n\n**Resource Group Separation Rationale:** The architecture implements a four-tier resource group separation strategy, with each group serving a distinct domain: **RMS-Core-RG** (case management microservices, core record operations, and primary transactional workflows), **RMS-Routing-RG** (external system integration services, message routing infrastructure, and partner API gateways), **RMS-Search-RG** (indexing services, query operations, and Azure Cognitive Search resources), and **RMS-Shared-RG** (Azure SQL Database, Azure Key Vault Premium, Service Bus Premium namespaces, and Redis Cache—shared infrastructure accessed by multiple microservices). This separation enables **independent deployment cycles**: the Search team can deploy index schema changes to RMS-Search-RG without risk of impacting core case management functionality in RMS-Core-RG. The isolation also supports **environment-specific scaling**: during peak reporting periods, operators can scale out Routing services in RMS-Routing-RG without incurring cost increases in underutilized Search services. This resource group topology aligns with Azure Landing Zone design patterns, where workload isolation prevents noisy neighbor scenarios and enables targeted disaster recovery (restore only the affected resource group during incident response).\n\n**Tag Strategy for Cost Allocation and Operational Tracking:** The diagram highlights the comprehensive tagging strategy applied to all resources within each resource group: **Environment** (Dev, Stage, Prod), **Owner** (RMS-Team, Routing-Team, Search-Team), **CostCenter** (CC-1001-RMS, CC-1002-Integration, CC-1003-Search), **Project** (CJN-Dakota-RMS), **ComplianceScope** (CJIS-CJI, CJIS-Sensitive, Non-CJIS), **DataClassification** (ConfidentialPII, Restricted, Public), and **DeploymentVersion** (infra-v2.1.0). These tags enable **Azure Cost Management chargeback reports** that break down monthly Azure spend by team, environment, and compliance scope—allowing finance to invoice departments accurately and identify cost optimization opportunities (e.g., \"Dev environment in RMS-Routing-RG consuming 30% of total budget—can we downscale non-production tiers?\"). The **ComplianceScope** tag feeds into Azure Policy compliance dashboards, validating that all resources tagged as \"CJIS-CJI\" have mandatory security controls enabled (encryption at rest, Private Link network isolation, diagnostic logging to Log Analytics). The **Owner** tag populates Azure Service Health alert routing, ensuring that when Azure announces planned maintenance for SQL Database in RMS-Shared-RG, the notification is automatically routed to the database administration team via Microsoft Teams webhook. This metadata-driven operational model reduces manual coordination overhead and ensures critical alerts reach the right stakeholders.\n\n**Resource Dependencies and Deployment Order:** The architecture diagram maps explicit dependency relationships between resource groups, establishing a deterministic deployment sequence required for Infrastructure-as-Code (IaC) orchestration. **Phase 1: Shared Infrastructure** (RMS-Shared-RG) must deploy first, provisioning the Azure SQL Database, Key Vault, Service Bus namespaces, and Virtual Network subnets that subsequent phases depend on. **Phase 2: Microservices** (RMS-Core-RG, RMS-Routing-RG, RMS-Search-RG) deploy in parallel once shared infrastructure is healthy, referencing Key Vault secrets via Managed Identity and connecting to SQL Database via Private Endpoints. Each microservice App Service retrieves its connection string from Key Vault during startup, eliminating hardcoded credentials in application configuration. This dependency model is codified in Bicep templates using the `dependsOn` keyword and enforced in Azure DevOps pipelines with sequential deployment stages (detailed in **Appendix B: CI/CD Pipeline Stages**). If a Bicep deployment to RMS-Core-RG fails due to a missing SQL Database connection string, the pipeline halts before attempting RMS-Routing-RG deployment, preventing cascade failures and simplifying rollback procedures.\n\n**RBAC Boundary Enforcement at Resource Group Level:** The diagram illustrates how Azure Role-Based Access Control (RBAC) assignments are scoped to resource groups, implementing the principle of least privilege. **RMS Core Team** members hold **Contributor** role on RMS-Core-RG, granting full management access to App Services, Functions, and Application Insights within that group, but **zero access** to resources in RMS-Routing-RG or RMS-Search-RG. This prevents accidental misconfiguration or malicious lateral movement—a compromised RMS developer account cannot modify Routing infrastructure or access Search service API keys. The **Platform Team** holds **Owner** role on RMS-Shared-RG to manage Key Vault access policies, SQL Database firewall rules, and Service Bus topic configurations, but only **Reader** role on microservice resource groups (visibility for troubleshooting, no modification rights). Break-glass **Global Administrators** receive just-in-time **Owner** access via Azure Privileged Identity Management (PIM) with approval workflow and 4-hour time limits. This RBAC hierarchy directly implements **CJIS Security Policy 5.6 (Personnel Security)** requirements by enforcing separation of duties and limiting blast radius of compromised credentials. The complete RBAC role assignments are detailed in **Appendix A: RBAC Role Matrix**, which maps organizational roles (Patrol Officer, Detective, Supervisor, Admin) to Azure resource permissions. The resource group architecture provides the technical scaffolding for these access controls, ensuring policy enforcement at the Azure Resource Manager layer before requests reach application code.\n\n**Lifecycle Management Advantages:** The resource group structure enables precise control over deployment, scaling, and decommissioning workflows. During major version upgrades, the operations team can **deploy RMS v3.0 to a new parallel resource group** (RMS-Core-V3-RG) while keeping RMS-Core-RG (v2.5) running for A/B testing and gradual traffic migration. Azure Front Door routes 10% of production traffic to the v3 resource group, monitoring error rates and latency metrics before full cutover. If anomalies are detected, operators delete RMS-Core-V3-RG entirely, reverting to the stable v2.5 deployment without complex rollback procedures. This blue-green deployment pattern—enabled by resource group isolation—reduces deployment risk and supports the **Operational Excellence** pillar's recommendation for canary deployments. For cost optimization, non-production environments are scheduled for automatic **resource group suspension**: Azure Automation runbooks execute `Stop-AzWebApp` and `Set-AzSqlDatabase -RequestedServiceObjectiveName 'Basic'` commands on RMS-Core-Dev-RG resources every weeknight at 6 PM, reducing compute costs by 70% during off-hours. The resource group boundary provides a clean scope for bulk operations, avoiding the complexity of targeting individual resources across a sprawling Azure subscription.\n\n***\n\n## 1.6 Multi-Tenant Isolation Strategy\n\n<ZoomableImage src=\"/images/arch/Multi-Tenant%20Isolation%20Model.png\" alt=\"Multi-Tenant Isolation Model\" caption=\"Multi-tenant isolation architecture with tenant-scoped access control and resource separation\" />\n\n### Tenant Provisioning and Isolation Architecture\n\nThe Multi-Tenant Isolation Model diagram illustrates the comprehensive tenant onboarding, resource isolation, and data segregation strategy that enables the CJN Dakota RMS to support multiple law enforcement agencies (Dakota County Sheriff, City Police Departments, Regional Task Forces) within a shared Azure infrastructure while maintaining strict security boundaries. This architecture balances operational efficiency (shared infrastructure reduces per-tenant cost) with regulatory compliance (CJIS Security Policy 5.10.1.2 mandates logical separation of CJI data between agencies). The model implements **tenant-scoped access control** at every system layer—Azure Active Directory groups, API Management policies, application-level authorization, and database row-level security—ensuring that an officer from Dakota County Sheriff cannot access cases created by City Police Department, even if application code vulnerabilities exist.\n\n**Tenant Onboarding Process and Provisioning Workflow:** The diagram details the automated tenant provisioning pipeline triggered when a new law enforcement agency contracts for RMS services. The workflow begins with a **Service Request** submitted via Azure DevOps Service Management portal, capturing tenant metadata (Agency Name, ORI Number, Billing Contact, Primary Administrator Email, Azure Region Preference). An Azure DevOps pipeline orchestrates the provisioning sequence: (1) **Entra ID Group Creation** (`RMS-DakotaSheriff-Users`, `RMS-DakotaSheriff-Admins`) with conditional access policies requiring MFA and compliant device enrollment, (2) **Resource Group Deployment** (`RMS-DakotaSheriff-RG`) dedicated to the tenant's application services, following the resource group architecture defined in Section 1.5, (3) **Azure SQL Database Schema Provisioning** (dedicated schema `dakota_sheriff` within the shared multi-tenant SQL Database, with row-level security policies enforcing tenant isolation), (4) **Service Bus Namespace Creation** (dedicated namespace `sb-dakotasheriff-prod` for tenant-specific message routing, preventing cross-tenant message leakage), (5) **Application Configuration** (tenant-specific app settings in Key Vault: `TenantId`, `DatabaseSchema`, `ServiceBusNamespace`, `BillingCode`), and (6) **Admin User Provisioning** (sending onboarding emails with initial credentials, MFA enrollment QR code, and training video links). This automated workflow reduces tenant onboarding time from 5 days (manual provisioning) to 2 hours (pipeline-driven), eliminating human error and ensuring consistent security configurations across all tenants.\n\n**Resource Isolation Guarantees and Dedicated Infrastructure:** The architecture implements a hybrid isolation model combining **shared infrastructure** (cost efficiency) with **dedicated tenant resources** (security boundaries). Each tenant receives a **dedicated resource group** for their application services—tenant-specific App Services, Azure Functions, and Application Insights instances—ensuring compute isolation and preventing one tenant's traffic spike from throttling another tenant's performance. For example, if Dakota County experiences a 10x load increase during a major incident, their dedicated App Service autoscales independently without impacting City Police Department's service availability. However, **shared infrastructure services**—Azure SQL Database (with logical schema separation), Azure Front Door, Azure API Management, and shared Key Vault—are provisioned once and serve all tenants to reduce operational overhead. The diagram illustrates Private Endpoint connections from tenant-specific App Services to the shared SQL Database, with network traffic remaining within the Azure backbone and never traversing public internet. Each tenant's App Service is assigned a **unique Managed Identity** (`RMS-DakotaSheriff-AppService-Identity`), which authenticates to SQL Database and is authorized to access only the `dakota_sheriff` schema via database-level permissions. This identity-based access control ensures that even if a tenant's application code is compromised, the attacker cannot escalate privileges to access other tenants' data at the database layer.\n\n**Performance Isolation Strategy and Resource Quotas:** To prevent noisy neighbor scenarios where one tenant's resource consumption degrades another tenant's performance, the architecture implements **Azure SQL Elastic Pools** with per-database DTU limits and **Service Bus Premium namespaces** with dedicated messaging units per tenant. The diagram shows Dakota County Sheriff's database allocated 50 DTUs within the shared elastic pool (supporting ~500 concurrent users), while smaller agencies receive 10 DTUs (supporting ~100 concurrent users). If Dakota County's workload exceeds 50 DTUs, SQL Database throttles their queries rather than allowing them to starve other tenants' resources. Similarly, each tenant's Service Bus namespace is configured with a quota of 1 Messaging Unit (1 GB memory, 1 vCPU), preventing one tenant from monopolizing the shared Service Bus infrastructure. Azure API Management enforces **per-tenant rate limiting**: Dakota County Sheriff is allocated 1,000 API requests/minute, while smaller agencies receive 200 requests/minute. These quotas are codified in API Management policies using `rate-limit-by-key` with the tenant's `ORI Number` as the throttling key, returning HTTP 429 Too Many Requests when limits are exceeded. Performance metrics are tracked in dedicated Application Insights instances per tenant, enabling tenant-specific performance SLAs (Dakota County contract specifies P95 API latency \\< 500ms, measured using their dedicated App Insights telemetry). This granular performance isolation—combined with autoscaling configurations that scale tenant resources based on their own workload—ensures predictable performance and meets enterprise SLA commitments.\n\n**Billing and Chargeback Model with Azure Cost Management Tags:** The diagram illustrates the cost allocation strategy that enables accurate per-tenant billing and chargeback to subscribing agencies. All Azure resources are tagged with **TenantId** (e.g., `dakota-sheriff`, `city-police-dept`) and **CostCenter** (e.g., `CC-2001-DakotaSheriff`), feeding into Azure Cost Management reports that break down monthly Azure spend by tenant. Shared infrastructure costs—SQL Database elastic pool base cost, Azure Front Door fees, API Management gateway instance—are **allocated proportionally** based on each tenant's resource consumption metrics (DTU-hours consumed, API requests processed, bandwidth transferred). The billing pipeline executes monthly: (1) Azure Cost Management API queries extract resource-level costs filtered by `TenantId` tag, (2) proportional allocation algorithm distributes shared costs (`SharedCost * (TenantAPIRequests / TotalAPIRequests)`), (3) invoice generation produces PDF invoices with cost breakdown tables (compute, storage, bandwidth, support) per tenant, and (4) automated Azure Automation runbook emails invoices to tenant billing contacts. This transparent cost model ensures accurate chargeback and enables tenants to optimize their usage (\"our evidence uploads cost $500/month—can we compress images before upload?\"). For tenants with fixed-price contracts, the cost reports serve as internal validation that actual Azure consumption aligns with pricing assumptions.\n\n**Data Isolation at Database Level:** The architecture implements defense-in-depth data isolation using multiple Azure SQL Database security features. **Row-Level Security (RLS) policies** enforce tenant filtering at the database engine level: when Dakota County Sheriff's App Service queries `SELECT * FROM Cases`, SQL Server automatically rewrites the query to `SELECT * FROM Cases WHERE TenantId = 'dakota-sheriff'`, preventing accidental cross-tenant data leakage even if application code omits the `WHERE TenantId` clause. **Separate database schemas** per tenant (`dakota_sheriff`, `city_police_dept`) provide namespace isolation and granular permission management—the `RMS-DakotaSheriff-AppService-Identity` is granted EXECUTE permission on stored procedures in the `dakota_sheriff` schema only, with DENY on all other schemas. **Always Encrypted columns** protect sensitive fields (SSN, criminal history) with tenant-specific Column Encryption Keys (CEKs) stored in Azure Key Vault, ensuring that even a database administrator with full SQL Server access cannot decrypt other tenants' sensitive data. The diagram maps these layered defenses, showing how a compromised application identity must bypass multiple security controls (Managed Identity authentication, schema-level authorization, RLS policy enforcement, Always Encrypted CEKs) before accessing another tenant's data—a defense-in-depth approach aligned with **CJIS Security Policy 5.10 (Information Systems Security Officer)** guidance on multi-tenant system design.\n\n**Scalability Considerations for Multi-Tenant Architecture:** The diagram addresses the scalability challenges inherent in multi-tenant systems, where tenant count growth must not degrade performance or management overhead. The current architecture supports **50 tenants** within a single Azure SQL Database (using elastic pools with 500 DTU capacity) and **20 tenants per Service Bus Premium namespace** (using topic-per-tenant design with 320 topics supported per namespace). When tenant count approaches these limits, the provisioning pipeline automatically **shards tenants across multiple infrastructure instances**: tenants 1-50 route to SQL Database `rms-sql-prod-001`, tenants 51-100 route to `rms-sql-prod-002`. Azure Front Door origin groups distribute traffic to region-specific deployments (East US, West US), enabling geographic scale-out as tenant count grows into hundreds. The architecture also supports **tenant migration**: if a high-volume tenant (Dakota County Sheriff with 5,000 users) outgrows shared infrastructure, operators can promote them to a **dedicated single-tenant deployment** by provisioning a standalone Azure SQL Database and redirecting their traffic via API Management backend pool updates. This hybrid model—starting tenants on shared infrastructure for cost efficiency, graduating high-growth tenants to dedicated infrastructure for performance guarantees—balances operational simplicity with enterprise scalability. The multi-tenant isolation strategy directly cross-references **Section 1.5 Resource Group Architecture**, which provides the resource organization foundation enabling per-tenant resource groups, and supports the **Multi-tenant isolation through resource groups** architecture strength listed in Section 1.\n\n***\n\n## 2. Network Topology & Security Zones\n\n<ZoomableImage src=\"/images/arch/network-security-zones.png\" alt=\"CJN Dakota Network Security Zones\" caption=\"Network security zones with defense-in-depth architecture and trust boundaries\" />\n\n### Network Security Architecture\n\nThe network topology diagram illustrates a defense-in-depth security model organized into six distinct trust zones, each with progressively restrictive access controls. This layered approach directly implements **CJIS Security Policy 5.5.4 (Network Security)** requirements by establishing clear trust boundaries, enforcing least-privilege access, and ensuring all CJI data remains within hardened, audited network segments.\n\n**Zone Hierarchy and Trust Model:** Network traffic flows through a graduated trust model, starting from the **Untrusted Zone** (public internet), passing through the **DMZ Edge Layer** (Azure Front Door with WAF/DDoS), entering the **Semi-Trusted API Gateway Zone** (Azure API Management with JWT validation), and finally reaching the **Trusted Application Tier** (VNet-integrated App Services) or **Restricted Data Tier** (Private Endpoint-only data services). The diagram's color coding—red for untrusted, yellow/orange for edge/gateway, green for application tier, and blue for data tier—provides immediate visual clarity on security posture. The **Management Zone** (purple) operates on a separate plane with dedicated RBAC and Privileged Identity Management (PIM) controls.\n\n**Private Endpoint Strategy:** The diagram prominently shows Private Endpoint connections (dark blue arrows) between the Application Tier and Data Tier. All PaaS services handling CJI data—Azure SQL Database, Key Vault Premium, Service Bus Premium, and Blob Storage—are accessed exclusively via Private Endpoints within the `snet-data /24` subnet. This architecture eliminates public IP addresses for data services, ensuring that even compromised application code cannot exfiltrate data directly to the internet. All data plane traffic remains within the Azure backbone network, satisfying CJIS Advanced Authentication requirements.\n\n**Network Security Group (NSG) Flow Control:** Traffic between zones is governed by NSG rules applied at the subnet level. The diagram illustrates filtered communication paths where API Management can route requests to App Services in `snet-rms-app`, `snet-route-app`, and `snet-search-app` subnets, but lateral movement between application subnets is denied by default. Each microservice operates in a network-isolated blast radius, preventing a compromised RMS service from directly accessing Search or Routing infrastructure. NSG flow logs are forwarded to Azure Monitor and Microsoft Sentinel for continuous security monitoring and anomaly detection.\n\n**Zero Trust Network Access (ZTNA):** The architecture implements Zero Trust principles by requiring explicit authentication and authorization at every layer. Even after passing Front Door WAF and API Management JWT validation, application services authenticate to data resources using Managed Identities (visualized as identity-based connections). Telemetry flows (dotted lines) from all services to Azure Monitor enable real-time detection of suspicious network patterns, such as unexpected data access or lateral movement attempts. This telemetry is aggregated in Microsoft Sentinel for Security Information and Event Management (SIEM) correlation, with automated response playbooks for high-severity alerts.\n\nThe table below maps each zone to its trust level, security controls, and hosted services. For operational procedures related to network security monitoring, see the **Operational Excellence** section. For application-level security patterns, refer to Section 6: **Defense-in-Depth Security**.\n\n| Zone | Trust Level | Controls | Services |\r\n|------|-------------|----------|----------|\r\n| **Public Internet** | Untrusted | N/A | End users, external partners |\r\n| **DMZ (Edge)** | Low | WAF, DDoS, TLS termination | Front Door, DNS |\r\n| **API Gateway** | Semi-trusted | Rate limiting, JWT, IP filter | API Management |\r\n| **Application Tier** | Trusted | NSGs, VNet integration, managed identity | App Services, Functions, SignalR |\r\n| **Data Tier** | Restricted | Private endpoints only, encryption at rest | SQL, Key Vault, Service Bus, Blob |\r\n| **Management** | Administrative | RBAC, PIM, audit logging | DevOps, Monitor, Sentinel |\n\n***\n\n## 3. Request Lifecycle\n\n| Step | Operation | Target Latency | SLA |\r\n|------|-----------|---------------|-----|\r\n| 1 | Authentication (Entra ID + MFA) | \\< 500ms | 99.99% |\r\n| 2-3 | Front Door routing | \\< 50ms | 99.99% |\r\n| 4 | API Management processing | \\< 100ms | 99.95% |\r\n| 5-7 | Business logic + DB write | \\< 500ms | 99.9% |\r\n| 8 | SignalR broadcast | \\< 200ms | 99.9% |\r\n| **Total** | **End-to-end** | **\\< 1.5s** | **99.9%** |\n\n### Distributed Tracing and Monitoring\n\n<ZoomableImage src=\"/images/arch/Azure%20Application%20Insights-2026-02-23-170842.png\" alt=\"Azure Application Insights Distributed Tracing\" caption=\"Application Insights distributed tracing showing correlation IDs and dependency tracking\" />\n\n#### Operational Visibility and Performance Monitoring\n\nThe Application Insights distributed tracing diagram visualizes the observability infrastructure that provides end-to-end visibility into request flows, dependency tracking, and performance anomaly detection across the entire CJN Dakota RMS distributed system. This monitoring architecture is foundational to achieving the **Operational Excellence** targets defined in Section 1's maturity assessment, enabling proactive incident response and data-driven capacity planning. The implementation aligns with the Phase 3 Operations roadmap item to \"implement comprehensive distributed tracing with Application Insights\" and establishes the baseline metrics referenced in **Appendix C (Monitoring Alert Thresholds)**.\n\n**Distributed Tracing Implementation Across Services:** The diagram illustrates how Application Insights SDKs embedded in each service—RMS App Service, Routing App Service, Search App Service, Azure Functions, and APIM Gateway—automatically capture telemetry data and propagate correlation context using the W3C Trace Context standard (`traceparent` HTTP header). When an officer initiates a \"Create Case\" request, the Static Web App generates a root `TraceId` and includes it in the API call to Azure Front Door. Front Door forwards the trace header to APIM, which appends its own `SpanId` and forwards to the RMS App Service. The RMS service creates child spans for each operation: Key Vault secret retrieval, SQL Database INSERT, Service Bus message publish, and SignalR notification broadcast. These nested spans form a hierarchical **dependency graph** in Application Insights, enabling operators to drill down from a slow API response (e.g., 5-second latency) to identify the specific bottleneck (e.g., SQL query took 4.8 seconds due to missing index). This granular visibility—unavailable in traditional monolithic application monitoring—is essential for troubleshooting distributed system performance issues.\n\n**Correlation ID Propagation Through the Request Chain:** The diagram emphasizes the role of `CorrelationId` (synonymous with `TraceId`) as the thread connecting telemetry across disparate services and asynchronous workflows. When the RMS service publishes a `CaseCreated` event to Service Bus, it includes the `CorrelationId` in message custom properties. Downstream consumers—`func-search-indexer`, `func-mncis-router`—extract this property and set it as the Application Insights `Operation_ParentId`, linking their telemetry to the original user request. This correlation extends even to external API calls: when `func-mncis-router` invokes the MNCIS SOAP endpoint, Application Insights tracks the outbound HTTP dependency with the same `CorrelationId`, creating a complete trace from browser click to external system response. Operators can query Application Insights Analytics with `Operation_Id == '...'` to retrieve all telemetry events (requests, dependencies, exceptions, custom events) for a single user transaction, dramatically reducing mean time to resolution (MTTR) for production incidents. For CJIS compliance, correlation IDs are also written to the SQL audit log, enabling cross-referencing between Application Insights performance data and regulatory audit trails.\n\n**Dependency Tracking Configuration for SQL, Service Bus, and Redis:** The diagram maps Application Insights' automatic dependency tracking capabilities for Azure PaaS services. The `Microsoft.ApplicationInsights.DependencyCollector` NuGet package intercepts ADO.NET database calls, Azure Service Bus SDK operations, and StackExchange.Redis cache commands, capturing dependency telemetry without code modification. For SQL Database, Application Insights logs each query with duration, row count, success/failure status, and the full SQL command text (sanitized to remove parameter values per CJIS requirements). For Service Bus, it tracks message publish operations with topic name, message size, and latency. For Redis, it captures cache hit/miss rates and command execution times. This dependency telemetry feeds into Application Insights' **Application Map** visualization (shown in the diagram), which renders real-time topology graphs with color-coded health indicators: green nodes (\\< 100ms average), yellow nodes (100-500ms), red nodes (> 500ms or high error rate). The Application Map serves as the primary operational dashboard—operators glance at the map to identify degraded services and receive drill-down links to diagnostic logs.\n\n**Performance Baselines and Anomaly Detection:** The architecture implements Application Insights Smart Detection, which uses machine learning to establish performance baselines for each service and alert on anomalies. For example, if the RMS API's median response time is typically 350ms but suddenly spikes to 2 seconds, Smart Detection automatically creates an incident with root cause analysis: \"SQL Database response time increased 6x—possible query regression or missing index.\" The diagram shows integration with Azure Monitor Action Groups, which route anomaly alerts to Microsoft Teams channels for immediate triage and optionally trigger auto-remediation runbooks (e.g., scaling out the App Service plan). Smart Detection also identifies dependency performance degradation (\"MNCIS API calls from func-mncis-router are 3x slower than last week\") and memory leak patterns (\"RMS App Service memory usage increasing 10% per hour\"). These proactive alerts—combined with the alert thresholds defined in Appendix C—enable the operations team to address performance regressions before they impact end users.\n\n**Alert Rules for Critical Metrics and Forward References:** The diagram highlights configured Azure Monitor alert rules that trigger on key performance indicators: **API response time** (warning at 2s, critical at 5s), **error rate** (warning at 1%, critical at 5%), **Service Bus DLQ depth** (critical at 10 messages), and **SQL DTU utilization** (warning at 70%, critical at 90%). Each alert rule specifies an Action Group with notification channels (email, SMS, Teams webhook) and severity levels (Sev 0-4). The monitoring strategy documented here references **Appendix C (Monitoring Alert Thresholds)** for complete threshold definitions and remediation procedures. This comprehensive alerting framework directly supports the **Operational Excellence** pillar recommendations from Section 1, addressing the maturity gap from 6.5/10 to 8.5/10. The distributed tracing capability is also identified as a Phase 3 deliverable in the Operations roadmap, providing the telemetry foundation for future AI-driven incident prediction and automated root cause analysis.\n\n***\n\n## 4. Event-Driven Processing\n\n### 4.1 Service Bus Topology\n\n<ZoomableImage src=\"/images/arch/Azure%20Service%20Bus%20Event%20Flow-2026-02-23-165619.png\" alt=\"Azure Service Bus Event Flow Architecture\" caption=\"Service Bus topology with session-based ordering and pub/sub pattern\" />\n\n#### Event-Driven Architecture Analysis\n\nThe Service Bus topology diagram illustrates a mature publish/subscribe (pub/sub) event-driven architecture that decouples microservices and enables asynchronous, scalable processing of RMS operations. This design pattern is fundamental to achieving high availability, fault tolerance, and independent service scaling across the RMS, Routing, and Search domains.\n\n**Session-Based Ordering Guarantees:** The diagram highlights three primary topics—`case-events`, `route-commands`, and `search-index`—each configured with **Service Bus Sessions** to guarantee FIFO (first-in, first-out) ordering within a session context. For `case-events`, the session key is `CaseId`, ensuring all events for Case #12345 are processed sequentially even under high load. Similarly, `route-commands` uses `DestinationId` as the session key, guaranteeing that all messages destined for MNCIS are processed in order, preventing race conditions where a case update could arrive at the state system before the initial case creation. This session-based ordering is critical for maintaining data consistency with external partners who expect deterministic event sequences.\n\n**Topic/Subscription Filtering Pattern:** The architecture leverages Azure Service Bus's content-based filtering to route messages from a single `route-commands` topic to multiple specialized subscribers. As shown in the diagram, subscriptions like `mncis-router`, `nibrs-router`, `ecite-router`, `maarc-router`, and `crash-router` each apply a SQL filter expression (`dest = 'MNCIS'`, `dest = 'NIBRS'`, etc.) to receive only relevant messages. This fan-out pattern eliminates the need for hardcoded routing logic in publisher code—the RMS API Service simply publishes a message with a `Destination` property, and Service Bus automatically delivers it to the appropriate consumer. This design supports rapid addition of new integration partners without modifying existing services.\n\n**Dead Letter Queue (DLQ) Monitoring and Recovery:** The diagram prominently features the error handling flow where failed messages are routed to a Dead Letter Queue after 10 delivery attempts (configured in the table below). The `DLQ Processor Function` continuously monitors the DLQ depth and triggers an **Azure Monitor Alert** when the count exceeds 10 messages, indicating a systemic integration failure. Operational procedures for DLQ triage involve inspecting message metadata (exception details, retry count) in the Azure Portal, correcting the root cause (e.g., restoring a downed external API), and manually resubmitting messages via the `ServiceBusAdministrationClient` SDK. This manual gate prevents automatic retry storms that could overwhelm partner systems.\n\n**Microservices Decoupling and Independent Scaling:** By using Service Bus as an intermediary, producer services (RMS API, Routing API, Scheduled Jobs) remain completely unaware of consumer implementations. If the `func-nibrs-sender` Function experiences a temporary outage, messages accumulate in the `nibrs-router` subscription without blocking other integrations. Each consumer Function scales independently based on queue depth, enabling cost-optimized scaling where high-volume integrations (MNCIS) run on multiple instances while low-volume integrations (MNCrash) use a single instance. This architecture prevents monolithic bottlenecks and supports continuous deployment of individual services without system-wide downtime.\n\nThe **Service Bus Premium** tier (selected for this deployment) provides essential enterprise features: geo-disaster recovery, Private Link network isolation (see Section 2), dedicated compute capacity (1 Messaging Unit = 1 vCPU), and larger message sizes (100 MB vs. 256 KB in Standard). For configuration details, see the property table below. For resilience patterns applied to external API calls within consumer Functions, see Section 5: **External Integrations**.\n\n| Property | Value | Rationale |\r\n|----------|-------|-----------|\r\n| **Tier** | Premium | Geo-DR, Private Link, dedicated resources |\r\n| **Sessions** | Enabled (per topic) | Ordered processing per case/destination |\r\n| **Max Delivery** | 10 attempts | Exponential backoff before DLQ |\r\n| **Lock Duration** | 5 minutes | Sufficient for external API calls |\r\n| **TTL** | 24 hours | Prevent stale message processing |\r\n| **DLQ Monitoring** | Alert on count > 10 | Immediate ops notification |\n\n### 4.2 RMS Event Publishing\n\n<ZoomableImage src=\"/images/arch/Azure%20RMS%20Services%20Event-2026-02-23-165517.png\" alt=\"Azure RMS Services Event Publishing\" caption=\"Event publishing architecture showing event types, schemas, and correlation strategy\" />\n\n#### Event Publishing Architecture\n\nThe RMS Event Publishing diagram illustrates the comprehensive event taxonomy and publishing mechanisms used across the RMS, Routing, and Search microservices to maintain eventual consistency and enable reactive workflows throughout the distributed system. This architecture implements the event sourcing pattern for critical state changes, creating an immutable audit trail that can reconstruct system state at any point in time and support future AI/ML pipelines for predictive analytics.\n\n**Event Type Classification and Schema Design:** The diagram categorizes published events into four primary types: **case-events** (CaseCreated, CaseUpdated, CaseStatusChanged, EvidenceAttached), **route-commands** (SubmitToMNCIS, SendNIBRSReport, FileCitation), **search-index** (IndexCase, UpdateSearchDocument, DeleteFromIndex), and **audit-events** (UserAction, SystemAction, ComplianceLog). Each event type follows a standardized JSON schema with required properties: `EventId` (GUID for deduplication), `EventType` (fully qualified type name), `AggregateId` (CaseId, EvidenceId, etc.), `Timestamp` (ISO 8601 UTC), `CorrelationId` (distributed tracing identifier), `UserId` (actor for CJIS audit), `Payload` (strongly-typed domain data), and `SchemaVersion` (semantic versioning for backward compatibility). This schema standardization enables generic event processing infrastructure—consumers can deserialize the envelope without knowing payload specifics, logging correlation IDs before payload parsing for observability.\n\n**Correlation ID Strategy for Distributed Tracing:** Every event published to Service Bus includes a `CorrelationId` property that propagates through the entire processing chain, enabling end-to-end request tracing across microservice boundaries. When an officer submits a case, the RMS API generates a root `TraceId` (W3C Trace Context standard) and embeds it in the `case-events` message. Downstream consumers (Search indexer, MNCIS router) extract this `CorrelationId`, attach it to their Application Insights telemetry, and include it in subsequent Service Bus messages. This creates a complete dependency graph in Application Insights, allowing operators to visualize the full event cascade triggered by a single user action. For example, querying Application Insights for `CorrelationId = abc123` reveals: API request → case-events published → search indexer invoked → route-commands published → MNCIS Function called → MNCIS API response—with timestamps and latencies at each hop. This tracing capability is essential for troubleshooting production incidents and identifying bottlenecks in the event processing pipeline.\n\n**Event Versioning for Backward Compatibility:** The diagram highlights the `SchemaVersion` property (e.g., `CaseCreated_v2`) used to implement zero-downtime schema evolution. When a new property is added to the `CaseCreated` event payload (e.g., adding `OfficerBadgeNumber` for enhanced audit logging), publishers increment the version to `v2` while consumers maintain support for both `v1` and `v2` schemas using polymorphic deserialization. Older consumers that don't recognize `v2` fall back to processing the common `v1` properties, preventing breaking changes during rolling deployments. This versioning strategy—combined with Azure Service Bus's native support for message properties—enables the RMS team to evolve the event schema incrementally without coordinating simultaneous deployments of all producer and consumer services. The Architecture Decision Record (ADR) for this pattern references Martin Fowler's event versioning guidance and prioritizes additive changes (new optional properties) over breaking changes (renaming/removing properties).\n\n**Publisher Pattern Implementation Across Services:** The diagram maps event publishing responsibilities to specific services: **RMS API Service** publishes `case-events` and `audit-events` after successful database writes (using the Outbox pattern to guarantee at-least-once delivery even if Service Bus is unavailable), **Routing API Service** publishes `route-commands` based on configuration rules (\"new felony cases automatically route to MNCIS\"), and **Search Service** publishes `search-index` events when document updates are required. Each service uses the Azure Service Bus SDK's `ServiceBusClient` with connection strings retrieved from Key Vault via Managed Identity, publishing to dedicated topics with explicit partition keys (for `case-events`, the partition key is `CaseId % 10` to distribute load across 10 partitions). This topic-per-event-type design (rather than a single monolithic event bus) enables granular access control—the Search Service can publish to `search-index` but cannot publish to `route-commands`, reducing blast radius in the event of a compromised service.\n\n### 4.3 Event Consumption and Processing\n\n<ZoomableImage src=\"/images/arch/Event%20Processing%20and-2026-02-23-170025.png\" alt=\"Event Processing and Consumption Architecture\" caption=\"Event consumption architecture with Azure Functions showing error handling and idempotency patterns\" />\n\n#### Consumer Architecture and Processing Guarantees\n\nThe Event Consumption and Processing diagram illustrates how Azure Functions consume messages from Service Bus subscriptions, implementing robust error handling, idempotency patterns, and performance optimization strategies to guarantee exactly-once processing semantics for critical workflows. This architecture balances throughput requirements (processing 50,000+ events/day during peak hours) with reliability requirements (zero data loss, deterministic retry behavior) while maintaining CJIS audit compliance for all CJI event processing.\n\n**Azure Function Triggers and Bindings Configuration:** The diagram shows dedicated Azure Functions for each event subscription: `func-case-processor` (consumes `case-events` subscription), `func-mncis-router` (consumes `mncis-router` subscription), `func-search-indexer` (consumes `search-index` subscription), and `func-audit-logger` (consumes `audit-events` subscription). Each Function uses the `ServiceBusTrigger` attribute with session-enabled configuration to process messages sequentially per session: `[ServiceBusTrigger(\"case-events\", \"case-processor\", IsSessionsEnabled = true)]`. The `host.json` configuration specifies critical performance parameters: `maxConcurrentSessions = 8` (parallel session processors per instance), `maxConcurrentCalls = 1` (sequential processing within a session for ordering guarantee), `prefetchCount = 32` (message pre-fetching for reduced latency), and `autoCompleteMessages = false` (explicit completion control for error handling). This configuration strikes a balance—8 concurrent sessions provide horizontal scaling while `maxConcurrentCalls = 1` ensures FIFO ordering within each case.\n\n**Error Handling and Retry Patterns with Exponential Backoff:** The diagram details the multi-layered error handling strategy. When a Function encounters a transient exception (network timeout, SQL deadlock, external API 503), the Service Bus redelivery mechanism automatically retries the message with exponential backoff: 1st retry after 10 seconds, 2nd after 40 seconds, 3rd after 90 seconds (backoff multiplier = 2.0, capped at 5 minutes). The Function code wraps external calls in Polly policies (see Section 5 code examples for circuit breaker implementation) to handle partner API failures gracefully. For poison messages that fail after 10 retry attempts—such as a malformed JSON payload or a permanent business rule violation—the message is automatically routed to the Dead Letter Queue (DLQ), where the `func-dlq-processor` Function logs the failure details to Application Insights with full context (stack trace, message properties, retry history) and sends an alert to the operations team via Azure Monitor Action Group. This graduated retry strategy prevents transient failures from triggering DLQ alarms while ensuring persistent errors receive immediate attention.\n\n**Performance and Scaling Considerations:** The architecture leverages **Consumption Plan** for low-traffic Functions (DLQ processor, audit logger) to minimize costs, but deploys high-throughput consumers (case processor, MNCIS router) on **Premium Plan** for guaranteed compute capacity and faster cold start times (\\< 1 second vs. 10+ seconds on Consumption Plan). Premium Plan Functions also benefit from VNet integration for Private Link connectivity to Service Bus (avoiding public internet traversal) and from always-ready instances (minimum 1 instance pre-warmed, scaling to 20 instances under load). The diagram shows Azure Functions scaling logic: when Service Bus queue depth exceeds 1,000 messages per instance, the platform automatically provisions additional Function instances (up to the configured maximum of 20). This elastic scaling—combined with Service Bus Premium's dedicated messaging units—ensures the system maintains sub-second processing latency even during incident spikes (e.g., 500 officers simultaneously creating cases after a major event).\n\n**Idempotency Patterns for Exactly-Once Processing Guarantee:** To prevent duplicate processing when Service Bus retries a message, each Function implements idempotency checks using distributed caching. Before processing a `CaseCreated` event, `func-case-processor` queries Azure Cache for Redis with the key `processed:{EventId}` (TTL = 7 days, matching Service Bus retention). If the key exists, the Function immediately completes the message without re-execution, logging a \"duplicate message detected\" telemetry event. For new messages, the Function performs a **two-phase commit**: (1) write to Redis cache with the processing status \"in-progress\", (2) execute business logic and persist to SQL Database, (3) update Redis to \"completed\" and complete the Service Bus message. If the Function crashes between steps 1 and 3, Service Bus redelivers the message, but the Redis check detects \"in-progress\" status and safely completes the message (the SQL write may have succeeded before the crash). This idempotency pattern—combined with SQL Database's deterministic stored procedures (checking for existing CaseId before INSERT)—guarantees exactly-once processing semantics without requiring distributed transactions or two-phase commit protocols across Service Bus and SQL Database.\n\n**Message Session Handling for Ordered Processing:** The diagram emphasizes Service Bus Sessions as the mechanism for maintaining event ordering within a case context. Each `case-events` message includes a `SessionId` property set to the `CaseId` value. Service Bus guarantees that all messages with the same `SessionId` are delivered to a single Function instance in FIFO order, preventing race conditions where a `CaseUpdated` event could be processed before the corresponding `CaseCreated` event. The Function code accepts the session using `IMessageSession.AcceptSessionAsync(sessionId)`, processes messages sequentially, and releases the session lock upon completion. This session-based ordering is critical for maintaining referential integrity in the search index—if `CaseUpdated` processed before `CaseCreated`, the search indexer would attempt to update a non-existent document. For non-case events (e.g., system health checks), messages are published without a `SessionId`, allowing parallel processing across all available Function instances for maximum throughput.\n\n***\n\n## 5. External Integrations\n\n<ZoomableImage src=\"/images/arch/API%20Gateway%20to%20Outbound-2026-02-23-165702.png\" alt=\"API Gateway to Outbound External Systems\" caption=\"External integration architecture showing inbound/outbound flows and resilience patterns\" />\n\n### External Integration Architecture\n\nThe external integrations diagram maps the complete data flow for bidirectional communication between the CJN Dakota RMS and nine external law enforcement, judicial, and public safety systems. This architecture handles both **inbound data** (court returns from MNCIS, mobile citations from Citation App) and **outbound data** (case submissions, crash reports, FBI reporting), implementing rigorous resilience patterns to ensure guaranteed delivery even when partner systems experience downtime.\n\n**Integration Gateway and Security Boundary:** All external traffic enters through the Azure API Management (APIM) Gateway, which serves as the single ingress/egress point for partner communications. The diagram highlights APIM's critical security functions: TLS 1.2/1.3 encryption for data in transit, JWT token validation for authenticated partners, IP allowlist filtering (restricting MNCIS to known state IP ranges), and comprehensive request/response logging for audit trails. APIM policies also enforce rate limiting (e.g., 100 requests/minute per partner) and throttling to protect backend services from denial-of-service scenarios. This gateway isolation ensures that external partners never obtain direct network access to RMS application or data tiers.\n\n**Inbound Processing Pipeline:** The diagram shows two primary inbound flows: **MNCIS Inbound** (court returns, charging decisions, case status updates) and **Citation App** (mobile-generated traffic citations). Inbound requests are routed from APIM to the **ROUTE\\_IN Service**, which performs schema validation, deduplication (checking for duplicate submission IDs), and message transformation into the internal RMS domain model. The processing pipeline includes scheduled jobs (MN Crash Job, MAARC Job, CAD Job) that poll external endpoints for updates when push-based webhooks are unavailable. These jobs publish processed data to the **RMS Service Core**, which persists entities to the **RMS Database** and triggers downstream workflows via Service Bus (see Section 4).\n\n**Outbound Routing via ROUTE2DEST Service:** The **ROUTE2DEST Distribution Service** (highlighted in purple) acts as the central hub for all outbound integrations, consuming messages from the `route-commands` Service Bus topic and invoking partner-specific Azure Functions. The diagram illustrates six outbound destinations: **MNCIS\\_OUT** (state judicial system), **eCitations\\_OUT** (citation filings), **eCharging\\_OUT** (prosecutor charging documents), **MNCrash\\_OUT** (traffic crash reports), **MAARC\\_OUT** (multi-agency records consortium), and **NIBRS\\_OUT** (National Incident-Based Reporting System for FBI). Each integration implements the resilience patterns detailed in the **Integration Resilience Patterns** subsection below—exponential backoff retry (3 attempts with 2^n second delays), circuit breaker (opens after 3 consecutive failures for 1 minute cooldown), and Dead Letter Queue routing after 10 total failures.\n\n**Cross-System Data Lineage and Audit Compliance:** The architecture maintains end-to-end traceability for all external data exchanges. Every message flowing through ROUTE2DEST includes distributed tracing headers (W3C Trace Context standard) that correlate with Application Insights telemetry, enabling operators to trace a case submission from the officer's browser through the RMS API, Service Bus, ROUTE2DEST, and ultimately to the MNCIS API response. This telemetry is critical for troubleshooting integration failures (e.g., \"Why didn't case #12345 reach MNCIS?\") and for regulatory compliance (CJIS Security Policy 5.4.1 requires audit logs for all CJI disclosures). Failed messages in the Dead Letter Queue are logged with full context (exception stack traces, retry count, original message payload) for forensic analysis.\n\nFor detailed partner-specific protocols and data formats, refer to the **External Systems** table below. For code examples demonstrating Polly-based retry and circuit breaker policies, see the **Integration Resilience Patterns** tab section. This integration architecture directly supports the multi-agency collaboration capabilities listed in Section 1's **Key Capabilities** table.\n\n### External Systems\n\n| System | Direction | Data Type | Protocol |\r\n|--------|-----------|-----------|----------|\r\n| **MNCIS** | Bidirectional | Case submissions, court returns | HTTPS/API |\r\n| **NIBRS** | Outbound | FBI crime reporting (monthly/annual) | NIBRS XML |\r\n| **eCitations** | Outbound | Citation filings | HTTPS/API |\r\n| **eCharging** | Outbound | Charging documents to prosecutors | HTTPS/API |\r\n| **MNCrash** | Outbound | Crash reports | HTTPS/API |\r\n| **MAARC** | Bidirectional | Multi-agency shared records | HTTPS/API |\r\n| **DPS** | Outbound | Dept. of Public Safety data | HTTPS/API |\r\n| **Hennepin County** | Bidirectional | County data exchange | HTTPS/API |\r\n| **LOGIS** | Bidirectional | Shared government IT services | HTTPS/API |\r\n| **Citation App** | Inbound | Mobile-generated citations | HTTPS/API |\n\n### Integration Resilience Patterns\n\n| Pattern | Implementation | Behavior |\r\n|---------|---------------|----------|\r\n| **Retry (Exponential Backoff)** | Polly `WaitAndRetryAsync` | 3 retries at 2^n seconds |\r\n| **Circuit Breaker** | Polly `CircuitBreakerAsync` | Opens after 3 failures, 1 min break |\r\n| **Guaranteed Delivery** | Service Bus Topics | 10 retry attempts before DLQ |\r\n| **Dead Letter Queue** | DLQ Processor Function | Alert on count > 10, manual reprocess |\r\n| **Store and Forward** | Fallback mechanism | Persist locally if partner unavailable |\n\n***\n\n## 6. Defense-in-Depth Security\n\n### Security Controls Matrix\n\n| Layer | Control | CJIS Mapping | Status |\r\n|-------|---------|-------------|--------|\r\n| **Identity** | Entra ID + MFA | 5.6.2.2 | Implemented |\r\n| **Identity** | FIPS 140 Authenticators | 5.6.2.2 | Needs Validation |\r\n| **Identity** | PIM/JIT Access | 5.5.2 | Recommended |\r\n| **Perimeter** | WAF v2 Rules | 5.10.4 | Implemented |\r\n| **Perimeter** | DDoS Protection | 5.10.4 | Implemented |\r\n| **Network** | Private Link | 5.5.4 | Recommended |\r\n| **Network** | VNet + NSGs | 5.5.4 | Implemented |\r\n| **Application** | JWT Validation | 5.5.2 | Implemented |\r\n| **Application** | Rate Limiting | 5.10.4 | Implemented |\r\n| **Compute** | Managed Identities | 5.6.1 | Recommended |\r\n| **Data** | TDE + CMK | 5.10.1 | Recommended |\r\n| **Data** | Always Encrypted | 5.10.1 | Recommended |\r\n| **Monitoring** | Sentinel SIEM | 5.4.1 | Recommended |\r\n| **Monitoring** | Audit Logging (7 yr) | 5.4 | Partial |\n\n### Security Recommendations\n\n### Managed Identity Implementation\n\n<ZoomableImage src=\"/images/arch/Managed%20Identity-2026-02-23-165751.png\" alt=\"Managed Identity Authentication Architecture\" caption=\"Managed Identity architecture showing credential-less authentication and RBAC role assignments\" />\n\n**System-Assigned vs User-Assigned Identity Decision Tree:** The diagram presents the architectural decision framework for selecting between **system-assigned managed identities** (lifecycle tied to a specific resource instance) and **user-assigned managed identities** (independent lifecycle, reusable across resources). For the RMS architecture, the recommendation follows the principle illustrated in the diagram's decision tree: use **system-assigned identities** for single-purpose, ephemeral resources like Azure Functions (where each function's identity permissions are tightly scoped to its specific integration partner, e.g., the `func-mncis-sender` Function has only `ServiceBusSender` role on the `route-commands` topic, nothing more), and use **user-assigned identities** for shared infrastructure components like the RMS API App Service and Routing API App Service that both require identical RBAC permissions to Azure SQL Database, Key Vault, and Service Bus. The diagram shows how a single user-assigned identity named `id-rms-shared-${environment}` can be assigned to multiple App Services, reducing RBAC management overhead from N individual role assignments per service to a single centralized role assignment per target resource.\n\n**Migration Path from Key Vault Stored Credentials to Managed Identities:** The architecture diagram illustrates the phased migration strategy (referenced in Priority Recommendation #1 in Section 10) for eliminating stored credentials currently held in Azure Key Vault. The current state, visualized in the diagram's \"Before\" pane, shows App Services retrieving connection strings from Key Vault secrets (`AzureWebJobsStorage`, `SqlConnectionString`, `ServiceBusConnectionString`) at startup and passing them to SDK clients like `ServiceBusClient`. This pattern, while encrypted at rest, still involves credentials existing in memory and configuration, creating breach risk if application code is compromised or misconfigured logging exposes connection strings. The target state, shown in the \"After\" pane, demonstrates managed identity-based authentication where the `ServiceBusClient` constructor receives a `DefaultAzureCredential` token provider instead of a connection string—the Azure SDK automatically obtains an access token from the Azure Instance Metadata Service (IMDS) using the resource's managed identity, authenticates to Service Bus, and handles token refresh without any secrets ever touching application code. The diagram notes that this migration has zero breaking changes to business logic; only the infrastructure-as-code Bicep templates and authentication initialization code require modification.\n\n**RBAC Role Assignments Per Service Shown in Diagram:** The diagram meticulously documents the least-privilege RBAC role assignments required for each microservice when using managed identity authentication, directly addressing the \"stored credentials\" security gap identified in the Executive Summary. The **RMS Core API** managed identity receives: `Key Vault Crypto User` (to retrieve Always Encrypted column encryption keys without managing secrets), `Azure SQL Database Contributor` (to execute SQL queries via Azure AD authentication), and `Azure Service Bus Data Sender` (to publish case events to the `case-events` topic). The **Routing Service** managed identity receives: `Azure Service Bus Data Receiver` on the `route-commands` subscription and `Azure Service Bus Data Sender` for publishing completion acknowledgments back to status topics. The **Search Indexing Functions** receive read-only roles: `Storage Blob Data Reader` for accessing case documents and `Search Index Data Contributor` for updating Azure AI Search indexes. This granular role decomposition, annotated in the diagram with resource scopes, ensures that even if a service is compromised through an application vulnerability, the attacker gains only narrowly scoped permissions—a compromised Search Function cannot modify SQL data or access encryption keys, limiting blast radius.\n\n**Credential Rotation Elimination Benefits and AAD Token Lifecycle:** The diagram highlights one of Managed Identity's strongest security advantages: **automatic credential rotation** handled entirely by the Azure platform. Unlike connection strings or service principal client secrets that require 90-day rotation workflows (with associated risk of expired credentials causing outages), managed identity access tokens are short-lived (1-hour validity) and automatically refreshed by the Azure SDK's credential chain without application involvement. The diagram illustrates the token acquisition flow: (1) Application code calls `serviceBusClient.SendMessageAsync()`, (2) Azure SDK's `DefaultAzureCredential` detects it's running in an Azure managed environment, (3) SDK queries the Instance Metadata Service (IMDS) endpoint `http://169.254.169.254/metadata/identity/oauth2/token` with the resource's managed identity, (4) IMDS authenticates the caller via Azure fabric identity proof and returns a signed JWT token with `aud` claim matching Service Bus's resource ID, (5) SDK includes the token in the `Authorization: Bearer` header of Service Bus API calls. This entire flow completes in milliseconds. When the token nears expiration (50 minutes into its 60-minute lifetime), the SDK proactively refreshes it using the same IMDS mechanism. This lifecycle management eliminates the operational burden of maintaining credential rotation runbooks and removes the risk of developers hardcoding secrets in application configuration \"temporarily\" during troubleshooting.\n\n**Zero Secrets in Configuration Advantage and Alignment with Priority Recommendation #1:** As emphasized in the diagram's benefits callout and explicitly referenced in Section 10's Priority Recommendations table (Priority #1: \"Implement Managed Identities for all services - 2-3 week effort - Eliminate credential management, reduce breach risk\"), the managed identity architecture achieves the security ideal of **zero secrets in application configuration**. The diagram contrasts the current Key Vault-based approach (where `appsettings.json` contains `\"KeyVaultUri\": \"https://kv-rms-prod.vault.usgovcloudapi.net/\"`, still a piece of infrastructure knowledge) with the managed identity approach (where configuration contains only `\"ServiceBusNamespace\": \"sb-rms-prod.servicebus.usgovcloudapi.net\"`, a non-sensitive routing target). Even if an attacker gains read-access to application configuration files or environment variables, they obtain zero authentication materials. This architecture satisfies CJIS Security Policy 5.10.1's requirement for Advanced Authentication by eliminating static credentials entirely, replacing them with cryptographically signed identity proof that cannot be exfiltrated or replayed outside the Azure environment. The migration to managed identities is the single highest-impact security improvement the RMS architecture can implement, and the diagram provides the technical blueprint for executing this transformation across all 15+ compute and data services in the topology.\n\n### CJIS Compliance Gaps\n\n| CJIS Policy Area | Status | Priority | Action Required |\r\n|---|---|---|---|\r\n| **5.10.1 Encryption In Use** | MISSING | Critical | Evaluate Azure Gov CJIS Management Agreement |\r\n| **5.12 Personnel Security** | MISSING | Critical | Fingerprint background checks for CJI access |\r\n| **5.6.2.2 FIPS 140 Authenticators** | MISSING | Critical | Document FIPS 140 compliance of all MFA methods |\r\n| **CJIS Security Addendum** | MISSING | Critical | Sign with Microsoft |\r\n| **5.4 Audit Logging** | Partial | High | Extend to all CJI touchpoints, 7+ year retention |\r\n| **5.5 Access Control** | Partial | High | Session lock, account lockout thresholds |\r\n| **5.2 Security Awareness Training** | MISSING | High | Formal training program |\r\n| **5.7/5.10.4 Configuration Management** | MISSING | High | Baseline configs, change control |\r\n| **5.15 System Integrity** | MISSING | High | Vulnerability scanning, integrity monitoring |\r\n| **Customer Lockbox** | MISSING | High | Control Microsoft engineer access |\r\n| **Azure Policy CJIS Initiative** | MISSING | Medium | Deploy built-in CJIS compliance policies |\r\n| **5.1 Information Exchange Agreements** | MISSING | Medium | Formal agreements with external systems |\r\n| **5.3 Incident Response** | Partial | Medium | Formal plan with exercise schedule |\n\n***\n\n## 7. CJIS Data Classification Boundaries\n\n| Data Type | Classification | Encryption | Access Control | Retention |\r\n|-----------|---------------|------------|---------------|-----------|\r\n| **Case records (PII)** | CJI - Restricted | TDE + Always Encrypted | Background-checked personnel | Per agency policy |\r\n| **Evidence files** | CJI - Restricted | Double encryption + WORM | Chain of custody verified | Case lifecycle + 7 years |\r\n| **Audit logs** | CJI - Controlled | Immutable storage | Read-only after write | 7+ years |\r\n| **Integration messages** | CJI - In Transit | TLS 1.2 + SB encryption | Managed Identity auth | TTL-based |\r\n| **Aggregated statistics** | Non-CJI | Standard encryption | Analyst role | 5 years |\r\n| **AI training data** | Non-CJI | Standard encryption | Data scientist role | Model lifecycle |\n\n### CJIS Data Anonymization Pipeline\n\n<ZoomableImage src=\"/images/arch/CJIS%20Data%20Anonymization-2026-02-23-170447.png\" alt=\"CJIS Data Anonymization Architecture\" caption=\"Data anonymization pipeline showing PII removal, k-anonymity enforcement, and re-identification risk assessment\" />\n\n**PII Removal and K-Anonymity Implementation:** The diagram above illustrates the comprehensive data anonymization pipeline that enables safe use of law enforcement data for analytics and AI/ML applications without violating CJIS Security Policy 5.10 requirements. The pipeline implements a multi-stage de-identification process starting with **field-level PII scrubbing** (removing direct identifiers such as names, SSN, date of birth, addresses, and phone numbers), followed by **k-anonymity enforcement** with a threshold of k=5, meaning each anonymized record must be indistinguishable from at least 4 other records when considering quasi-identifiers like age range, geographic region, and case type. This statistical disclosure control technique, visualized in the diagram's aggregation layer, prevents re-identification attacks where an adversary might correlate anonymized data with external datasets to uncover individual identities.\n\n**Re-identification Risk Assessment Methodology:** The pipeline includes a critical validation stage that performs quantitative re-identification risk assessment before any data exits the CJIS restricted zone. As shown in the diagram's \"Validate\" component, this assessment calculates the probability that a motivated attacker with access to public records databases could successfully link an anonymized record back to a specific individual. The methodology incorporates prosecutor and public defender risk models (assuming adversaries with moderate computational resources and access to county property records, voter registrations, and court dockets) and applies a threshold of \\< 0.05 re-identification probability per record. Records failing this threshold are either further generalized (e.g., converting specific ages to 5-year age bands) or excluded from the non-CJI dataset entirely. This approach directly implements the principles outlined in NIST SP 800-188 (De-Identifying Government Datasets).\n\n**CJIS Security Policy 5.4 Audit Requirements Compliance:** Every execution of the anonymization pipeline generates immutable audit logs (stored in Azure Monitor Log Analytics with 7-year retention) documenting the transformation applied to each source record, the k-anonymity scores achieved, the re-identification risk scores calculated, and the identity of the data scientist or analyst who initiated the pipeline run. The diagram shows these audit trails flowing to a dedicated \"Pipeline Audit Log\" store that is subject to quarterly CJIS compliance reviews. This audit capability satisfies Policy 5.4.1's requirement to log all CJI disclosures, treating the anonymization pipeline as a controlled disclosure mechanism. The logs also support forensic investigations if downstream AI systems exhibit biased or problematic behavior—analysts can trace back to the original data selection and transformation logic to identify root causes.\n\n**Data Masking Layers and AI-Ready Architecture Integration:** The architecture implements a defense-in-depth approach to data protection with multiple masking layers visible in the diagram. **Row-level filtering** excludes sensitive case types (e.g., active witness protection cases, juvenile records with court-ordered sealing) before any transformation occurs. **Field-level redaction** removes narrative text fields containing unstructured PII that automated scrubbing might miss (e.g., officer notes mentioning \"spoke with John Smith's mother\"). **Aggregation-level suppression** prevents small-cell disclosures by suppressing any statistical aggregates derived from fewer than 10 source records. This multi-layered approach, combined with the one-way data flow architecture (CJI → Anonymization → Non-CJI with no reverse path), creates a robust trust boundary. As referenced in Section 9 (AI-Ready Architecture), this anonymization pipeline is the sole mechanism for populating AI/ML training datasets, ensuring that Azure OpenAI services and Azure AI Search indexes in the non-CJI zone never have direct access to raw criminal justice information, eliminating compliance risk while enabling advanced analytics capabilities.\n\n***\n\n## 8. Disaster Recovery Topology\n\n| Component | RPO (Data Loss) | RTO (Downtime) | Replication | Failover |\r\n|-----------|----------------|----------------|-------------|----------|\r\n| **SQL Database** | \\< 5 seconds | \\< 60 minutes | Sync geo-replication | Automatic (failover group) |\r\n| **Service Bus** | Metadata only | \\< 10 minutes | Geo-DR pairing | Manual alias switch |\r\n| **Blob Storage** | \\< 15 minutes | \\< 1 hour | RA-GRS | Manual DNS update |\r\n| **Key Vault** | Manual backup | \\< 2 hours | Backup/restore | Manual restore |\r\n| **App Services** | N/A (stateless) | \\< 15 minutes | Warm standby | DNS switch + scale up |\r\n| **Front Door** | N/A | \\< 5 minutes | Global (built-in) | Automatic health probes |\n\n### Azure SQL Failover Group Configuration\n\n<ZoomableImage src=\"/images/arch/Azure%20SQL%20Failover%20and-2026-02-23-170534.png\" alt=\"Azure SQL Failover and Geo-Replication Architecture\" caption=\"Azure SQL failover group configuration with active-passive replication and automatic failover\" />\n\n**Failover Group Architecture and Active-Passive Configuration:** The diagram illustrates the Azure SQL Database failover group implementation that provides automated geo-redundancy for the RMS transactional database. The architecture deploys an **active-passive** configuration with the primary database in US Gov Virginia handling all read/write traffic and a continuously synchronized secondary replica in US Gov Arizona maintained in hot standby mode. Unlike active-active configurations that distribute writes across regions (which would introduce complex conflict resolution for case management transactions), the active-passive model ensures strong consistency—every committed transaction on the primary is synchronously replicated to the secondary before the commit acknowledgment is returned to the application, guaranteeing zero data loss (RPO = 0) for committed transactions. The diagram shows the failover group listener endpoints that abstract the physical database locations from application connection strings, enabling transparent failover without application code changes.\n\n**Achieving RPO \\< 5 Seconds with Continuous Data Replication:** The RPO target of \"\\< 5 seconds\" documented in the table above represents the maximum age of the most recent transaction that could be lost during an unplanned primary region outage. Azure SQL's active geo-replication technology, visualized in the diagram's replication flow, achieves this aggressive RPO through a **redo log shipping** mechanism that streams transaction log records from the primary to the secondary over the Azure backbone network with typical latency under 1 second. The diagram highlights the asynchronous commit mode used to balance data durability with application performance—transactions commit on the primary after writing to local durable storage, then replication to the secondary occurs in the background. This approach prevents cross-region network latency (approximately 50ms between Virginia and Arizona) from blocking user-facing transactions. In the rare scenario where the primary region fails before recent transactions replicate, the failover process implements **potential data loss detection**, alerting operators to the last successfully replicated transaction timestamp so business users can manually reconcile any lost case updates.\n\n**Manual vs. Automatic Failover Decision Tree:** The diagram presents a critical architectural decision point: configuring the failover group for automatic failover versus manual failover. **Automatic failover** (recommended in the diagram with a 60-minute grace period) triggers when the primary database becomes unreachable for longer than the configured detection timeout. Azure's health probe system continuously monitors database availability every 30 seconds, and after 4 consecutive failures (2 minutes of downtime), begins a 60-minute waiting period to distinguish between transient network issues and genuine regional outages. If the primary remains unavailable after this grace period, the system automatically promotes the secondary to primary, updates DNS records for the failover group listener, and sends Azure Monitor alerts to the operations team. **Manual failover**, alternatively, requires an authorized operator to explicitly invoke the failover command via Azure Portal, CLI, or automation runbook. The diagram recommends automatic failover for production RMS environments to minimize downtime during after-hours or weekend regional outages, but notes that manual failover provides greater control for planned maintenance scenarios where operators want to validate application state before cutting over.\n\n**Connection String Handling and Read/Write Endpoint Strategy:** Application services (RMS API, Routing Service, Search Service) use the failover group listener connection strings shown in the diagram rather than connecting directly to specific database servers. The architecture provisions two listener endpoints: a **read/write listener** (e.g., `rms-failover-group.database.usgovcloudapi.net`) that always points to the current primary database and automatically updates during failover, and a **read-only listener** (e.g., `rms-failover-group.secondary.database.usgovcloudapi.net`) that explicitly targets the secondary replica for offloading read-intensive reporting queries. The diagram illustrates how the RMS Core API uses the read/write listener for transactional case management operations, while the reporting dashboard and analytics queries connect to the read-only endpoint to prevent report generation from impacting officer productivity. During failover, the read/write listener's DNS record is updated within 5 minutes (contributing to the 60-minute total RTO), and application connection pools automatically reconnect to the newly promoted primary. This listener-based approach eliminates the need for application code to implement region-aware routing logic or maintain multiple connection string configurations per environment.\n\n### RPO/RTO Objectives and Recovery Prioritization\n\n<ZoomableImage src=\"/images/arch/RPO_RTO%20Objectives%20and-2026-02-23-170624.png\" alt=\"RPO/RTO Objectives and Tier-Based Recovery\" caption=\"Recovery objectives with tier-based prioritization for business continuity\" />\n\n**Business Process Mapping to Recovery Objectives:** The diagram illustrates the comprehensive Recovery Point Objective (RPO) and Recovery Time Objective (RTO) targets mapped to critical RMS business processes, derived from stakeholder interviews with patrol officers, detectives, dispatch supervisors, and IT operations staff. The architecture implements a **tier-based recovery prioritization model** (Tier 0: Critical, Tier 1: Important, Tier 2: Normal) that acknowledges not all system components require the same aggressive recovery targets. Tier 0 components—the RMS Core API for active case management, Azure SQL Database for transactional case records, and Azure Front Door for officer access—have the most stringent targets (RPO \\< 5 seconds, RTO \\< 60 minutes) because their unavailability directly prevents officers from documenting incidents in the field or accessing case histories during traffic stops. Tier 1 components like the Routing Service for external integrations and Service Bus message queues have relaxed targets (RPO \\< 15 minutes, RTO \\< 2 hours) since temporary delays in submitting cases to MNCIS or NIBRS do not immediately impact field operations. Tier 2 components such as the reporting dashboard and analytics queries tolerate even longer outages (RTO \\< 8 hours) as they support administrative workflows rather than real-time public safety operations.\n\n**Acceptable Data Loss Windows and Operational Reasoning:** The RPO targets annotated in the diagram represent the maximum amount of recent data the organization is willing to lose during a disaster scenario, informed by cost-benefit analysis of replication technology investments versus business impact. For the RMS transactional database, the RPO \\< 5 seconds target means that in a catastrophic primary region failure, officers might need to re-enter up to 5 seconds of case updates manually—potentially affecting 1-2 active case submissions during peak activity hours. This narrow data loss window justifies the investment in Azure SQL active geo-replication (which incurs egress costs for cross-region data transfer and requires doubling database compute/storage costs for the secondary replica). For Service Bus message queues with RPO \\< 15 minutes, the organization accepts that messages published in the 15 minutes before a disaster might be lost, requiring manual resubmission of affected case routing requests identified through Application Insights distributed tracing logs. This decision balances the cost of Service Bus Premium geo-disaster recovery pairing (~$2,500/month) against the operational impact of occasionally reprocessing a small batch of integration messages.\n\n**Downtime Cost Analysis and Investment Justification:** The RTO targets in the diagram directly correlate to quantified downtime costs that justify disaster recovery infrastructure investments. Internal analysis (detailed in the \"DR Cost Model\" section of the operational playbooks) estimates that complete RMS unavailability costs approximately **$15,000 per hour** in officer productivity loss (officers reverting to paper forms, delayed case filings causing court continuances, inability to access warrant information during traffic stops). The Tier 0 RTO \\< 60 minutes target therefore limits worst-case financial exposure to $15,000 for a single regional outage, compared to potential 8-12 hour recovery times without geo-redundancy that could exceed $180,000 in impact. The diagram shows how this cost model drove the decision to implement automatic SQL failover, warm standby App Service deployments in the secondary region, and Azure Front Door's built-in multi-region routing—collectively adding approximately $8,000/month in infrastructure costs but protecting against potentially catastrophic business disruptions.\n\n**DR Testing Schedule and Validation Procedures:** The diagram references a rigorous DR testing program designed to validate that actual recovery times match the documented RTO targets. The architecture mandates **quarterly failover drills** (scheduled 90 days apart, documented in Azure DevOps work items) where the operations team deliberately fails over to the secondary region during a planned maintenance window, measures time-to-recovery for each component, and documents discrepancies. The diagram illustrates the test procedure: (1) Announce test window to stakeholders, (2) Trigger SQL failover group promotion, (3) Update App Service deployment slots to secondary region, (4) Validate application functionality with smoke tests, (5) Measure and record actual RTO/RPO achieved, (6) Conduct post-mortem to identify process improvements. This testing discipline ensures that DR runbooks remain accurate as the architecture evolves and that operations staff maintain proficiency in failover procedures. Test results are aggregated in the **DR Readiness Dashboard** (visible in the diagram) that tracks failover success rate, average RTO variance from target, and runbook accuracy metrics, providing executive leadership with confidence in disaster recovery preparedness.\n\n### Reliability Recommendations\n\n| Item | Current State | Recommendation | Effort |\r\n|------|--------------|----------------|--------|\r\n| **DR Strategy** | No documented plan | Define RTO/RPO, create runbooks | 1 week |\r\n| **SQL Geo-Replication** | Single-region | Enable geo-replication to secondary | 2 weeks |\r\n| **Service Bus Geo-DR** | Standard tier | Upgrade to Premium for geo-DR | 2 weeks |\r\n| **Health Endpoints** | Basic monitoring | Comprehensive health checks per service | 1 week |\r\n| **Retry Policies** | Limited | Exponential backoff + circuit breakers | 2 weeks |\r\n| **DR Testing** | Never tested | Quarterly failover drills | Ongoing |\n\n***\n\n## 9. AI-Ready Architecture (Future State)\n\n<Note type=\"warning\" title=\"CJIS Compliance for AI\">\n  All AI models trained only on de-identified data. No CJI used in external AI services unless CJIS-compliant. All AI outputs require human review before use in CJIS systems. Document all AI decision-making per NIST AI Risk Management Framework.\n</Note>\n\n| Use Case | Complexity | CJIS Impact | Business Value |\r\n|----------|-----------|-------------|---------------|\r\n| **Enhanced Search** (AI Search) | Medium | None (non-CJI zone) | High - Faster case lookup |\r\n| **Form Extraction** (Document Intelligence) | Medium | Document-level review | High - Reduce manual entry |\r\n| **Report Writing Assist** (OpenAI) | High | Human review required | High - Officer productivity |\r\n| **Case Duration Prediction** (ML) | High | None (aggregated data) | Medium - Resource planning |\n\n***\n\n## 10. Implementation Roadmap\n\n| Phase | Focus | Key Deliverables | Dependencies |\r\n|-------|-------|-----------------|-------------|\r\n| **0** | Planning | Approved roadmap, answered questions, deep-dive sessions | Stakeholder alignment |\r\n| **1** | Security | Managed Identities, TDE/CMK, Private Link, CJIS addendum | Phase 0 complete |\r\n| **2** | Reliability | Geo-replication, DR plan, health monitoring, tested failover | Phase 1 foundations |\r\n| **3** | Operations | Distributed tracing, Sentinel SIEM, dashboards, alerting | Phase 2 health endpoints |\r\n| **4** | Performance | Redis cache, auto-scaling, load testing, API versioning | Phase 3 monitoring |\r\n| **5** | AI | Data segregation, anonymization pipeline, AI Search POC | Phase 1 + Phase 3 |\n\n***\n\n## Priority Recommendations\n\n### Immediate Actions (Next 30 Days)\n\n| # | Recommendation | Pillar | Effort | Business Impact |\r\n|---|----------------|--------|--------|----------------|\r\n| 1 | Implement Managed Identities for all services | Security | 2-3 weeks | Eliminate credential management, reduce breach risk |\r\n| 2 | Enable SQL TDE with Customer-Managed Keys | Security | 2 weeks | CJIS compliance, enhanced key control |\r\n| 3 | Configure Application Insights distributed tracing | Operations | 1 week | End-to-end visibility, faster troubleshooting |\r\n| 4 | Implement health endpoints and monitoring | Reliability | 1 week | Proactive issue detection, prevent outages |\r\n| 5 | Enable SQL Database geo-replication | Reliability | 2 weeks | Multi-region redundancy, disaster recovery |\r\n| 6 | Document DR procedures and RPO/RTO | Reliability | 1 week | Clear recovery processes, compliance |\n\n### Short-term (Next 90 Days)\n\n| # | Recommendation | Pillar | Effort | Business Impact |\r\n|---|----------------|--------|--------|----------------|\r\n| 7 | Implement Private Link for all PaaS services | Security | 3-4 weeks | Network isolation, eliminate public exposure |\r\n| 8 | Configure Azure Cache for Redis | Performance | 2 weeks | Faster response times, better user experience |\r\n| 9 | Implement API versioning strategy | Operations | 2 weeks | Safe evolution, backward compatibility |\r\n| 10 | Set up Microsoft Sentinel for SIEM | Security | 3-4 weeks | Advanced threat detection, automated response |\r\n| 11 | Configure auto-scaling rules | Performance | 2 weeks | Handle traffic spikes, maintain performance |\r\n| 12 | Implement storage lifecycle management | Operations | 1 week | Efficient data management, compliance |\n\n### Long-term (90+ Days)\n\n| # | Recommendation | Pillar | Effort | Business Impact |\r\n|---|----------------|--------|--------|----------------|\r\n| 13 | Evaluate AI use cases (non-CJIS data) | Innovation | 6-8 weeks | Enhanced analytics, predictive capabilities |\r\n| 14 | Implement Event Sourcing for audit trail | Reliability | 8-12 weeks | Complete audit history, forensic analysis |\r\n| 15 | Consider CQRS for read/write separation | Performance | 10-12 weeks | Optimized queries, scalable architecture |\r\n| 16 | Migrate to Premium Service Bus for geo-DR | Reliability | 2 weeks | Geographic redundancy, business continuity |\n\nVisit the [Priority Matrix](/docs/priority-matrix) to track implementation progress interactively.\n\n***\n\n## Appendix\n\n### A. RBAC Role Matrix\n\n<ZoomableImage src=\"/images/arch/User%20Role%20Access%20Management-2026-02-23-171421.png\" alt=\"User Role Access Management\" caption=\"RBAC architecture showing authentication flow, Conditional Access policies, and role-based permissions\" />\n\n#### Visual RBAC Flow and Access Control Architecture\n\nThe User Role Access Management diagram provides a comprehensive visualization of the role-based access control (RBAC) flow across all system layers, from Azure Active Directory (Entra ID) authentication through API Management authorization, application-level permission enforcement, and database-level row security. This end-to-end RBAC architecture implements defense-in-depth access control aligned with **CJIS Security Policy 5.6 (Personnel Security)** requirements, ensuring that access privileges are validated at every trust boundary and that no single layer's compromise can bypass authorization checks. The diagram directly maps to the RBAC Role Matrix table below, illustrating how organizational roles (Patrol Officer, Detective, Supervisor, Admin) translate into technical permissions across Azure infrastructure, application code, and data storage layers.\n\n**RBAC Flow Across System Layers:** The diagram traces the complete authentication and authorization path for a typical user request. **Layer 1 (Azure AD / Entra ID)**: Officers authenticate using their organizational credentials (`officer.smith@dakotacounty.gov`), with Multi-Factor Authentication (MFA) enforcement via Conditional Access policies that require Authenticator app approval and compliant device check (Azure AD Join or Intune MDM enrollment). Upon successful authentication, Entra ID issues a **JWT access token** containing user claims: `oid` (unique user object ID), `roles` (array of assigned application roles: `[\"PatrolOfficer\", \"CJIUser\"]`), `groups` (Azure AD security group memberships: `[\"RMS-DakotaSheriff-Users\"]`), and `tid` (tenant ID for multi-tenant isolation, referencing Section 1.6). This JWT token serves as the user's identity credential for all subsequent API calls. **Layer 2 (API Management)**: Azure APIM validates the JWT token signature against Entra ID's public signing keys (JWKS endpoint), verifies token expiration and issuer claims, and extracts the `roles` claim for initial authorization checks. APIM policies implement coarse-grained authorization: `<validate-jwt>` policy blocks requests without valid tokens, `<check-header>` policy requires TLS client certificates for API-to-API calls, and `<rate-limit-by-key>` policy enforces per-role quotas (patrol officers limited to 60 requests/minute, detectives allowed 200 requests/minute to support high-volume investigative queries). **Layer 3 (Application Tier)**: RMS App Service receives the validated JWT and performs fine-grained authorization using ASP.NET Core's `[Authorize(Roles = \"Detective\")]` attributes on controller actions. The application code inspects claims to enforce business rules: patrol officers can read only their own cases (`if (currentUser.OfficerId != case.CreatedByOfficerId) throw new ForbiddenException()`), while detectives can read all cases within their department (`if (currentUser.Department != case.Department) throw new ForbiddenException()`). **Layer 4 (Database Tier)**: Azure SQL Database enforces row-level security (RLS) policies that automatically filter query results based on the `Managed Identity` or `SQL User` principal executing the query. For tenant isolation, RLS appends `WHERE TenantId = SESSION_CONTEXT('TenantId')` to all SELECT statements, with the application setting session context after authentication. This layered access control ensures that even SQL injection vulnerabilities cannot bypass authorization—the database engine enforces access restrictions independently of application code.\n\n**Conditional Access Policy Flow and Enforcement Points:** The diagram details the Conditional Access policy evaluation chain that occurs during Entra ID authentication, implementing Zero Trust principles where every authentication request is evaluated against dynamic risk signals. Conditional Access policies are configured with **Grant Controls** (Require MFA, Require compliant device, Require hybrid Azure AD joined device) and **Session Controls** (Application enforced restrictions, Conditional Access App Control with Microsoft Defender for Cloud Apps monitoring). The evaluation flow follows a decision tree: (1) user initiates authentication → (2) Entra ID checks user's location (is the request originating from known Dakota County IP ranges or via VPN?) → (3) device compliance check (is the device Intune-managed with required security patches?) → (4) user risk score (has this account been observed in credential leak databases or exhibiting anomalous behavior patterns?) → (5) sign-in risk score (is this login attempt from an impossible travel scenario, e.g., Minneapolis 10 minutes ago, now Moscow?). If any risk signal exceeds thresholds (user risk: High, sign-in risk: Medium), Conditional Access **blocks** the authentication and requires security team remediation. If risk signals are acceptable, Conditional Access grants a session token with **token lifetime restrictions**: standard users receive 8-hour tokens requiring re-authentication each shift, while external partner accounts receive 1-hour tokens with reauthentication prompts. These session controls are visualized in the diagram as decision gates between Entra ID and the application layer, emphasizing that authentication is continuously evaluated rather than a one-time check.\n\n**Privileged Identity Management (PIM) Just-in-Time Access Workflow:** The diagram prominently features the **Azure PIM workflow** for administrative access to production resources, implementing time-bound, approval-gated privilege elevation. Standard operational procedures dictate that database administrators and infrastructure engineers hold **Eligible Role Assignments** (Contributor on RMS-Core-RG, Owner on RMS-Shared-RG) but do not have **Active Role Assignments** by default. When an engineer requires elevated access for incident response, they initiate a **PIM Activation Request** via the Azure Portal or PowerShell module, specifying: (1) requested role (Contributor on RMS-Core-RG), (2) duration (maximum 4 hours), (3) business justification (\"investigating P1 incident #12345 - API Gateway 502 errors\"), and (4) optionally attaching an approved Change Request ticket ID. The PIM workflow routes the request to designated **Approvers** (two infrastructure architects must approve), who receive notifications via Microsoft Teams and email with full context (requester identity, requested scope, justification, approval deadline). If approved within 15 minutes, PIM grants the requested role for the specified duration and logs the activation to Azure Activity Log and Microsoft Sentinel. After 4 hours, the role assignment **automatically expires**, requiring reactivation if additional access is needed. This JIT access model—critical for CJIS compliance—ensures that administrative privileges are time-limited, auditable, and require peer approval, drastically reducing the attack surface compared to permanent global administrator assignments. The diagram maps PIM activation to the **Admin** row in the RBAC Role Matrix below, showing that full access is gated by \"(via PIM)\" annotations.\n\n**Break-Glass Account Strategy for Emergency Access:** The architecture implements a **break-glass account** strategy for emergency scenarios where normal authentication mechanisms fail (Entra ID outage, MFA provider unavailable, Conditional Access policy misconfiguration locking out all administrators). Two break-glass accounts (`bg-admin-001@dakotacounty.onmicrosoft.com`, `bg-admin-002@dakotacounty.onmicrosoft.com`) are provisioned with **permanent Global Administrator** privileges and **excluded from all Conditional Access policies**. These accounts are secured with 64-character randomly-generated passwords stored in a physical safe (with dual-access control requiring two executives) and monitored continuously—any authentication event using break-glass accounts triggers **immediate P0 alerts** to the security team and executive leadership. The accounts are tested quarterly during disaster recovery drills to validate they remain functional and passwords are rotated annually with witness verification. The diagram shows break-glass accounts as a separate authentication path bypassing normal RBAC flows, with a direct line to resource access layers marked \"EMERGENCY ONLY - FULLY AUDITED\". This contingency access pattern balances business continuity (preventing lockout scenarios) with security rigor (extensive logging, physical security controls, quarterly accountability reviews).\n\n**CJIS Security Policy 5.6 Personnel Security Alignment:** The RBAC architecture directly implements CJIS requirements for personnel security: **5.6.1.1 (Personnel Screening)** verified through background check flags in Entra ID user profiles (`extensionAttribute1: \"BackgroundCheckCompleted-2025-06-15\"`), **5.6.2.1 (Training)** enforced via mandatory annual CJIS training completion records that gate access (Conditional Access policy: `if (user.trainingExpiry < today) deny()`), and **5.6.3.1 (Separation of Duties)** implemented via distinct roles with non-overlapping permissions (patrol officers cannot approve supervisor actions, analysts cannot access PII fields). The diagram cross-references these CJIS controls, annotating each access layer with the applicable policy section. Audit logs—captured at Entra ID sign-ins, APIM gateway requests, application-level authorization decisions, and SQL Database row access—provide **end-to-end forensic trails** for compliance audits, enabling investigators to reconstruct complete access histories: \"which users accessed Case #12345's evidence photos during the investigation period?\". These logs are exported to Azure Log Analytics, retained for 7 years per CJIS requirements, and protected with immutable storage (Azure Blob WORM policy) to prevent tampering.\n\n**Entra B2B Guest User Access Patterns:** The architecture supports **external partner access** via Entra ID B2B (business-to-business) collaboration, enabling prosecutors from Hennepin County or state investigators from BCA to access shared cases without creating duplicate user accounts. Guest users authenticate with their home organization's credentials (e.g., `@hennepin.us` Entra ID tenant) and receive **JIT guest invitations** scoped to specific cases or evidence items. The RBAC diagram illustrates the guest user flow: external user authenticates to Hennepin County Entra ID → cross-tenant token minted by Dakota County Entra ID (home tenant provides identity, resource tenant provides authorization) → guest user receives restricted permissions (Read-Only access to assigned cases, no download/print rights, watermarked evidence previews). Guest access sessions are limited to **2-hour lifetime** with explicit reauthentication after session expiry, and all guest user activities generate **high-severity audit events** logged to Microsoft Sentinel for security monitoring. The diagram maps guest users to the **External System** row in the RBAC Role Matrix, specifying \"API Scoped\" and \"Per Agreement\" constraints. This B2B integration pattern—replacing insecure email attachments or FTP file shares—provides secure, auditable, time-limited collaboration with external law enforcement agencies while maintaining tenant isolation (external users never receive native Entra ID accounts in Dakota County's directory).\n\n#### RBAC Role Matrix Table\n\n| Role | Cases | Evidence | Admin | Reports | Integration | CJIS Level |\r\n|------|-------|----------|-------|---------|-------------|------------|\r\n| **Patrol Officer** | Create/Read Own | Upload | None | Own Dept | None | CJI Access |\r\n| **Detective** | Read/Update All in Dept | Full Access | None | Dept-wide | None | CJI Access |\r\n| **Supervisor** | Full Dept Access | Full Access | User Mgmt | All Reports | Config | CJI Access |\r\n| **Admin** | All (via PIM) | All (via PIM) | Full | All | Full | CJI + Background Check |\r\n| **Analyst** | Read (de-identified) | None | None | Aggregated | None | Non-CJI |\r\n| **External System** | API Scoped | None | None | None | Specific API | Per Agreement |\n\n### B. CI/CD Pipeline Stages\n\n<ZoomableImage src=\"/images/arch/Azure%20DevOps%20CI_CD%20Pipeline-2026-02-23-170737.png\" alt=\"Azure DevOps CI/CD Pipeline Architecture\" caption=\"CI/CD pipeline showing build stages, approval gates, and deployment workflow\" />\n\n#### Deployment Pipeline Architecture and Infrastructure as Code\n\nThe Azure DevOps CI/CD pipeline diagram illustrates the comprehensive continuous integration and continuous deployment workflow that automates the delivery of application code and infrastructure changes to the CJN Dakota RMS environment. This pipeline architecture implements best practices for security scanning, approval gates, and automated rollback mechanisms to ensure production deployments meet CJIS compliance requirements while enabling rapid iteration velocity. The pipeline integrates with the Bicep Infrastructure-as-Code (IaC) toolchain referenced in Section 1's **Technology Stack** table (\"IaC: Bicep + Azure DevOps\"), providing a declarative, version-controlled approach to managing all Azure resources.\n\n**Branch Strategy and Merge Policies:** The diagram illustrates the Git branching model: developers work in **feature branches** (`feature/case-search-enhancement`), which merge to the **develop branch** via pull requests (PRs) that trigger automated CI builds, unit tests, and Static Application Security Testing (SAST) scans. Once validated in the develop environment, changes are promoted to the **main branch** through a gated PR requiring two code reviewer approvals and passing integration tests. The main branch automatically deploys to the **production environment** after manual approval from the release manager. Azure Repos enforces branch policies: direct commits to main or develop are blocked, PR authors cannot approve their own PRs, and all PRs must include linked Azure DevOps work items (user stories, bugs) for traceability. This branching strategy—based on GitFlow—prevents untested code from reaching production and maintains a clean audit trail for CJIS compliance (\"who deployed what, when, and why\").\n\n**Bicep IaC Deployment Pipeline Stages:** The infrastructure deployment pipeline (triggered by commits to the `infra/` directory) executes a multi-stage workflow visualized in the diagram: (1) **Bicep Compilation**: validate `.bicep` files with `az bicep build` to catch syntax errors, (2) **What-If Analysis**: run `az deployment group what-if` to preview infrastructure changes without applying them (e.g., \"This will create 3 new resources, modify 1 existing resource, and delete 0 resources\"), (3) **Peer Review Gate**: block deployment until two infrastructure engineers approve the what-if diff, (4) **Incremental Deployment**: execute `az deployment group create --mode Incremental` to apply only the delta changes, preserving existing resources not defined in Bicep templates, (5) **Smoke Tests**: validate critical resource configurations (e.g., verify App Service has VNet integration enabled, confirm Key Vault has purge protection), and (6) **Deployment Report**: publish a summary to the Azure DevOps pipeline run with links to Azure Portal resource groups. This IaC approach eliminates manual Azure Portal clicking, provides disaster recovery capability (re-deploy entire infrastructure from Git history), and enables infrastructure drift detection (comparing actual Azure state to Bicep templates via what-if analysis).\n\n**Approval Gates and Manual Intervention Points:** The diagram highlights three critical manual approval stages: **Stage Environment Deployment** (requires QA team sign-off after smoke tests pass), **Production Deployment** (requires release manager approval with mandatory 4-hour delay for business hours deployments), and **Infrastructure Changes** (requires dual approval from infrastructure architects for security-sensitive changes like NSG rule modifications or Private Link configurations). Each approval gate integrates with Azure DevOps Approvals API, which sends notifications to Microsoft Teams channels and enforces timeout policies (approvals expire after 24 hours, blocking stale deployments). For emergency hotfixes, the pipeline supports a \"fast-track\" path that bypasses the stage environment and deploys directly to production, but requires dual approval and generates a high-severity audit log entry for post-incident review. These approval gates balance deployment velocity (multiple deployments per day to dev/stage) with production stability (zero unplanned downtime in 6 months, per customer interviews).\n\n**Rollback Procedure and Version Tagging:** The pipeline implements automated rollback capability using Azure App Service deployment slots. Each production deployment first publishes to a **staging slot**, performs health checks (HTTP 200 responses, Application Insights availability tests, synthetic transaction validation), and then swaps the staging slot to production using `az webapp deployment slot swap`. If post-deployment health checks fail—indicated by error rate exceeding 1% within 5 minutes or Application Insights anomaly detection triggering—the pipeline automatically swaps back to the previous version within 60 seconds, restoring service. The diagram shows the version tagging strategy: every successful deployment tags the Git commit with the semantic version (`v2.3.15`) and deployment timestamp, creating an immutable release history. These tags enable point-in-time rollback: operators can redeploy any previous version by triggering the pipeline with a specific Git tag as the source. For infrastructure changes, Bicep templates are tagged similarly (`infra-v1.2.0`), and Azure Policy assignments enforce tagging requirements on all resources (\"all resources must have tags: Environment, Owner, CostCenter, Version\").\n\n**Infrastructure Drift Detection and Security Scanning Integration:** The pipeline includes a nightly scheduled job (visualized in the diagram as a separate pipeline trigger) that runs `az deployment group what-if` against production resource groups to detect configuration drift—manual changes made outside the CI/CD pipeline (e.g., an engineer adjusting NSG rules via Azure Portal). If drift is detected, the pipeline creates a high-priority Azure DevOps work item with a detailed diff and alerts the infrastructure team. This drift detection—combined with Azure Resource Graph queries that identify untagged or non-compliant resources—ensures the production environment matches the declarative Bicep templates. The diagram also highlights **Microsoft Defender for DevOps** integration, which scans Infrastructure-as-Code templates for security misconfigurations (e.g., storage accounts without encryption, Key Vaults with public network access enabled) and blocks deployments with critical findings. Defender for DevOps extends to application code scanning, integrating SAST tools (Checkmarx, SonarQube) and Software Composition Analysis (SCA) tools (WhiteSource, Snyk) to identify vulnerable dependencies (CVEs in NuGet packages) and code quality issues (SQL injection risks, hardcoded secrets). These security scans run in parallel during the CI build stage, failing the build if critical vulnerabilities are detected, thus preventing vulnerable code from reaching production.\n\n| Stage | Trigger | Gate | Failure Action |\r\n|-------|---------|------|---------------|\r\n| **CI Build** | PR or merge to main | Automated (compilation) | Block merge |\r\n| **Unit Tests** | CI pipeline | 90%+ coverage required | Block merge |\r\n| **SAST/Dep Scan** | CI pipeline | No critical vulnerabilities | Block merge |\r\n| **Dev Deploy** | Merge to main | Smoke tests pass | Alert team |\r\n| **Stage Deploy** | Manual promote | QA approval required | Block promotion |\r\n| **Prod Deploy** | Manual approval | Error rate \\< 1% | Auto-rollback |\r\n| **Infra Deploy** | PR to infra/ branch | Peer review + what-if | Block apply |\n\n### C. Monitoring Alert Thresholds\n\n| Metric | Warning | Critical | Response |\r\n|--------|---------|----------|----------|\r\n| **API Response Time** | > 2 seconds | > 5 seconds | Scale out App Service |\r\n| **Error Rate** | > 1% | > 5% | Page on-call, initiate rollback |\r\n| **CPU Utilization** | > 70% | > 90% | Auto-scale (configured) |\r\n| **DLQ Message Count** | > 5 | > 20 | Investigate failed integrations |\r\n| **SQL DTU Usage** | > 70% | > 90% | Scale database tier |\r\n| **Failed Authentications** | > 5/min | > 20/min | Sentinel auto-block IP |\r\n| **Service Bus Queue Depth** | > 1000 | > 5000 | Scale consumers |\r\n| **Certificate Expiry** | \\< 30 days | \\< 7 days | Auto-renew or page team |\n\n### D. Data Lifecycle Storage Tiers\n\n| Phase | SQL Tier | Blob Tier | Cache | Transition |\r\n|-------|----------|-----------|-------|------------|\r\n| **Active** (0-90 days) | General Purpose | Hot | Redis cached | Manual |\r\n| **Investigation** (90d - 2y) | General Purpose | Cool (auto at 90d) | Evicted | Lifecycle policy |\r\n| **Closed** (2-7 years) | Partitioned archive | Archive (auto at 730d) | None | Lifecycle policy |\r\n| **Disposal** (7+ years) | Purge (legal hold check) | Purge (WORM check) | N/A | Manual + approval |\n\n### E. Pillar Maturity Assessment\n\n| Pillar | Sub-Area | Current | Target | Gap | Priority |\r\n|--------|----------|---------|--------|-----|----------|\r\n| **Security** | Identity Management | 7/10 | 9/10 | 2 | High |\r\n| **Security** | Data Protection | 6/10 | 9/10 | 3 | Critical |\r\n| **Security** | Network Security | 7/10 | 9/10 | 2 | High |\r\n| **Security** | CJIS Compliance | 6/10 | 9/10 | 3 | Critical |\r\n| **Reliability** | Disaster Recovery | 4/10 | 9/10 | 5 | Critical |\r\n| **Reliability** | Health Monitoring | 5/10 | 8/10 | 3 | High |\r\n| **Reliability** | Resilience Patterns | 6/10 | 8/10 | 2 | Medium |\r\n| **Operations** | Observability | 5/10 | 8/10 | 3 | High |\r\n| **Operations** | CI/CD Maturity | 7/10 | 9/10 | 2 | Medium |\r\n| **Operations** | Incident Response | 4/10 | 8/10 | 4 | High |\r\n| **Performance** | Caching Strategy | 3/10 | 8/10 | 5 | High |\r\n| **Performance** | Auto-Scaling | 4/10 | 8/10 | 4 | Medium |\r\n| **Performance** | Database Optimization | 6/10 | 8/10 | 2 | Medium |\n\n### F. Azure Verified Modules (AVM)\n\n| Recommendation | AVM Module | Registry Path |\r\n|----------------|------------|---------------|\r\n| Managed Identities | User Assigned Identity | `br/public:avm/res/managed-identity/user-assigned-identity` |\r\n| SQL Database + TDE | SQL Server | `br/public:avm/res/sql/server` |\r\n| Private Endpoints | Private Endpoint | `br/public:avm/res/network/private-endpoint` |\r\n| Key Vault (HSM) | Key Vault | `br/public:avm/res/key-vault/vault` |\r\n| Service Bus | Service Bus Namespace | `br/public:avm/res/service-bus/namespace` |\r\n| Azure Functions | Web/Sites | `br/public:avm/res/web/site` |\r\n| API Management | APIM Service | `br/public:avm/res/api-management/service` |\r\n| Application Insights | Insights Components | `br/public:avm/res/insights/component` |\r\n| Redis Cache | Cache for Redis | `br/public:avm/res/cache/redis` |\r\n| Front Door | CDN Profile | `br/public:avm/res/cdn/profile` |\n\n### Resources\n\n* [Azure Well-Architected Framework](https://learn.microsoft.com/azure/architecture/framework/)\n* [CJIS Compliance in Azure](https://learn.microsoft.com/azure/compliance/offerings/offering-cjis)\n* [Azure Security Baseline](https://learn.microsoft.com/security/benchmark/azure/)\n* [AVM Bicep Registry Index](https://azure.github.io/Azure-Verified-Modules/indexes/bicep/)\n\n***\n\n*Last Updated: February 22, 2026*\n",
    "_searchMeta": {
      "cleanContent": "cjn dakota county - rms architecture date: february 20 2026 customer: cjn dakota county tim anderberg nathan noll project: records management system rms on azure commercial gcc executive summary well-architected framework maturity estimated maturity levels based on architectural review we recommend completing the azure well-architected review for a formal baseline pillar current target gap -------- --------- -------- ----- reliability 6 10 8 5 10 dr strategy geo-replication health probes security 7 10 9 10 managed identities private link always encrypted operational excellence 6 5 10 8 5 10 distributed tracing dashboards runbooks performance efficiency 6 10 8 10 caching auto-scaling query optimization overall 6 4 10 8 0 10 achievable with phased implementation architecture strengths paas-first approach minimizing operational overhead event-driven architecture using azure service bus with session support multi-tenant isolation through resource groups infrastructure-as-code with bicep cjis compliance awareness and security-first design microservices pattern with clear domain separation system architecture overview zoomableimage src images arch top-down-topology png alt cjn dakota rms system architecture caption cjn dakota rms system architecture - top-down topology showing resource groups services and security zones architecture analysis the system architecture diagram above illustrates the complete azure-based records management system deployed in azure commercial gcc to meet cjis compliance requirements this topology represents a mature microservices architecture with clear separation of concerns across four distinct resource groups each serving a specific domain within the rms ecosystem resource group separation strategy: the architecture implements a rigorous isolation model with dedicated resource groups for rms core case management and core record operations routing services external system integration and message distribution search services indexing and query operations and shared infrastructure sql database key vault service bus premium this separation enables independent lifecycle management granular rbac assignments and blast radius containment in the event of a security incident or operational failure cjis component identification: services marked with - cji annotations in the topology handle criminal justice information and are subject to cjis security policy 5 0 requirements these include all app services rms routing search azure functions signalr hub service bus topics and the sql database the diagram clearly delineates the trust boundary all cji components reside within the vnet-integrated application tier or are accessed via private endpoints ensuring no public internet exposure to sensitive law enforcement data service dependencies and data flow: the topology visualizes the hub-and-spoke pattern where the rms app service acts as the primary orchestrator coordinating with routing and search services through azure api management all compute services maintain direct connections to azure sql database for transactional consistency while key vault provides centralized secrets management using managed identity authentication eliminating stored credentials the service bus premium instances route sb and search sb enable asynchronous event-driven communication between services supporting session-based ordering per case or destination edge security and gateway layers: user requests traverse multiple security checkpoints before reaching application services azure front door provides global ddos protection web application firewall waf and tls 1 2 termination at the edge azure api management enforces rate limiting jwt validation and request throttling before forwarding traffic to backend services this defense-in-depth approach detailed further in the network topology security zones section below ensures that even if one security layer is compromised additional controls remain in place for detailed capability mapping refer to the key capabilities table below for technology rationale and version specifications see the technology stack section the network security implementation of this architecture is visualized in section 2 legend: cji criminal justice information blue data storage green compute yellow integration light blue edge technology stack layer technology purpose ------- ------------ --------- identity entra id b2b conditional access user authentication mfa edge cdn azure front door global load balancing ddos protection api gateway azure api management rate limiting throttling api versioning web app azure static web apps modern spa hosting compute azure app services functions microservices rms routing search messaging azure service bus premium event-driven architecture session-based messaging real-time azure signalr service live notifications and updates database azure sql database paas transactional data with tde encryption caching azure cache for redis distributed cache for performance secrets azure key vault premium customer-managed keys hsm-backed observability application insights azure monitor distributed tracing metrics logs security microsoft sentinel siem soar for threat detection network azure virtual network private link network isolation no public internet exposure iac bicep azure devops infrastructure as code ci cd pipelines key capabilities capability description ----------- ------------- secure data management cjis-compliant encryption at rest transit immutable audit logs data residency in azure gcc real-time operations signalr hub service bus for live officer notifications and event-driven processing enterprise integration 9 external systems mncis nibrs ecitations echarging mncrash maarc dps hennepin logis business continuity sql geo-replication automated backup point-in-time restore documented dr operational visibility distributed tracing custom workbooks sentinel siem proactive health monitoring performance at scale redis cache auto-scaling front door cdn microservices independent scaling ai-ready foundation cjis non-cjis data segregation anonymization pipeline azure ai search readiness 1 5 resource group architecture zoomableimage src images arch rms 20resource 20group-2026-02-23-165317 png alt rms resource group architecture caption resource group architecture showing organizational structure and deployment dependencies resource organization and deployment strategy the resource group architecture diagram illustrates the foundational organizational structure that underpins the cjn dakota rms deployment implementing azure s resource management best practices to enable granular access control independent lifecycle management and comprehensive cost allocation this architecture directly supports the multi-tenant isolation through resource groups strength highlighted in section 1 s architecture strengths establishing clear security boundaries that contain blast radius in the event of service compromise or operational failure resource group separation rationale: the architecture implements a four-tier resource group separation strategy with each group serving a distinct domain: rms-core-rg case management microservices core record operations and primary transactional workflows rms-routing-rg external system integration services message routing infrastructure and partner api gateways rms-search-rg indexing services query operations and azure cognitive search resources and rms-shared-rg azure sql database azure key vault premium service bus premium namespaces and redis cache shared infrastructure accessed by multiple microservices this separation enables independent deployment cycles: the search team can deploy index schema changes to rms-search-rg without risk of impacting core case management functionality in rms-core-rg the isolation also supports environment-specific scaling: during peak reporting periods operators can scale out routing services in rms-routing-rg without incurring cost increases in underutilized search services this resource group topology aligns with azure landing zone design patterns where workload isolation prevents noisy neighbor scenarios and enables targeted disaster recovery restore only the affected resource group during incident response tag strategy for cost allocation and operational tracking: the diagram highlights the comprehensive tagging strategy applied to all resources within each resource group: environment dev stage prod owner rms-team routing-team search-team costcenter cc-1001-rms cc-1002-integration cc-1003-search project cjn-dakota-rms compliancescope cjis-cji cjis-sensitive non-cjis dataclassification confidentialpii restricted public and deploymentversion infra-v2 1 0 these tags enable azure cost management chargeback reports that break down monthly azure spend by team environment and compliance scope allowing finance to invoice departments accurately and identify cost optimization opportunities e g dev environment in rms-routing-rg consuming 30 of total budget can we downscale non-production tiers the compliancescope tag feeds into azure policy compliance dashboards validating that all resources tagged as cjis-cji have mandatory security controls enabled encryption at rest private link network isolation diagnostic logging to log analytics the owner tag populates azure service health alert routing ensuring that when azure announces planned maintenance for sql database in rms-shared-rg the notification is automatically routed to the database administration team via microsoft teams webhook this metadata-driven operational model reduces manual coordination overhead and ensures critical alerts reach the right stakeholders resource dependencies and deployment order: the architecture diagram maps explicit dependency relationships between resource groups establishing a deterministic deployment sequence required for infrastructure-as-code iac orchestration phase 1: shared infrastructure rms-shared-rg must deploy first provisioning the azure sql database key vault service bus namespaces and virtual network subnets that subsequent phases depend on phase 2: microservices rms-core-rg rms-routing-rg rms-search-rg deploy in parallel once shared infrastructure is healthy referencing key vault secrets via managed identity and connecting to sql database via private endpoints each microservice app service retrieves its connection string from key vault during startup eliminating hardcoded credentials in application configuration this dependency model is codified in bicep templates using the dependson keyword and enforced in azure devops pipelines with sequential deployment stages detailed in appendix b: ci cd pipeline stages if a bicep deployment to rms-core-rg fails due to a missing sql database connection string the pipeline halts before attempting rms-routing-rg deployment preventing cascade failures and simplifying rollback procedures rbac boundary enforcement at resource group level: the diagram illustrates how azure role-based access control rbac assignments are scoped to resource groups implementing the principle of least privilege rms core team members hold contributor role on rms-core-rg granting full management access to app services functions and application insights within that group but zero access to resources in rms-routing-rg or rms-search-rg this prevents accidental misconfiguration or malicious lateral movement a compromised rms developer account cannot modify routing infrastructure or access search service api keys the platform team holds owner role on rms-shared-rg to manage key vault access policies sql database firewall rules and service bus topic configurations but only reader role on microservice resource groups visibility for troubleshooting no modification rights break-glass global administrators receive just-in-time owner access via azure privileged identity management pim with approval workflow and 4-hour time limits this rbac hierarchy directly implements cjis security policy 5 6 personnel security requirements by enforcing separation of duties and limiting blast radius of compromised credentials the complete rbac role assignments are detailed in appendix a: rbac role matrix which maps organizational roles patrol officer detective supervisor admin to azure resource permissions the resource group architecture provides the technical scaffolding for these access controls ensuring policy enforcement at the azure resource manager layer before requests reach application code lifecycle management advantages: the resource group structure enables precise control over deployment scaling and decommissioning workflows during major version upgrades the operations team can deploy rms v3 0 to a new parallel resource group rms-core-v3-rg while keeping rms-core-rg v2 5 running for a b testing and gradual traffic migration azure front door routes 10 of production traffic to the v3 resource group monitoring error rates and latency metrics before full cutover if anomalies are detected operators delete rms-core-v3-rg entirely reverting to the stable v2 5 deployment without complex rollback procedures this blue-green deployment pattern enabled by resource group isolation reduces deployment risk and supports the operational excellence pillar s recommendation for canary deployments for cost optimization non-production environments are scheduled for automatic resource group suspension: azure automation runbooks execute stop-azwebapp and set-azsqldatabase -requestedserviceobjectivename basic commands on rms-core-dev-rg resources every weeknight at 6 pm reducing compute costs by 70 during off-hours the resource group boundary provides a clean scope for bulk operations avoiding the complexity of targeting individual resources across a sprawling azure subscription 1 6 multi-tenant isolation strategy zoomableimage src images arch multi-tenant 20isolation 20model png alt multi-tenant isolation model caption multi-tenant isolation architecture with tenant-scoped access control and resource separation tenant provisioning and isolation architecture the multi-tenant isolation model diagram illustrates the comprehensive tenant onboarding resource isolation and data segregation strategy that enables the cjn dakota rms to support multiple law enforcement agencies dakota county sheriff city police departments regional task forces within a shared azure infrastructure while maintaining strict security boundaries this architecture balances operational efficiency shared infrastructure reduces per-tenant cost with regulatory compliance cjis security policy 5 10 1 2 mandates logical separation of cji data between agencies the model implements tenant-scoped access control at every system layer azure active directory groups api management policies application-level authorization and database row-level security ensuring that an officer from dakota county sheriff cannot access cases created by city police department even if application code vulnerabilities exist tenant onboarding process and provisioning workflow: the diagram details the automated tenant provisioning pipeline triggered when a new law enforcement agency contracts for rms services the workflow begins with a service request submitted via azure devops service management portal capturing tenant metadata agency name ori number billing contact primary administrator email azure region preference an azure devops pipeline orchestrates the provisioning sequence: 1 entra id group creation rms-dakotasheriff-users rms-dakotasheriff-admins with conditional access policies requiring mfa and compliant device enrollment 2 resource group deployment rms-dakotasheriff-rg dedicated to the tenant s application services following the resource group architecture defined in section 1 5 3 azure sql database schema provisioning dedicated schema dakota_sheriff within the shared multi-tenant sql database with row-level security policies enforcing tenant isolation 4 service bus namespace creation dedicated namespace sb-dakotasheriff-prod for tenant-specific message routing preventing cross-tenant message leakage 5 application configuration tenant-specific app settings in key vault: tenantid databaseschema servicebusnamespace billingcode and 6 admin user provisioning sending onboarding emails with initial credentials mfa enrollment qr code and training video links this automated workflow reduces tenant onboarding time from 5 days manual provisioning to 2 hours pipeline-driven eliminating human error and ensuring consistent security configurations across all tenants resource isolation guarantees and dedicated infrastructure: the architecture implements a hybrid isolation model combining shared infrastructure cost efficiency with dedicated tenant resources security boundaries each tenant receives a dedicated resource group for their application services tenant-specific app services azure functions and application insights instances ensuring compute isolation and preventing one tenant s traffic spike from throttling another tenant s performance for example if dakota county experiences a 10x load increase during a major incident their dedicated app service autoscales independently without impacting city police department s service availability however shared infrastructure services azure sql database with logical schema separation azure front door azure api management and shared key vault are provisioned once and serve all tenants to reduce operational overhead the diagram illustrates private endpoint connections from tenant-specific app services to the shared sql database with network traffic remaining within the azure backbone and never traversing public internet each tenant s app service is assigned a unique managed identity rms-dakotasheriff-appservice-identity which authenticates to sql database and is authorized to access only the dakota_sheriff schema via database-level permissions this identity-based access control ensures that even if a tenant s application code is compromised the attacker cannot escalate privileges to access other tenants data at the database layer performance isolation strategy and resource quotas: to prevent noisy neighbor scenarios where one tenant s resource consumption degrades another tenant s performance the architecture implements azure sql elastic pools with per-database dtu limits and service bus premium namespaces with dedicated messaging units per tenant the diagram shows dakota county sheriff s database allocated 50 dtus within the shared elastic pool supporting 500 concurrent users while smaller agencies receive 10 dtus supporting 100 concurrent users if dakota county s workload exceeds 50 dtus sql database throttles their queries rather than allowing them to starve other tenants resources similarly each tenant s service bus namespace is configured with a quota of 1 messaging unit 1 gb memory 1 vcpu preventing one tenant from monopolizing the shared service bus infrastructure azure api management enforces per-tenant rate limiting: dakota county sheriff is allocated 1 000 api requests minute while smaller agencies receive 200 requests minute these quotas are codified in api management policies using rate-limit-by-key with the tenant s ori number as the throttling key returning http 429 too many requests when limits are exceeded performance metrics are tracked in dedicated application insights instances per tenant enabling tenant-specific performance slas dakota county contract specifies p95 api latency 500ms measured using their dedicated app insights telemetry this granular performance isolation combined with autoscaling configurations that scale tenant resources based on their own workload ensures predictable performance and meets enterprise sla commitments billing and chargeback model with azure cost management tags: the diagram illustrates the cost allocation strategy that enables accurate per-tenant billing and chargeback to subscribing agencies all azure resources are tagged with tenantid e g dakota-sheriff city-police-dept and costcenter e g cc-2001-dakotasheriff feeding into azure cost management reports that break down monthly azure spend by tenant shared infrastructure costs sql database elastic pool base cost azure front door fees api management gateway instance are allocated proportionally based on each tenant s resource consumption metrics dtu-hours consumed api requests processed bandwidth transferred the billing pipeline executes monthly: 1 azure cost management api queries extract resource-level costs filtered by tenantid tag 2 proportional allocation algorithm distributes shared costs sharedcost tenantapirequests totalapirequests 3 invoice generation produces pdf invoices with cost breakdown tables compute storage bandwidth support per tenant and 4 automated azure automation runbook emails invoices to tenant billing contacts this transparent cost model ensures accurate chargeback and enables tenants to optimize their usage our evidence uploads cost 500 month can we compress images before upload for tenants with fixed-price contracts the cost reports serve as internal validation that actual azure consumption aligns with pricing assumptions data isolation at database level: the architecture implements defense-in-depth data isolation using multiple azure sql database security features row-level security rls policies enforce tenant filtering at the database engine level: when dakota county sheriff s app service queries select from cases sql server automatically rewrites the query to select from cases where tenantid dakota-sheriff preventing accidental cross-tenant data leakage even if application code omits the where tenantid clause separate database schemas per tenant dakotasheriff citypolicedept provide namespace isolation and granular permission management the rms-dakotasheriff-appservice-identity is granted execute permission on stored procedures in the dakotasheriff schema only with deny on all other schemas always encrypted columns protect sensitive fields ssn criminal history with tenant-specific column encryption keys ceks stored in azure key vault ensuring that even a database administrator with full sql server access cannot decrypt other tenants sensitive data the diagram maps these layered defenses showing how a compromised application identity must bypass multiple security controls managed identity authentication schema-level authorization rls policy enforcement always encrypted ceks before accessing another tenant s data a defense-in-depth approach aligned with cjis security policy 5 10 information systems security officer guidance on multi-tenant system design scalability considerations for multi-tenant architecture: the diagram addresses the scalability challenges inherent in multi-tenant systems where tenant count growth must not degrade performance or management overhead the current architecture supports 50 tenants within a single azure sql database using elastic pools with 500 dtu capacity and 20 tenants per service bus premium namespace using topic-per-tenant design with 320 topics supported per namespace when tenant count approaches these limits the provisioning pipeline automatically shards tenants across multiple infrastructure instances: tenants 1-50 route to sql database rms-sql-prod-001 tenants 51-100 route to rms-sql-prod-002 azure front door origin groups distribute traffic to region-specific deployments east us west us enabling geographic scale-out as tenant count grows into hundreds the architecture also supports tenant migration: if a high-volume tenant dakota county sheriff with 5 000 users outgrows shared infrastructure operators can promote them to a dedicated single-tenant deployment by provisioning a standalone azure sql database and redirecting their traffic via api management backend pool updates this hybrid model starting tenants on shared infrastructure for cost efficiency graduating high-growth tenants to dedicated infrastructure for performance guarantees balances operational simplicity with enterprise scalability the multi-tenant isolation strategy directly cross-references section 1 5 resource group architecture which provides the resource organization foundation enabling per-tenant resource groups and supports the multi-tenant isolation through resource groups architecture strength listed in section 1 network topology security zones zoomableimage src images arch network-security-zones png alt cjn dakota network security zones caption network security zones with defense-in-depth architecture and trust boundaries network security architecture the network topology diagram illustrates a defense-in-depth security model organized into six distinct trust zones each with progressively restrictive access controls this layered approach directly implements cjis security policy 5 5 4 network security requirements by establishing clear trust boundaries enforcing least-privilege access and ensuring all cji data remains within hardened audited network segments zone hierarchy and trust model: network traffic flows through a graduated trust model starting from the untrusted zone public internet passing through the dmz edge layer azure front door with waf ddos entering the semi-trusted api gateway zone azure api management with jwt validation and finally reaching the trusted application tier vnet-integrated app services or restricted data tier private endpoint-only data services the diagram s color coding red for untrusted yellow orange for edge gateway green for application tier and blue for data tier provides immediate visual clarity on security posture the management zone purple operates on a separate plane with dedicated rbac and privileged identity management pim controls private endpoint strategy: the diagram prominently shows private endpoint connections dark blue arrows between the application tier and data tier all paas services handling cji data azure sql database key vault premium service bus premium and blob storage are accessed exclusively via private endpoints within the snet-data 24 subnet this architecture eliminates public ip addresses for data services ensuring that even compromised application code cannot exfiltrate data directly to the internet all data plane traffic remains within the azure backbone network satisfying cjis advanced authentication requirements network security group nsg flow control: traffic between zones is governed by nsg rules applied at the subnet level the diagram illustrates filtered communication paths where api management can route requests to app services in snet-rms-app snet-route-app and snet-search-app subnets but lateral movement between application subnets is denied by default each microservice operates in a network-isolated blast radius preventing a compromised rms service from directly accessing search or routing infrastructure nsg flow logs are forwarded to azure monitor and microsoft sentinel for continuous security monitoring and anomaly detection zero trust network access ztna : the architecture implements zero trust principles by requiring explicit authentication and authorization at every layer even after passing front door waf and api management jwt validation application services authenticate to data resources using managed identities visualized as identity-based connections telemetry flows dotted lines from all services to azure monitor enable real-time detection of suspicious network patterns such as unexpected data access or lateral movement attempts this telemetry is aggregated in microsoft sentinel for security information and event management siem correlation with automated response playbooks for high-severity alerts the table below maps each zone to its trust level security controls and hosted services for operational procedures related to network security monitoring see the operational excellence section for application-level security patterns refer to section 6: defense-in-depth security zone trust level controls services ------ ------------- ---------- ---------- public internet untrusted n a end users external partners dmz edge low waf ddos tls termination front door dns api gateway semi-trusted rate limiting jwt ip filter api management application tier trusted nsgs vnet integration managed identity app services functions signalr data tier restricted private endpoints only encryption at rest sql key vault service bus blob management administrative rbac pim audit logging devops monitor sentinel request lifecycle step operation target latency sla ------ ----------- --------------- ----- 1 authentication entra id mfa 500ms 99 99 2-3 front door routing 50ms 99 99 4 api management processing 100ms 99 95 5-7 business logic db write 500ms 99 9 8 signalr broadcast 200ms 99 9 total end-to-end 1 5s 99 9 distributed tracing and monitoring zoomableimage src images arch azure 20application 20insights-2026-02-23-170842 png alt azure application insights distributed tracing caption application insights distributed tracing showing correlation ids and dependency tracking operational visibility and performance monitoring the application insights distributed tracing diagram visualizes the observability infrastructure that provides end-to-end visibility into request flows dependency tracking and performance anomaly detection across the entire cjn dakota rms distributed system this monitoring architecture is foundational to achieving the operational excellence targets defined in section 1 s maturity assessment enabling proactive incident response and data-driven capacity planning the implementation aligns with the phase 3 operations roadmap item to implement comprehensive distributed tracing with application insights and establishes the baseline metrics referenced in appendix c monitoring alert thresholds distributed tracing implementation across services: the diagram illustrates how application insights sdks embedded in each service rms app service routing app service search app service azure functions and apim gateway automatically capture telemetry data and propagate correlation context using the w3c trace context standard traceparent http header when an officer initiates a create case request the static web app generates a root traceid and includes it in the api call to azure front door front door forwards the trace header to apim which appends its own spanid and forwards to the rms app service the rms service creates child spans for each operation: key vault secret retrieval sql database insert service bus message publish and signalr notification broadcast these nested spans form a hierarchical dependency graph in application insights enabling operators to drill down from a slow api response e g 5-second latency to identify the specific bottleneck e g sql query took 4 8 seconds due to missing index this granular visibility unavailable in traditional monolithic application monitoring is essential for troubleshooting distributed system performance issues correlation id propagation through the request chain: the diagram emphasizes the role of correlationid synonymous with traceid as the thread connecting telemetry across disparate services and asynchronous workflows when the rms service publishes a casecreated event to service bus it includes the correlationid in message custom properties downstream consumers func-search-indexer func-mncis-router extract this property and set it as the application insights operationparentid linking their telemetry to the original user request this correlation extends even to external api calls: when func-mncis-router invokes the mncis soap endpoint application insights tracks the outbound http dependency with the same correlationid creating a complete trace from browser click to external system response operators can query application insights analytics with operationid to retrieve all telemetry events requests dependencies exceptions custom events for a single user transaction dramatically reducing mean time to resolution mttr for production incidents for cjis compliance correlation ids are also written to the sql audit log enabling cross-referencing between application insights performance data and regulatory audit trails dependency tracking configuration for sql service bus and redis: the diagram maps application insights automatic dependency tracking capabilities for azure paas services the microsoft applicationinsights dependencycollector nuget package intercepts ado net database calls azure service bus sdk operations and stackexchange redis cache commands capturing dependency telemetry without code modification for sql database application insights logs each query with duration row count success failure status and the full sql command text sanitized to remove parameter values per cjis requirements for service bus it tracks message publish operations with topic name message size and latency for redis it captures cache hit miss rates and command execution times this dependency telemetry feeds into application insights application map visualization shown in the diagram which renders real-time topology graphs with color-coded health indicators: green nodes 100ms average yellow nodes 100-500ms red nodes 500ms or high error rate the application map serves as the primary operational dashboard operators glance at the map to identify degraded services and receive drill-down links to diagnostic logs performance baselines and anomaly detection: the architecture implements application insights smart detection which uses machine learning to establish performance baselines for each service and alert on anomalies for example if the rms api s median response time is typically 350ms but suddenly spikes to 2 seconds smart detection automatically creates an incident with root cause analysis: sql database response time increased 6x possible query regression or missing index the diagram shows integration with azure monitor action groups which route anomaly alerts to microsoft teams channels for immediate triage and optionally trigger auto-remediation runbooks e g scaling out the app service plan smart detection also identifies dependency performance degradation mncis api calls from func-mncis-router are 3x slower than last week and memory leak patterns rms app service memory usage increasing 10 per hour these proactive alerts combined with the alert thresholds defined in appendix c enable the operations team to address performance regressions before they impact end users alert rules for critical metrics and forward references: the diagram highlights configured azure monitor alert rules that trigger on key performance indicators: api response time warning at 2s critical at 5s error rate warning at 1 critical at 5 service bus dlq depth critical at 10 messages and sql dtu utilization warning at 70 critical at 90 each alert rule specifies an action group with notification channels email sms teams webhook and severity levels sev 0-4 the monitoring strategy documented here references appendix c monitoring alert thresholds for complete threshold definitions and remediation procedures this comprehensive alerting framework directly supports the operational excellence pillar recommendations from section 1 addressing the maturity gap from 6 5 10 to 8 5 10 the distributed tracing capability is also identified as a phase 3 deliverable in the operations roadmap providing the telemetry foundation for future ai-driven incident prediction and automated root cause analysis event-driven processing 4 1 service bus topology zoomableimage src images arch azure 20service 20bus 20event 20flow-2026-02-23-165619 png alt azure service bus event flow architecture caption service bus topology with session-based ordering and pub sub pattern event-driven architecture analysis the service bus topology diagram illustrates a mature publish subscribe pub sub event-driven architecture that decouples microservices and enables asynchronous scalable processing of rms operations this design pattern is fundamental to achieving high availability fault tolerance and independent service scaling across the rms routing and search domains session-based ordering guarantees: the diagram highlights three primary topics case-events route-commands and search-index each configured with service bus sessions to guarantee fifo first-in first-out ordering within a session context for case-events the session key is caseid ensuring all events for case 12345 are processed sequentially even under high load similarly route-commands uses destinationid as the session key guaranteeing that all messages destined for mncis are processed in order preventing race conditions where a case update could arrive at the state system before the initial case creation this session-based ordering is critical for maintaining data consistency with external partners who expect deterministic event sequences topic subscription filtering pattern: the architecture leverages azure service bus s content-based filtering to route messages from a single route-commands topic to multiple specialized subscribers as shown in the diagram subscriptions like mncis-router nibrs-router ecite-router maarc-router and crash-router each apply a sql filter expression dest mncis dest nibrs etc to receive only relevant messages this fan-out pattern eliminates the need for hardcoded routing logic in publisher code the rms api service simply publishes a message with a destination property and service bus automatically delivers it to the appropriate consumer this design supports rapid addition of new integration partners without modifying existing services dead letter queue dlq monitoring and recovery: the diagram prominently features the error handling flow where failed messages are routed to a dead letter queue after 10 delivery attempts configured in the table below the dlq processor function continuously monitors the dlq depth and triggers an azure monitor alert when the count exceeds 10 messages indicating a systemic integration failure operational procedures for dlq triage involve inspecting message metadata exception details retry count in the azure portal correcting the root cause e g restoring a downed external api and manually resubmitting messages via the servicebusadministrationclient sdk this manual gate prevents automatic retry storms that could overwhelm partner systems microservices decoupling and independent scaling: by using service bus as an intermediary producer services rms api routing api scheduled jobs remain completely unaware of consumer implementations if the func-nibrs-sender function experiences a temporary outage messages accumulate in the nibrs-router subscription without blocking other integrations each consumer function scales independently based on queue depth enabling cost-optimized scaling where high-volume integrations mncis run on multiple instances while low-volume integrations mncrash use a single instance this architecture prevents monolithic bottlenecks and supports continuous deployment of individual services without system-wide downtime the service bus premium tier selected for this deployment provides essential enterprise features: geo-disaster recovery private link network isolation see section 2 dedicated compute capacity 1 messaging unit 1 vcpu and larger message sizes 100 mb vs 256 kb in standard for configuration details see the property table below for resilience patterns applied to external api calls within consumer functions see section 5: external integrations property value rationale ---------- ------- ----------- tier premium geo-dr private link dedicated resources sessions enabled per topic ordered processing per case destination max delivery 10 attempts exponential backoff before dlq lock duration 5 minutes sufficient for external api calls ttl 24 hours prevent stale message processing dlq monitoring alert on count 10 immediate ops notification 4 2 rms event publishing zoomableimage src images arch azure 20rms 20services 20event-2026-02-23-165517 png alt azure rms services event publishing caption event publishing architecture showing event types schemas and correlation strategy event publishing architecture the rms event publishing diagram illustrates the comprehensive event taxonomy and publishing mechanisms used across the rms routing and search microservices to maintain eventual consistency and enable reactive workflows throughout the distributed system this architecture implements the event sourcing pattern for critical state changes creating an immutable audit trail that can reconstruct system state at any point in time and support future ai ml pipelines for predictive analytics event type classification and schema design: the diagram categorizes published events into four primary types: case-events casecreated caseupdated casestatuschanged evidenceattached route-commands submittomncis sendnibrsreport filecitation search-index indexcase updatesearchdocument deletefromindex and audit-events useraction systemaction compliancelog each event type follows a standardized json schema with required properties: eventid guid for deduplication eventtype fully qualified type name aggregateid caseid evidenceid etc timestamp iso 8601 utc correlationid distributed tracing identifier userid actor for cjis audit payload strongly-typed domain data and schemaversion semantic versioning for backward compatibility this schema standardization enables generic event processing infrastructure consumers can deserialize the envelope without knowing payload specifics logging correlation ids before payload parsing for observability correlation id strategy for distributed tracing: every event published to service bus includes a correlationid property that propagates through the entire processing chain enabling end-to-end request tracing across microservice boundaries when an officer submits a case the rms api generates a root traceid w3c trace context standard and embeds it in the case-events message downstream consumers search indexer mncis router extract this correlationid attach it to their application insights telemetry and include it in subsequent service bus messages this creates a complete dependency graph in application insights allowing operators to visualize the full event cascade triggered by a single user action for example querying application insights for correlationid abc123 reveals: api request case-events published search indexer invoked route-commands published mncis function called mncis api response with timestamps and latencies at each hop this tracing capability is essential for troubleshooting production incidents and identifying bottlenecks in the event processing pipeline event versioning for backward compatibility: the diagram highlights the schemaversion property e g casecreated_v2 used to implement zero-downtime schema evolution when a new property is added to the casecreated event payload e g adding officerbadgenumber for enhanced audit logging publishers increment the version to v2 while consumers maintain support for both v1 and v2 schemas using polymorphic deserialization older consumers that don t recognize v2 fall back to processing the common v1 properties preventing breaking changes during rolling deployments this versioning strategy combined with azure service bus s native support for message properties enables the rms team to evolve the event schema incrementally without coordinating simultaneous deployments of all producer and consumer services the architecture decision record adr for this pattern references martin fowler s event versioning guidance and prioritizes additive changes new optional properties over breaking changes renaming removing properties publisher pattern implementation across services: the diagram maps event publishing responsibilities to specific services: rms api service publishes case-events and audit-events after successful database writes using the outbox pattern to guarantee at-least-once delivery even if service bus is unavailable routing api service publishes route-commands based on configuration rules new felony cases automatically route to mncis and search service publishes search-index events when document updates are required each service uses the azure service bus sdk s servicebusclient with connection strings retrieved from key vault via managed identity publishing to dedicated topics with explicit partition keys for case-events the partition key is caseid 10 to distribute load across 10 partitions this topic-per-event-type design rather than a single monolithic event bus enables granular access control the search service can publish to search-index but cannot publish to route-commands reducing blast radius in the event of a compromised service 4 3 event consumption and processing zoomableimage src images arch event 20processing 20and-2026-02-23-170025 png alt event processing and consumption architecture caption event consumption architecture with azure functions showing error handling and idempotency patterns consumer architecture and processing guarantees the event consumption and processing diagram illustrates how azure functions consume messages from service bus subscriptions implementing robust error handling idempotency patterns and performance optimization strategies to guarantee exactly-once processing semantics for critical workflows this architecture balances throughput requirements processing 50 000 events day during peak hours with reliability requirements zero data loss deterministic retry behavior while maintaining cjis audit compliance for all cji event processing azure function triggers and bindings configuration: the diagram shows dedicated azure functions for each event subscription: func-case-processor consumes case-events subscription func-mncis-router consumes mncis-router subscription func-search-indexer consumes search-index subscription and func-audit-logger consumes audit-events subscription each function uses the servicebustrigger attribute with session-enabled configuration to process messages sequentially per session: servicebustrigger case-events case-processor issessionsenabled true the host json configuration specifies critical performance parameters: maxconcurrentsessions 8 parallel session processors per instance maxconcurrentcalls 1 sequential processing within a session for ordering guarantee prefetchcount 32 message pre-fetching for reduced latency and autocompletemessages false explicit completion control for error handling this configuration strikes a balance 8 concurrent sessions provide horizontal scaling while maxconcurrentcalls 1 ensures fifo ordering within each case error handling and retry patterns with exponential backoff: the diagram details the multi-layered error handling strategy when a function encounters a transient exception network timeout sql deadlock external api 503 the service bus redelivery mechanism automatically retries the message with exponential backoff: 1st retry after 10 seconds 2nd after 40 seconds 3rd after 90 seconds backoff multiplier 2 0 capped at 5 minutes the function code wraps external calls in polly policies see section 5 code examples for circuit breaker implementation to handle partner api failures gracefully for poison messages that fail after 10 retry attempts such as a malformed json payload or a permanent business rule violation the message is automatically routed to the dead letter queue dlq where the func-dlq-processor function logs the failure details to application insights with full context stack trace message properties retry history and sends an alert to the operations team via azure monitor action group this graduated retry strategy prevents transient failures from triggering dlq alarms while ensuring persistent errors receive immediate attention performance and scaling considerations: the architecture leverages consumption plan for low-traffic functions dlq processor audit logger to minimize costs but deploys high-throughput consumers case processor mncis router on premium plan for guaranteed compute capacity and faster cold start times 1 second vs 10 seconds on consumption plan premium plan functions also benefit from vnet integration for private link connectivity to service bus avoiding public internet traversal and from always-ready instances minimum 1 instance pre-warmed scaling to 20 instances under load the diagram shows azure functions scaling logic: when service bus queue depth exceeds 1 000 messages per instance the platform automatically provisions additional function instances up to the configured maximum of 20 this elastic scaling combined with service bus premium s dedicated messaging units ensures the system maintains sub-second processing latency even during incident spikes e g 500 officers simultaneously creating cases after a major event idempotency patterns for exactly-once processing guarantee: to prevent duplicate processing when service bus retries a message each function implements idempotency checks using distributed caching before processing a casecreated event func-case-processor queries azure cache for redis with the key processed: eventid ttl 7 days matching service bus retention if the key exists the function immediately completes the message without re-execution logging a duplicate message detected telemetry event for new messages the function performs a two-phase commit: 1 write to redis cache with the processing status in-progress 2 execute business logic and persist to sql database 3 update redis to completed and complete the service bus message if the function crashes between steps 1 and 3 service bus redelivers the message but the redis check detects in-progress status and safely completes the message the sql write may have succeeded before the crash this idempotency pattern combined with sql database s deterministic stored procedures checking for existing caseid before insert guarantees exactly-once processing semantics without requiring distributed transactions or two-phase commit protocols across service bus and sql database message session handling for ordered processing: the diagram emphasizes service bus sessions as the mechanism for maintaining event ordering within a case context each case-events message includes a sessionid property set to the caseid value service bus guarantees that all messages with the same sessionid are delivered to a single function instance in fifo order preventing race conditions where a caseupdated event could be processed before the corresponding casecreated event the function code accepts the session using imessagesession acceptsessionasync sessionid processes messages sequentially and releases the session lock upon completion this session-based ordering is critical for maintaining referential integrity in the search index if caseupdated processed before casecreated the search indexer would attempt to update a non-existent document for non-case events e g system health checks messages are published without a sessionid allowing parallel processing across all available function instances for maximum throughput external integrations zoomableimage src images arch api 20gateway 20to 20outbound-2026-02-23-165702 png alt api gateway to outbound external systems caption external integration architecture showing inbound outbound flows and resilience patterns external integration architecture the external integrations diagram maps the complete data flow for bidirectional communication between the cjn dakota rms and nine external law enforcement judicial and public safety systems this architecture handles both inbound data court returns from mncis mobile citations from citation app and outbound data case submissions crash reports fbi reporting implementing rigorous resilience patterns to ensure guaranteed delivery even when partner systems experience downtime integration gateway and security boundary: all external traffic enters through the azure api management apim gateway which serves as the single ingress egress point for partner communications the diagram highlights apim s critical security functions: tls 1 2 1 3 encryption for data in transit jwt token validation for authenticated partners ip allowlist filtering restricting mncis to known state ip ranges and comprehensive request response logging for audit trails apim policies also enforce rate limiting e g 100 requests minute per partner and throttling to protect backend services from denial-of-service scenarios this gateway isolation ensures that external partners never obtain direct network access to rms application or data tiers inbound processing pipeline: the diagram shows two primary inbound flows: mncis inbound court returns charging decisions case status updates and citation app mobile-generated traffic citations inbound requests are routed from apim to the route _in service which performs schema validation deduplication checking for duplicate submission ids and message transformation into the internal rms domain model the processing pipeline includes scheduled jobs mn crash job maarc job cad job that poll external endpoints for updates when push-based webhooks are unavailable these jobs publish processed data to the rms service core which persists entities to the rms database and triggers downstream workflows via service bus see section 4 outbound routing via route2dest service: the route2dest distribution service highlighted in purple acts as the central hub for all outbound integrations consuming messages from the route-commands service bus topic and invoking partner-specific azure functions the diagram illustrates six outbound destinations: mncis out state judicial system ecitations out citation filings echarging out prosecutor charging documents mncrash out traffic crash reports maarc out multi-agency records consortium and nibrs out national incident-based reporting system for fbi each integration implements the resilience patterns detailed in the integration resilience patterns subsection below exponential backoff retry 3 attempts with 2 n second delays circuit breaker opens after 3 consecutive failures for 1 minute cooldown and dead letter queue routing after 10 total failures cross-system data lineage and audit compliance: the architecture maintains end-to-end traceability for all external data exchanges every message flowing through route2dest includes distributed tracing headers w3c trace context standard that correlate with application insights telemetry enabling operators to trace a case submission from the officer s browser through the rms api service bus route2dest and ultimately to the mncis api response this telemetry is critical for troubleshooting integration failures e g why didn t case 12345 reach mncis and for regulatory compliance cjis security policy 5 4 1 requires audit logs for all cji disclosures failed messages in the dead letter queue are logged with full context exception stack traces retry count original message payload for forensic analysis for detailed partner-specific protocols and data formats refer to the external systems table below for code examples demonstrating polly-based retry and circuit breaker policies see the integration resilience patterns tab section this integration architecture directly supports the multi-agency collaboration capabilities listed in section 1 s key capabilities table external systems system direction data type protocol -------- ----------- ----------- ---------- mncis bidirectional case submissions court returns https api nibrs outbound fbi crime reporting monthly annual nibrs xml ecitations outbound citation filings https api echarging outbound charging documents to prosecutors https api mncrash outbound crash reports https api maarc bidirectional multi-agency shared records https api dps outbound dept of public safety data https api hennepin county bidirectional county data exchange https api logis bidirectional shared government it services https api citation app inbound mobile-generated citations https api integration resilience patterns pattern implementation behavior --------- --------------- ---------- retry exponential backoff polly waitandretryasync 3 retries at 2 n seconds circuit breaker polly circuitbreakerasync opens after 3 failures 1 min break guaranteed delivery service bus topics 10 retry attempts before dlq dead letter queue dlq processor function alert on count 10 manual reprocess store and forward fallback mechanism persist locally if partner unavailable defense-in-depth security security controls matrix layer control cjis mapping status ------- --------- ------------- -------- identity entra id mfa 5 6 2 2 implemented identity fips 140 authenticators 5 6 2 2 needs validation identity pim jit access 5 5 2 recommended perimeter waf v2 rules 5 10 4 implemented perimeter ddos protection 5 10 4 implemented network private link 5 5 4 recommended network vnet nsgs 5 5 4 implemented application jwt validation 5 5 2 implemented application rate limiting 5 10 4 implemented compute managed identities 5 6 1 recommended data tde cmk 5 10 1 recommended data always encrypted 5 10 1 recommended monitoring sentinel siem 5 4 1 recommended monitoring audit logging 7 yr 5 4 partial security recommendations managed identity implementation zoomableimage src images arch managed 20identity-2026-02-23-165751 png alt managed identity authentication architecture caption managed identity architecture showing credential-less authentication and rbac role assignments system-assigned vs user-assigned identity decision tree: the diagram presents the architectural decision framework for selecting between system-assigned managed identities lifecycle tied to a specific resource instance and user-assigned managed identities independent lifecycle reusable across resources for the rms architecture the recommendation follows the principle illustrated in the diagram s decision tree: use system-assigned identities for single-purpose ephemeral resources like azure functions where each function s identity permissions are tightly scoped to its specific integration partner e g the func-mncis-sender function has only servicebussender role on the route-commands topic nothing more and use user-assigned identities for shared infrastructure components like the rms api app service and routing api app service that both require identical rbac permissions to azure sql database key vault and service bus the diagram shows how a single user-assigned identity named id-rms-shared- environment can be assigned to multiple app services reducing rbac management overhead from n individual role assignments per service to a single centralized role assignment per target resource migration path from key vault stored credentials to managed identities: the architecture diagram illustrates the phased migration strategy referenced in priority recommendation 1 in section 10 for eliminating stored credentials currently held in azure key vault the current state visualized in the diagram s before pane shows app services retrieving connection strings from key vault secrets azurewebjobsstorage sqlconnectionstring servicebusconnectionstring at startup and passing them to sdk clients like servicebusclient this pattern while encrypted at rest still involves credentials existing in memory and configuration creating breach risk if application code is compromised or misconfigured logging exposes connection strings the target state shown in the after pane demonstrates managed identity-based authentication where the servicebusclient constructor receives a defaultazurecredential token provider instead of a connection string the azure sdk automatically obtains an access token from the azure instance metadata service imds using the resource s managed identity authenticates to service bus and handles token refresh without any secrets ever touching application code the diagram notes that this migration has zero breaking changes to business logic only the infrastructure-as-code bicep templates and authentication initialization code require modification rbac role assignments per service shown in diagram: the diagram meticulously documents the least-privilege rbac role assignments required for each microservice when using managed identity authentication directly addressing the stored credentials security gap identified in the executive summary the rms core api managed identity receives: key vault crypto user to retrieve always encrypted column encryption keys without managing secrets azure sql database contributor to execute sql queries via azure ad authentication and azure service bus data sender to publish case events to the case-events topic the routing service managed identity receives: azure service bus data receiver on the route-commands subscription and azure service bus data sender for publishing completion acknowledgments back to status topics the search indexing functions receive read-only roles: storage blob data reader for accessing case documents and search index data contributor for updating azure ai search indexes this granular role decomposition annotated in the diagram with resource scopes ensures that even if a service is compromised through an application vulnerability the attacker gains only narrowly scoped permissions a compromised search function cannot modify sql data or access encryption keys limiting blast radius credential rotation elimination benefits and aad token lifecycle: the diagram highlights one of managed identity s strongest security advantages: automatic credential rotation handled entirely by the azure platform unlike connection strings or service principal client secrets that require 90-day rotation workflows with associated risk of expired credentials causing outages managed identity access tokens are short-lived 1-hour validity and automatically refreshed by the azure sdk s credential chain without application involvement the diagram illustrates the token acquisition flow: 1 application code calls servicebusclient sendmessageasync 2 azure sdk s defaultazurecredential detects it s running in an azure managed environment 3 sdk queries the instance metadata service imds endpoint http: 169 254 169 254 metadata identity oauth2 token with the resource s managed identity 4 imds authenticates the caller via azure fabric identity proof and returns a signed jwt token with aud claim matching service bus s resource id 5 sdk includes the token in the authorization: bearer header of service bus api calls this entire flow completes in milliseconds when the token nears expiration 50 minutes into its 60-minute lifetime the sdk proactively refreshes it using the same imds mechanism this lifecycle management eliminates the operational burden of maintaining credential rotation runbooks and removes the risk of developers hardcoding secrets in application configuration temporarily during troubleshooting zero secrets in configuration advantage and alignment with priority recommendation 1: as emphasized in the diagram s benefits callout and explicitly referenced in section 10 s priority recommendations table priority 1: implement managed identities for all services - 2-3 week effort - eliminate credential management reduce breach risk the managed identity architecture achieves the security ideal of zero secrets in application configuration the diagram contrasts the current key vault-based approach where appsettings json contains keyvaulturi : https: kv-rms-prod vault usgovcloudapi net still a piece of infrastructure knowledge with the managed identity approach where configuration contains only servicebusnamespace : sb-rms-prod servicebus usgovcloudapi net a non-sensitive routing target even if an attacker gains read-access to application configuration files or environment variables they obtain zero authentication materials this architecture satisfies cjis security policy 5 10 1 s requirement for advanced authentication by eliminating static credentials entirely replacing them with cryptographically signed identity proof that cannot be exfiltrated or replayed outside the azure environment the migration to managed identities is the single highest-impact security improvement the rms architecture can implement and the diagram provides the technical blueprint for executing this transformation across all 15 compute and data services in the topology cjis compliance gaps cjis policy area status priority action required --- --- --- --- 5 10 1 encryption in use missing critical evaluate azure gov cjis management agreement 5 12 personnel security missing critical fingerprint background checks for cji access 5 6 2 2 fips 140 authenticators missing critical document fips 140 compliance of all mfa methods cjis security addendum missing critical sign with microsoft 5 4 audit logging partial high extend to all cji touchpoints 7 year retention 5 5 access control partial high session lock account lockout thresholds 5 2 security awareness training missing high formal training program 5 7 5 10 4 configuration management missing high baseline configs change control 5 15 system integrity missing high vulnerability scanning integrity monitoring customer lockbox missing high control microsoft engineer access azure policy cjis initiative missing medium deploy built-in cjis compliance policies 5 1 information exchange agreements missing medium formal agreements with external systems 5 3 incident response partial medium formal plan with exercise schedule cjis data classification boundaries data type classification encryption access control retention ----------- --------------- ------------ --------------- ----------- case records pii cji - restricted tde always encrypted background-checked personnel per agency policy evidence files cji - restricted double encryption worm chain of custody verified case lifecycle 7 years audit logs cji - controlled immutable storage read-only after write 7 years integration messages cji - in transit tls 1 2 sb encryption managed identity auth ttl-based aggregated statistics non-cji standard encryption analyst role 5 years ai training data non-cji standard encryption data scientist role model lifecycle cjis data anonymization pipeline zoomableimage src images arch cjis 20data 20anonymization-2026-02-23-170447 png alt cjis data anonymization architecture caption data anonymization pipeline showing pii removal k-anonymity enforcement and re-identification risk assessment pii removal and k-anonymity implementation: the diagram above illustrates the comprehensive data anonymization pipeline that enables safe use of law enforcement data for analytics and ai ml applications without violating cjis security policy 5 10 requirements the pipeline implements a multi-stage de-identification process starting with field-level pii scrubbing removing direct identifiers such as names ssn date of birth addresses and phone numbers followed by k-anonymity enforcement with a threshold of k 5 meaning each anonymized record must be indistinguishable from at least 4 other records when considering quasi-identifiers like age range geographic region and case type this statistical disclosure control technique visualized in the diagram s aggregation layer prevents re-identification attacks where an adversary might correlate anonymized data with external datasets to uncover individual identities re-identification risk assessment methodology: the pipeline includes a critical validation stage that performs quantitative re-identification risk assessment before any data exits the cjis restricted zone as shown in the diagram s validate component this assessment calculates the probability that a motivated attacker with access to public records databases could successfully link an anonymized record back to a specific individual the methodology incorporates prosecutor and public defender risk models assuming adversaries with moderate computational resources and access to county property records voter registrations and court dockets and applies a threshold of 0 05 re-identification probability per record records failing this threshold are either further generalized e g converting specific ages to 5-year age bands or excluded from the non-cji dataset entirely this approach directly implements the principles outlined in nist sp 800-188 de-identifying government datasets cjis security policy 5 4 audit requirements compliance: every execution of the anonymization pipeline generates immutable audit logs stored in azure monitor log analytics with 7-year retention documenting the transformation applied to each source record the k-anonymity scores achieved the re-identification risk scores calculated and the identity of the data scientist or analyst who initiated the pipeline run the diagram shows these audit trails flowing to a dedicated pipeline audit log store that is subject to quarterly cjis compliance reviews this audit capability satisfies policy 5 4 1 s requirement to log all cji disclosures treating the anonymization pipeline as a controlled disclosure mechanism the logs also support forensic investigations if downstream ai systems exhibit biased or problematic behavior analysts can trace back to the original data selection and transformation logic to identify root causes data masking layers and ai-ready architecture integration: the architecture implements a defense-in-depth approach to data protection with multiple masking layers visible in the diagram row-level filtering excludes sensitive case types e g active witness protection cases juvenile records with court-ordered sealing before any transformation occurs field-level redaction removes narrative text fields containing unstructured pii that automated scrubbing might miss e g officer notes mentioning spoke with john smith s mother aggregation-level suppression prevents small-cell disclosures by suppressing any statistical aggregates derived from fewer than 10 source records this multi-layered approach combined with the one-way data flow architecture cji anonymization non-cji with no reverse path creates a robust trust boundary as referenced in section 9 ai-ready architecture this anonymization pipeline is the sole mechanism for populating ai ml training datasets ensuring that azure openai services and azure ai search indexes in the non-cji zone never have direct access to raw criminal justice information eliminating compliance risk while enabling advanced analytics capabilities disaster recovery topology component rpo data loss rto downtime replication failover ----------- ---------------- ---------------- ------------- ---------- sql database 5 seconds 60 minutes sync geo-replication automatic failover group service bus metadata only 10 minutes geo-dr pairing manual alias switch blob storage 15 minutes 1 hour ra-grs manual dns update key vault manual backup 2 hours backup restore manual restore app services n a stateless 15 minutes warm standby dns switch scale up front door n a 5 minutes global built-in automatic health probes azure sql failover group configuration zoomableimage src images arch azure 20sql 20failover 20and-2026-02-23-170534 png alt azure sql failover and geo-replication architecture caption azure sql failover group configuration with active-passive replication and automatic failover failover group architecture and active-passive configuration: the diagram illustrates the azure sql database failover group implementation that provides automated geo-redundancy for the rms transactional database the architecture deploys an active-passive configuration with the primary database in us gov virginia handling all read write traffic and a continuously synchronized secondary replica in us gov arizona maintained in hot standby mode unlike active-active configurations that distribute writes across regions which would introduce complex conflict resolution for case management transactions the active-passive model ensures strong consistency every committed transaction on the primary is synchronously replicated to the secondary before the commit acknowledgment is returned to the application guaranteeing zero data loss rpo 0 for committed transactions the diagram shows the failover group listener endpoints that abstract the physical database locations from application connection strings enabling transparent failover without application code changes achieving rpo 5 seconds with continuous data replication: the rpo target of 5 seconds documented in the table above represents the maximum age of the most recent transaction that could be lost during an unplanned primary region outage azure sql s active geo-replication technology visualized in the diagram s replication flow achieves this aggressive rpo through a redo log shipping mechanism that streams transaction log records from the primary to the secondary over the azure backbone network with typical latency under 1 second the diagram highlights the asynchronous commit mode used to balance data durability with application performance transactions commit on the primary after writing to local durable storage then replication to the secondary occurs in the background this approach prevents cross-region network latency approximately 50ms between virginia and arizona from blocking user-facing transactions in the rare scenario where the primary region fails before recent transactions replicate the failover process implements potential data loss detection alerting operators to the last successfully replicated transaction timestamp so business users can manually reconcile any lost case updates manual vs automatic failover decision tree: the diagram presents a critical architectural decision point: configuring the failover group for automatic failover versus manual failover automatic failover recommended in the diagram with a 60-minute grace period triggers when the primary database becomes unreachable for longer than the configured detection timeout azure s health probe system continuously monitors database availability every 30 seconds and after 4 consecutive failures 2 minutes of downtime begins a 60-minute waiting period to distinguish between transient network issues and genuine regional outages if the primary remains unavailable after this grace period the system automatically promotes the secondary to primary updates dns records for the failover group listener and sends azure monitor alerts to the operations team manual failover alternatively requires an authorized operator to explicitly invoke the failover command via azure portal cli or automation runbook the diagram recommends automatic failover for production rms environments to minimize downtime during after-hours or weekend regional outages but notes that manual failover provides greater control for planned maintenance scenarios where operators want to validate application state before cutting over connection string handling and read write endpoint strategy: application services rms api routing service search service use the failover group listener connection strings shown in the diagram rather than connecting directly to specific database servers the architecture provisions two listener endpoints: a read write listener e g rms-failover-group database usgovcloudapi net that always points to the current primary database and automatically updates during failover and a read-only listener e g rms-failover-group secondary database usgovcloudapi net that explicitly targets the secondary replica for offloading read-intensive reporting queries the diagram illustrates how the rms core api uses the read write listener for transactional case management operations while the reporting dashboard and analytics queries connect to the read-only endpoint to prevent report generation from impacting officer productivity during failover the read write listener s dns record is updated within 5 minutes contributing to the 60-minute total rto and application connection pools automatically reconnect to the newly promoted primary this listener-based approach eliminates the need for application code to implement region-aware routing logic or maintain multiple connection string configurations per environment rpo rto objectives and recovery prioritization zoomableimage src images arch rpo_rto 20objectives 20and-2026-02-23-170624 png alt rpo rto objectives and tier-based recovery caption recovery objectives with tier-based prioritization for business continuity business process mapping to recovery objectives: the diagram illustrates the comprehensive recovery point objective rpo and recovery time objective rto targets mapped to critical rms business processes derived from stakeholder interviews with patrol officers detectives dispatch supervisors and it operations staff the architecture implements a tier-based recovery prioritization model tier 0: critical tier 1: important tier 2: normal that acknowledges not all system components require the same aggressive recovery targets tier 0 components the rms core api for active case management azure sql database for transactional case records and azure front door for officer access have the most stringent targets rpo 5 seconds rto 60 minutes because their unavailability directly prevents officers from documenting incidents in the field or accessing case histories during traffic stops tier 1 components like the routing service for external integrations and service bus message queues have relaxed targets rpo 15 minutes rto 2 hours since temporary delays in submitting cases to mncis or nibrs do not immediately impact field operations tier 2 components such as the reporting dashboard and analytics queries tolerate even longer outages rto 8 hours as they support administrative workflows rather than real-time public safety operations acceptable data loss windows and operational reasoning: the rpo targets annotated in the diagram represent the maximum amount of recent data the organization is willing to lose during a disaster scenario informed by cost-benefit analysis of replication technology investments versus business impact for the rms transactional database the rpo 5 seconds target means that in a catastrophic primary region failure officers might need to re-enter up to 5 seconds of case updates manually potentially affecting 1-2 active case submissions during peak activity hours this narrow data loss window justifies the investment in azure sql active geo-replication which incurs egress costs for cross-region data transfer and requires doubling database compute storage costs for the secondary replica for service bus message queues with rpo 15 minutes the organization accepts that messages published in the 15 minutes before a disaster might be lost requiring manual resubmission of affected case routing requests identified through application insights distributed tracing logs this decision balances the cost of service bus premium geo-disaster recovery pairing 2 500 month against the operational impact of occasionally reprocessing a small batch of integration messages downtime cost analysis and investment justification: the rto targets in the diagram directly correlate to quantified downtime costs that justify disaster recovery infrastructure investments internal analysis detailed in the dr cost model section of the operational playbooks estimates that complete rms unavailability costs approximately 15 000 per hour in officer productivity loss officers reverting to paper forms delayed case filings causing court continuances inability to access warrant information during traffic stops the tier 0 rto 60 minutes target therefore limits worst-case financial exposure to 15 000 for a single regional outage compared to potential 8-12 hour recovery times without geo-redundancy that could exceed 180 000 in impact the diagram shows how this cost model drove the decision to implement automatic sql failover warm standby app service deployments in the secondary region and azure front door s built-in multi-region routing collectively adding approximately 8 000 month in infrastructure costs but protecting against potentially catastrophic business disruptions dr testing schedule and validation procedures: the diagram references a rigorous dr testing program designed to validate that actual recovery times match the documented rto targets the architecture mandates quarterly failover drills scheduled 90 days apart documented in azure devops work items where the operations team deliberately fails over to the secondary region during a planned maintenance window measures time-to-recovery for each component and documents discrepancies the diagram illustrates the test procedure: 1 announce test window to stakeholders 2 trigger sql failover group promotion 3 update app service deployment slots to secondary region 4 validate application functionality with smoke tests 5 measure and record actual rto rpo achieved 6 conduct post-mortem to identify process improvements this testing discipline ensures that dr runbooks remain accurate as the architecture evolves and that operations staff maintain proficiency in failover procedures test results are aggregated in the dr readiness dashboard visible in the diagram that tracks failover success rate average rto variance from target and runbook accuracy metrics providing executive leadership with confidence in disaster recovery preparedness reliability recommendations item current state recommendation effort ------ -------------- ---------------- -------- dr strategy no documented plan define rto rpo create runbooks 1 week sql geo-replication single-region enable geo-replication to secondary 2 weeks service bus geo-dr standard tier upgrade to premium for geo-dr 2 weeks health endpoints basic monitoring comprehensive health checks per service 1 week retry policies limited exponential backoff circuit breakers 2 weeks dr testing never tested quarterly failover drills ongoing ai-ready architecture future state all ai models trained only on de-identified data no cji used in external ai services unless cjis-compliant all ai outputs require human review before use in cjis systems document all ai decision-making per nist ai risk management framework use case complexity cjis impact business value ---------- ----------- ------------- --------------- enhanced search ai search medium none non-cji zone high - faster case lookup form extraction document intelligence medium document-level review high - reduce manual entry report writing assist openai high human review required high - officer productivity case duration prediction ml high none aggregated data medium - resource planning implementation roadmap phase focus key deliverables dependencies ------- ------- ----------------- ------------- 0 planning approved roadmap answered questions deep-dive sessions stakeholder alignment 1 security managed identities tde cmk private link cjis addendum phase 0 complete 2 reliability geo-replication dr plan health monitoring tested failover phase 1 foundations 3 operations distributed tracing sentinel siem dashboards alerting phase 2 health endpoints 4 performance redis cache auto-scaling load testing api versioning phase 3 monitoring 5 ai data segregation anonymization pipeline ai search poc phase 1 phase 3 priority recommendations immediate actions next 30 days recommendation pillar effort business impact --- ---------------- -------- -------- ---------------- 1 implement managed identities for all services security 2-3 weeks eliminate credential management reduce breach risk 2 enable sql tde with customer-managed keys security 2 weeks cjis compliance enhanced key control 3 configure application insights distributed tracing operations 1 week end-to-end visibility faster troubleshooting 4 implement health endpoints and monitoring reliability 1 week proactive issue detection prevent outages 5 enable sql database geo-replication reliability 2 weeks multi-region redundancy disaster recovery 6 document dr procedures and rpo rto reliability 1 week clear recovery processes compliance short-term next 90 days recommendation pillar effort business impact --- ---------------- -------- -------- ---------------- 7 implement private link for all paas services security 3-4 weeks network isolation eliminate public exposure 8 configure azure cache for redis performance 2 weeks faster response times better user experience 9 implement api versioning strategy operations 2 weeks safe evolution backward compatibility 10 set up microsoft sentinel for siem security 3-4 weeks advanced threat detection automated response 11 configure auto-scaling rules performance 2 weeks handle traffic spikes maintain performance 12 implement storage lifecycle management operations 1 week efficient data management compliance long-term 90 days recommendation pillar effort business impact --- ---------------- -------- -------- ---------------- 13 evaluate ai use cases non-cjis data innovation 6-8 weeks enhanced analytics predictive capabilities 14 implement event sourcing for audit trail reliability 8-12 weeks complete audit history forensic analysis 15 consider cqrs for read write separation performance 10-12 weeks optimized queries scalable architecture 16 migrate to premium service bus for geo-dr reliability 2 weeks geographic redundancy business continuity visit the priority matrix to track implementation progress interactively appendix a rbac role matrix zoomableimage src images arch user 20role 20access 20management-2026-02-23-171421 png alt user role access management caption rbac architecture showing authentication flow conditional access policies and role-based permissions visual rbac flow and access control architecture the user role access management diagram provides a comprehensive visualization of the role-based access control rbac flow across all system layers from azure active directory entra id authentication through api management authorization application-level permission enforcement and database-level row security this end-to-end rbac architecture implements defense-in-depth access control aligned with cjis security policy 5 6 personnel security requirements ensuring that access privileges are validated at every trust boundary and that no single layer s compromise can bypass authorization checks the diagram directly maps to the rbac role matrix table below illustrating how organizational roles patrol officer detective supervisor admin translate into technical permissions across azure infrastructure application code and data storage layers rbac flow across system layers: the diagram traces the complete authentication and authorization path for a typical user request layer 1 azure ad entra id : officers authenticate using their organizational credentials officer smith dakotacounty gov with multi-factor authentication mfa enforcement via conditional access policies that require authenticator app approval and compliant device check azure ad join or intune mdm enrollment upon successful authentication entra id issues a jwt access token containing user claims: oid unique user object id roles array of assigned application roles: patrolofficer cjiuser groups azure ad security group memberships: rms-dakotasheriff-users and tid tenant id for multi-tenant isolation referencing section 1 6 this jwt token serves as the user s identity credential for all subsequent api calls layer 2 api management : azure apim validates the jwt token signature against entra id s public signing keys jwks endpoint verifies token expiration and issuer claims and extracts the roles claim for initial authorization checks apim policies implement coarse-grained authorization: validate-jwt policy blocks requests without valid tokens check-header policy requires tls client certificates for api-to-api calls and rate-limit-by-key policy enforces per-role quotas patrol officers limited to 60 requests minute detectives allowed 200 requests minute to support high-volume investigative queries layer 3 application tier : rms app service receives the validated jwt and performs fine-grained authorization using asp net core s authorize roles detective attributes on controller actions the application code inspects claims to enforce business rules: patrol officers can read only their own cases if currentuser officerid case createdbyofficerid throw new forbiddenexception while detectives can read all cases within their department if currentuser department case department throw new forbiddenexception layer 4 database tier : azure sql database enforces row-level security rls policies that automatically filter query results based on the managed identity or sql user principal executing the query for tenant isolation rls appends where tenantid session_context tenantid to all select statements with the application setting session context after authentication this layered access control ensures that even sql injection vulnerabilities cannot bypass authorization the database engine enforces access restrictions independently of application code conditional access policy flow and enforcement points: the diagram details the conditional access policy evaluation chain that occurs during entra id authentication implementing zero trust principles where every authentication request is evaluated against dynamic risk signals conditional access policies are configured with grant controls require mfa require compliant device require hybrid azure ad joined device and session controls application enforced restrictions conditional access app control with microsoft defender for cloud apps monitoring the evaluation flow follows a decision tree: 1 user initiates authentication 2 entra id checks user s location is the request originating from known dakota county ip ranges or via vpn 3 device compliance check is the device intune-managed with required security patches 4 user risk score has this account been observed in credential leak databases or exhibiting anomalous behavior patterns 5 sign-in risk score is this login attempt from an impossible travel scenario e g minneapolis 10 minutes ago now moscow if any risk signal exceeds thresholds user risk: high sign-in risk: medium conditional access blocks the authentication and requires security team remediation if risk signals are acceptable conditional access grants a session token with token lifetime restrictions: standard users receive 8-hour tokens requiring re-authentication each shift while external partner accounts receive 1-hour tokens with reauthentication prompts these session controls are visualized in the diagram as decision gates between entra id and the application layer emphasizing that authentication is continuously evaluated rather than a one-time check privileged identity management pim just-in-time access workflow: the diagram prominently features the azure pim workflow for administrative access to production resources implementing time-bound approval-gated privilege elevation standard operational procedures dictate that database administrators and infrastructure engineers hold eligible role assignments contributor on rms-core-rg owner on rms-shared-rg but do not have active role assignments by default when an engineer requires elevated access for incident response they initiate a pim activation request via the azure portal or powershell module specifying: 1 requested role contributor on rms-core-rg 2 duration maximum 4 hours 3 business justification investigating p1 incident 12345 - api gateway 502 errors and 4 optionally attaching an approved change request ticket id the pim workflow routes the request to designated approvers two infrastructure architects must approve who receive notifications via microsoft teams and email with full context requester identity requested scope justification approval deadline if approved within 15 minutes pim grants the requested role for the specified duration and logs the activation to azure activity log and microsoft sentinel after 4 hours the role assignment automatically expires requiring reactivation if additional access is needed this jit access model critical for cjis compliance ensures that administrative privileges are time-limited auditable and require peer approval drastically reducing the attack surface compared to permanent global administrator assignments the diagram maps pim activation to the admin row in the rbac role matrix below showing that full access is gated by via pim annotations break-glass account strategy for emergency access: the architecture implements a break-glass account strategy for emergency scenarios where normal authentication mechanisms fail entra id outage mfa provider unavailable conditional access policy misconfiguration locking out all administrators two break-glass accounts bg-admin-001 dakotacounty onmicrosoft com bg-admin-002 dakotacounty onmicrosoft com are provisioned with permanent global administrator privileges and excluded from all conditional access policies these accounts are secured with 64-character randomly-generated passwords stored in a physical safe with dual-access control requiring two executives and monitored continuously any authentication event using break-glass accounts triggers immediate p0 alerts to the security team and executive leadership the accounts are tested quarterly during disaster recovery drills to validate they remain functional and passwords are rotated annually with witness verification the diagram shows break-glass accounts as a separate authentication path bypassing normal rbac flows with a direct line to resource access layers marked emergency only - fully audited this contingency access pattern balances business continuity preventing lockout scenarios with security rigor extensive logging physical security controls quarterly accountability reviews cjis security policy 5 6 personnel security alignment: the rbac architecture directly implements cjis requirements for personnel security: 5 6 1 1 personnel screening verified through background check flags in entra id user profiles extensionattribute1: backgroundcheckcompleted-2025-06-15 5 6 2 1 training enforced via mandatory annual cjis training completion records that gate access conditional access policy: if user trainingexpiry today deny and 5 6 3 1 separation of duties implemented via distinct roles with non-overlapping permissions patrol officers cannot approve supervisor actions analysts cannot access pii fields the diagram cross-references these cjis controls annotating each access layer with the applicable policy section audit logs captured at entra id sign-ins apim gateway requests application-level authorization decisions and sql database row access provide end-to-end forensic trails for compliance audits enabling investigators to reconstruct complete access histories: which users accessed case 12345 s evidence photos during the investigation period these logs are exported to azure log analytics retained for 7 years per cjis requirements and protected with immutable storage azure blob worm policy to prevent tampering entra b2b guest user access patterns: the architecture supports external partner access via entra id b2b business-to-business collaboration enabling prosecutors from hennepin county or state investigators from bca to access shared cases without creating duplicate user accounts guest users authenticate with their home organization s credentials e g hennepin us entra id tenant and receive jit guest invitations scoped to specific cases or evidence items the rbac diagram illustrates the guest user flow: external user authenticates to hennepin county entra id cross-tenant token minted by dakota county entra id home tenant provides identity resource tenant provides authorization guest user receives restricted permissions read-only access to assigned cases no download print rights watermarked evidence previews guest access sessions are limited to 2-hour lifetime with explicit reauthentication after session expiry and all guest user activities generate high-severity audit events logged to microsoft sentinel for security monitoring the diagram maps guest users to the external system row in the rbac role matrix specifying api scoped and per agreement constraints this b2b integration pattern replacing insecure email attachments or ftp file shares provides secure auditable time-limited collaboration with external law enforcement agencies while maintaining tenant isolation external users never receive native entra id accounts in dakota county s directory rbac role matrix table role cases evidence admin reports integration cjis level ------ ------- ---------- ------- --------- ------------- ------------ patrol officer create read own upload none own dept none cji access detective read update all in dept full access none dept-wide none cji access supervisor full dept access full access user mgmt all reports config cji access admin all via pim all via pim full all full cji background check analyst read de-identified none none aggregated none non-cji external system api scoped none none none specific api per agreement b ci cd pipeline stages zoomableimage src images arch azure 20devops 20ci_cd 20pipeline-2026-02-23-170737 png alt azure devops ci cd pipeline architecture caption ci cd pipeline showing build stages approval gates and deployment workflow deployment pipeline architecture and infrastructure as code the azure devops ci cd pipeline diagram illustrates the comprehensive continuous integration and continuous deployment workflow that automates the delivery of application code and infrastructure changes to the cjn dakota rms environment this pipeline architecture implements best practices for security scanning approval gates and automated rollback mechanisms to ensure production deployments meet cjis compliance requirements while enabling rapid iteration velocity the pipeline integrates with the bicep infrastructure-as-code iac toolchain referenced in section 1 s technology stack table iac: bicep azure devops providing a declarative version-controlled approach to managing all azure resources branch strategy and merge policies: the diagram illustrates the git branching model: developers work in feature branches feature case-search-enhancement which merge to the develop branch via pull requests prs that trigger automated ci builds unit tests and static application security testing sast scans once validated in the develop environment changes are promoted to the main branch through a gated pr requiring two code reviewer approvals and passing integration tests the main branch automatically deploys to the production environment after manual approval from the release manager azure repos enforces branch policies: direct commits to main or develop are blocked pr authors cannot approve their own prs and all prs must include linked azure devops work items user stories bugs for traceability this branching strategy based on gitflow prevents untested code from reaching production and maintains a clean audit trail for cjis compliance who deployed what when and why bicep iac deployment pipeline stages: the infrastructure deployment pipeline triggered by commits to the infra directory executes a multi-stage workflow visualized in the diagram: 1 bicep compilation: validate bicep files with az bicep build to catch syntax errors 2 what-if analysis: run az deployment group what-if to preview infrastructure changes without applying them e g this will create 3 new resources modify 1 existing resource and delete 0 resources 3 peer review gate: block deployment until two infrastructure engineers approve the what-if diff 4 incremental deployment: execute az deployment group create --mode incremental to apply only the delta changes preserving existing resources not defined in bicep templates 5 smoke tests: validate critical resource configurations e g verify app service has vnet integration enabled confirm key vault has purge protection and 6 deployment report: publish a summary to the azure devops pipeline run with links to azure portal resource groups this iac approach eliminates manual azure portal clicking provides disaster recovery capability re-deploy entire infrastructure from git history and enables infrastructure drift detection comparing actual azure state to bicep templates via what-if analysis approval gates and manual intervention points: the diagram highlights three critical manual approval stages: stage environment deployment requires qa team sign-off after smoke tests pass production deployment requires release manager approval with mandatory 4-hour delay for business hours deployments and infrastructure changes requires dual approval from infrastructure architects for security-sensitive changes like nsg rule modifications or private link configurations each approval gate integrates with azure devops approvals api which sends notifications to microsoft teams channels and enforces timeout policies approvals expire after 24 hours blocking stale deployments for emergency hotfixes the pipeline supports a fast-track path that bypasses the stage environment and deploys directly to production but requires dual approval and generates a high-severity audit log entry for post-incident review these approval gates balance deployment velocity multiple deployments per day to dev stage with production stability zero unplanned downtime in 6 months per customer interviews rollback procedure and version tagging: the pipeline implements automated rollback capability using azure app service deployment slots each production deployment first publishes to a staging slot performs health checks http 200 responses application insights availability tests synthetic transaction validation and then swaps the staging slot to production using az webapp deployment slot swap if post-deployment health checks fail indicated by error rate exceeding 1 within 5 minutes or application insights anomaly detection triggering the pipeline automatically swaps back to the previous version within 60 seconds restoring service the diagram shows the version tagging strategy: every successful deployment tags the git commit with the semantic version v2 3 15 and deployment timestamp creating an immutable release history these tags enable point-in-time rollback: operators can redeploy any previous version by triggering the pipeline with a specific git tag as the source for infrastructure changes bicep templates are tagged similarly infra-v1 2 0 and azure policy assignments enforce tagging requirements on all resources all resources must have tags: environment owner costcenter version infrastructure drift detection and security scanning integration: the pipeline includes a nightly scheduled job visualized in the diagram as a separate pipeline trigger that runs az deployment group what-if against production resource groups to detect configuration drift manual changes made outside the ci cd pipeline e g an engineer adjusting nsg rules via azure portal if drift is detected the pipeline creates a high-priority azure devops work item with a detailed diff and alerts the infrastructure team this drift detection combined with azure resource graph queries that identify untagged or non-compliant resources ensures the production environment matches the declarative bicep templates the diagram also highlights microsoft defender for devops integration which scans infrastructure-as-code templates for security misconfigurations e g storage accounts without encryption key vaults with public network access enabled and blocks deployments with critical findings defender for devops extends to application code scanning integrating sast tools checkmarx sonarqube and software composition analysis sca tools whitesource snyk to identify vulnerable dependencies cves in nuget packages and code quality issues sql injection risks hardcoded secrets these security scans run in parallel during the ci build stage failing the build if critical vulnerabilities are detected thus preventing vulnerable code from reaching production stage trigger gate failure action ------- --------- ------ --------------- ci build pr or merge to main automated compilation block merge unit tests ci pipeline 90 coverage required block merge sast dep scan ci pipeline no critical vulnerabilities block merge dev deploy merge to main smoke tests pass alert team stage deploy manual promote qa approval required block promotion prod deploy manual approval error rate 1 auto-rollback infra deploy pr to infra branch peer review what-if block apply c monitoring alert thresholds metric warning critical response -------- --------- ---------- ---------- api response time 2 seconds 5 seconds scale out app service error rate 1 5 page on-call initiate rollback cpu utilization 70 90 auto-scale configured dlq message count 5 20 investigate failed integrations sql dtu usage 70 90 scale database tier failed authentications 5 min 20 min sentinel auto-block ip service bus queue depth 1000 5000 scale consumers certificate expiry 30 days 7 days auto-renew or page team d data lifecycle storage tiers phase sql tier blob tier cache transition ------- ---------- ----------- ------- ------------ active 0-90 days general purpose hot redis cached manual investigation 90d - 2y general purpose cool auto at 90d evicted lifecycle policy closed 2-7 years partitioned archive archive auto at 730d none lifecycle policy disposal 7 years purge legal hold check purge worm check n a manual approval e pillar maturity assessment pillar sub-area current target gap priority -------- ---------- --------- -------- ----- ---------- security identity management 7 10 9 10 2 high security data protection 6 10 9 10 3 critical security network security 7 10 9 10 2 high security cjis compliance 6 10 9 10 3 critical reliability disaster recovery 4 10 9 10 5 critical reliability health monitoring 5 10 8 10 3 high reliability resilience patterns 6 10 8 10 2 medium operations observability 5 10 8 10 3 high operations ci cd maturity 7 10 9 10 2 medium operations incident response 4 10 8 10 4 high performance caching strategy 3 10 8 10 5 high performance auto-scaling 4 10 8 10 4 medium performance database optimization 6 10 8 10 2 medium f azure verified modules avm recommendation avm module registry path ---------------- ------------ --------------- managed identities user assigned identity br public:avm res managed-identity user-assigned-identity sql database tde sql server br public:avm res sql server private endpoints private endpoint br public:avm res network private-endpoint key vault hsm key vault br public:avm res key-vault vault service bus service bus namespace br public:avm res service-bus namespace azure functions web sites br public:avm res web site api management apim service br public:avm res api-management service application insights insights components br public:avm res insights component redis cache cache for redis br public:avm res cache redis front door cdn profile br public:avm res cdn profile resources azure well-architected framework cjis compliance in azure azure security baseline avm bicep registry index last updated: february 22 2026",
      "headings": [
        "Executive Summary",
        "1. System Architecture Overview",
        "1.5 Resource Group Architecture",
        "1.6 Multi-Tenant Isolation Strategy",
        "2. Network Topology & Security Zones",
        "3. Request Lifecycle",
        "4. Event-Driven Processing",
        "5. External Integrations",
        "6. Defense-in-Depth Security",
        "7. CJIS Data Classification Boundaries",
        "8. Disaster Recovery Topology",
        "9. AI-Ready Architecture (Future State)",
        "10. Implementation Roadmap",
        "Priority Recommendations",
        "Appendix"
      ],
      "keywords": [
        "architecture",
        "azure",
        "well-architected",
        "recommendations",
        "CJN Dakota",
        "Executive Summary",
        "1. System Architecture Overview",
        "1.5 Resource Group Architecture",
        "1.6 Multi-Tenant Isolation Strategy",
        "2. Network Topology & Security Zones",
        "3. Request Lifecycle",
        "4. Event-Driven Processing",
        "5. External Integrations",
        "6. Defense-in-Depth Security",
        "7. CJIS Data Classification Boundaries",
        "8. Disaster Recovery Topology",
        "9. AI-Ready Architecture (Future State)",
        "10. Implementation Roadmap",
        "Priority Recommendations",
        "Appendix",
        "Date:",
        "Customer:",
        "Project:",
        "Reliability",
        "Security",
        "Operational Excellence",
        "Performance Efficiency",
        "Overall",
        "6.4/10",
        "8.0/10",
        "## 1. System Architecture Overview\n\n<ZoomableImage src=\"/images/arch/top-down-topology.png\" alt=\"CJN Dakota RMS System Architecture\" caption=\"CJN Dakota RMS System Architecture - Top-down topology showing resource groups, services, and security zones\" />\n\n### Architecture Analysis\n\nThe system architecture diagram above illustrates the complete Azure-based Records Management System deployed in Azure Commercial GCC to meet CJIS compliance requirements. This topology represents a mature microservices architecture with clear separation of concerns across four distinct resource groups, each serving a specific domain within the RMS ecosystem.",
        "The architecture implements a rigorous isolation model with dedicated resource groups for",
        "(case management and core record operations),",
        "(external system integration and message distribution),",
        "(indexing and query operations), and",
        "(SQL Database, Key Vault, Service Bus Premium). This separation enables independent lifecycle management, granular RBAC assignments, and blast radius containment in the event of a security incident or operational failure.",
        "Services marked with \"- CJI\" annotations in the topology handle Criminal Justice Information and are subject to CJIS Security Policy 5.0 requirements. These include all App Services (RMS, Routing, Search), Azure Functions, SignalR Hub, Service Bus topics, and the SQL Database. The diagram clearly delineates the trust boundary—all CJI components reside within the VNet-integrated application tier or are accessed via Private Endpoints, ensuring no public internet exposure to sensitive law enforcement data.",
        "The topology visualizes the hub-and-spoke pattern where the RMS App Service acts as the primary orchestrator, coordinating with Routing and Search services through Azure API Management. All compute services maintain direct connections to Azure SQL Database for transactional consistency, while Key Vault provides centralized secrets management using Managed Identity authentication (eliminating stored credentials). The Service Bus Premium instances (Route\\_SB and Search\\_SB) enable asynchronous, event-driven communication between services, supporting session-based ordering per case or destination.",
        "User requests traverse multiple security checkpoints before reaching application services. Azure Front Door provides global DDoS protection, Web Application Firewall (WAF), and TLS 1.2 termination at the edge. Azure API Management enforces rate limiting, JWT validation, and request throttling before forwarding traffic to backend services. This defense-in-depth approach—detailed further in the",
        "section below—ensures that even if one security layer is compromised, additional controls remain in place.\n\nFor detailed capability mapping, refer to the",
        "table below. For technology rationale and version specifications, see the",
        "section. The network security implementation of this architecture is visualized in Section 2.",
        "CJI = Criminal Justice Information | Blue = Data & storage | Green = Compute | Yellow = Integration | Light Blue = Edge\n\n### Technology Stack\n\n| Layer | Technology | Purpose |\r\n|-------|------------|---------|\r\n|",
        "| Entra ID B2B + Conditional Access | User authentication, MFA |\r\n|",
        "| Azure Front Door | Global load balancing, DDoS protection |\r\n|",
        "| Azure API Management | Rate limiting, throttling, API versioning |\r\n|",
        "| Azure Static Web Apps | Modern SPA hosting |\r\n|",
        "| Azure App Services + Functions | Microservices (RMS, Routing, Search) |\r\n|",
        "| Azure Service Bus (Premium) | Event-driven architecture, session-based messaging |\r\n|",
        "| Azure SignalR Service | Live notifications and updates |\r\n|",
        "| Azure SQL Database (PaaS) | Transactional data with TDE encryption |\r\n|",
        "| Azure Cache for Redis | Distributed cache for performance |\r\n|",
        "| Azure Key Vault Premium | Customer-managed keys, HSM-backed |\r\n|",
        "| Application Insights + Azure Monitor | Distributed tracing, metrics, logs |\r\n|",
        "| Microsoft Sentinel | SIEM/SOAR for threat detection |\r\n|",
        "| Azure Virtual Network + Private Link | Network isolation, no public internet exposure |\r\n|",
        "| Bicep + Azure DevOps | Infrastructure as code, CI/CD pipelines |\n\n### Key Capabilities\n\n| Capability | Description |\r\n|-----------|-------------|\r\n|",
        "| CJIS-compliant encryption at rest/transit, immutable audit logs, data residency in Azure GCC |\r\n|",
        "| SignalR Hub + Service Bus for live officer notifications and event-driven processing |\r\n|",
        "| 9+ external systems (MNCIS, NIBRS, eCitations, eCharging, MNCrash, MAARC, DPS, Hennepin, LOGIS) |\r\n|",
        "| SQL geo-replication, automated backup, point-in-time restore, documented DR |\r\n|",
        "| Distributed tracing, custom workbooks, Sentinel SIEM, proactive health monitoring |\r\n|",
        "| Redis cache, auto-scaling, Front Door CDN, microservices independent scaling |\r\n|",
        "| CJIS/non-CJIS data segregation, anonymization pipeline, Azure AI Search readiness |",
        "Multi-tenant isolation through resource groups",
        "Resource Group Separation Rationale:",
        "RMS-Core-RG",
        "RMS-Routing-RG",
        "RMS-Search-RG",
        "RMS-Shared-RG",
        "independent deployment cycles",
        "environment-specific scaling",
        "Tag Strategy for Cost Allocation and Operational Tracking:",
        "Environment",
        "Owner",
        "CostCenter",
        "Project",
        "ComplianceScope",
        "DataClassification",
        "DeploymentVersion",
        "Azure Cost Management chargeback reports",
        "Resource Dependencies and Deployment Order:",
        "Phase 1: Shared Infrastructure",
        "Phase 2: Microservices",
        "Appendix B: CI/CD Pipeline Stages",
        "RBAC Boundary Enforcement at Resource Group Level:",
        "RMS Core Team",
        "Contributor",
        "zero access",
        "Platform Team",
        "Reader",
        "Global Administrators",
        "CJIS Security Policy 5.6 (Personnel Security)",
        "Appendix A: RBAC Role Matrix",
        "Lifecycle Management Advantages:",
        "deploy RMS v3.0 to a new parallel resource group",
        "resource group suspension",
        "## 1.6 Multi-Tenant Isolation Strategy\n\n<ZoomableImage src=\"/images/arch/Multi-Tenant%20Isolation%20Model.png\" alt=\"Multi-Tenant Isolation Model\" caption=\"Multi-tenant isolation architecture with tenant-scoped access control and resource separation\" />\n\n### Tenant Provisioning and Isolation Architecture\n\nThe Multi-Tenant Isolation Model diagram illustrates the comprehensive tenant onboarding, resource isolation, and data segregation strategy that enables the CJN Dakota RMS to support multiple law enforcement agencies (Dakota County Sheriff, City Police Departments, Regional Task Forces) within a shared Azure infrastructure while maintaining strict security boundaries. This architecture balances operational efficiency (shared infrastructure reduces per-tenant cost) with regulatory compliance (CJIS Security Policy 5.10.1.2 mandates logical separation of CJI data between agencies). The model implements",
        "at every system layer—Azure Active Directory groups, API Management policies, application-level authorization, and database row-level security—ensuring that an officer from Dakota County Sheriff cannot access cases created by City Police Department, even if application code vulnerabilities exist.",
        "The diagram details the automated tenant provisioning pipeline triggered when a new law enforcement agency contracts for RMS services. The workflow begins with a",
        "submitted via Azure DevOps Service Management portal, capturing tenant metadata (Agency Name, ORI Number, Billing Contact, Primary Administrator Email, Azure Region Preference). An Azure DevOps pipeline orchestrates the provisioning sequence: (1)",
        "(`RMS-DakotaSheriff-Users`, `RMS-DakotaSheriff-Admins`) with conditional access policies requiring MFA and compliant device enrollment, (2)",
        "(`RMS-DakotaSheriff-RG`) dedicated to the tenant's application services, following the resource group architecture defined in Section 1.5, (3)",
        "(dedicated schema `dakota_sheriff` within the shared multi-tenant SQL Database, with row-level security policies enforcing tenant isolation), (4)",
        "(dedicated namespace `sb-dakotasheriff-prod` for tenant-specific message routing, preventing cross-tenant message leakage), (5)",
        "(tenant-specific app settings in Key Vault: `TenantId`, `DatabaseSchema`, `ServiceBusNamespace`, `BillingCode`), and (6)",
        "(sending onboarding emails with initial credentials, MFA enrollment QR code, and training video links). This automated workflow reduces tenant onboarding time from 5 days (manual provisioning) to 2 hours (pipeline-driven), eliminating human error and ensuring consistent security configurations across all tenants.",
        "The architecture implements a hybrid isolation model combining",
        "(cost efficiency) with",
        "(security boundaries). Each tenant receives a",
        "for their application services—tenant-specific App Services, Azure Functions, and Application Insights instances—ensuring compute isolation and preventing one tenant's traffic spike from throttling another tenant's performance. For example, if Dakota County experiences a 10x load increase during a major incident, their dedicated App Service autoscales independently without impacting City Police Department's service availability. However,",
        "—Azure SQL Database (with logical schema separation), Azure Front Door, Azure API Management, and shared Key Vault—are provisioned once and serve all tenants to reduce operational overhead. The diagram illustrates Private Endpoint connections from tenant-specific App Services to the shared SQL Database, with network traffic remaining within the Azure backbone and never traversing public internet. Each tenant's App Service is assigned a",
        "(`RMS-DakotaSheriff-AppService-Identity`), which authenticates to SQL Database and is authorized to access only the `dakota_sheriff` schema via database-level permissions. This identity-based access control ensures that even if a tenant's application code is compromised, the attacker cannot escalate privileges to access other tenants' data at the database layer.",
        "To prevent noisy neighbor scenarios where one tenant's resource consumption degrades another tenant's performance, the architecture implements",
        "with per-database DTU limits and",
        "with dedicated messaging units per tenant. The diagram shows Dakota County Sheriff's database allocated 50 DTUs within the shared elastic pool (supporting ~500 concurrent users), while smaller agencies receive 10 DTUs (supporting ~100 concurrent users). If Dakota County's workload exceeds 50 DTUs, SQL Database throttles their queries rather than allowing them to starve other tenants' resources. Similarly, each tenant's Service Bus namespace is configured with a quota of 1 Messaging Unit (1 GB memory, 1 vCPU), preventing one tenant from monopolizing the shared Service Bus infrastructure. Azure API Management enforces",
        ": Dakota County Sheriff is allocated 1,000 API requests/minute, while smaller agencies receive 200 requests/minute. These quotas are codified in API Management policies using `rate-limit-by-key` with the tenant's `ORI Number` as the throttling key, returning HTTP 429 Too Many Requests when limits are exceeded. Performance metrics are tracked in dedicated Application Insights instances per tenant, enabling tenant-specific performance SLAs (Dakota County contract specifies P95 API latency \\< 500ms, measured using their dedicated App Insights telemetry). This granular performance isolation—combined with autoscaling configurations that scale tenant resources based on their own workload—ensures predictable performance and meets enterprise SLA commitments.",
        "The diagram illustrates the cost allocation strategy that enables accurate per-tenant billing and chargeback to subscribing agencies. All Azure resources are tagged with",
        "(e.g., `dakota-sheriff`, `city-police-dept`) and",
        "(e.g., `CC-2001-DakotaSheriff`), feeding into Azure Cost Management reports that break down monthly Azure spend by tenant. Shared infrastructure costs—SQL Database elastic pool base cost, Azure Front Door fees, API Management gateway instance—are",
        "Data Isolation at Database Level:",
        "Row-Level Security (RLS) policies",
        "Separate database schemas",
        "Always Encrypted columns",
        "CJIS Security Policy 5.10 (Information Systems Security Officer)",
        "Scalability Considerations for Multi-Tenant Architecture:",
        "50 tenants",
        "20 tenants per Service Bus Premium namespace",
        "shards tenants across multiple infrastructure instances",
        "tenant migration",
        "dedicated single-tenant deployment",
        "Section 1.5 Resource Group Architecture",
        "## 2. Network Topology & Security Zones\n\n<ZoomableImage src=\"/images/arch/network-security-zones.png\" alt=\"CJN Dakota Network Security Zones\" caption=\"Network security zones with defense-in-depth architecture and trust boundaries\" />\n\n### Network Security Architecture\n\nThe network topology diagram illustrates a defense-in-depth security model organized into six distinct trust zones, each with progressively restrictive access controls. This layered approach directly implements",
        "requirements by establishing clear trust boundaries, enforcing least-privilege access, and ensuring all CJI data remains within hardened, audited network segments.",
        "Network traffic flows through a graduated trust model, starting from the",
        "(public internet), passing through the",
        "(Azure Front Door with WAF/DDoS), entering the",
        "(Azure API Management with JWT validation), and finally reaching the",
        "(VNet-integrated App Services) or",
        "(Private Endpoint-only data services). The diagram's color coding—red for untrusted, yellow/orange for edge/gateway, green for application tier, and blue for data tier—provides immediate visual clarity on security posture. The",
        "(purple) operates on a separate plane with dedicated RBAC and Privileged Identity Management (PIM) controls.",
        "The diagram prominently shows Private Endpoint connections (dark blue arrows) between the Application Tier and Data Tier. All PaaS services handling CJI data—Azure SQL Database, Key Vault Premium, Service Bus Premium, and Blob Storage—are accessed exclusively via Private Endpoints within the `snet-data /24` subnet. This architecture eliminates public IP addresses for data services, ensuring that even compromised application code cannot exfiltrate data directly to the internet. All data plane traffic remains within the Azure backbone network, satisfying CJIS Advanced Authentication requirements.",
        "Traffic between zones is governed by NSG rules applied at the subnet level. The diagram illustrates filtered communication paths where API Management can route requests to App Services in `snet-rms-app`, `snet-route-app`, and `snet-search-app` subnets, but lateral movement between application subnets is denied by default. Each microservice operates in a network-isolated blast radius, preventing a compromised RMS service from directly accessing Search or Routing infrastructure. NSG flow logs are forwarded to Azure Monitor and Microsoft Sentinel for continuous security monitoring and anomaly detection.",
        "The architecture implements Zero Trust principles by requiring explicit authentication and authorization at every layer. Even after passing Front Door WAF and API Management JWT validation, application services authenticate to data resources using Managed Identities (visualized as identity-based connections). Telemetry flows (dotted lines) from all services to Azure Monitor enable real-time detection of suspicious network patterns, such as unexpected data access or lateral movement attempts. This telemetry is aggregated in Microsoft Sentinel for Security Information and Event Management (SIEM) correlation, with automated response playbooks for high-severity alerts.\n\nThe table below maps each zone to its trust level, security controls, and hosted services. For operational procedures related to network security monitoring, see the",
        "section. For application-level security patterns, refer to Section 6:",
        ".\n\n| Zone | Trust Level | Controls | Services |\r\n|------|-------------|----------|----------|\r\n|",
        "| Untrusted | N/A | End users, external partners |\r\n|",
        "| Low | WAF, DDoS, TLS termination | Front Door, DNS |\r\n|",
        "| Semi-trusted | Rate limiting, JWT, IP filter | API Management |\r\n|",
        "| Trusted | NSGs, VNet integration, managed identity | App Services, Functions, SignalR |\r\n|",
        "| Restricted | Private endpoints only, encryption at rest | SQL, Key Vault, Service Bus, Blob |\r\n|",
        "| Administrative | RBAC, PIM, audit logging | DevOps, Monitor, Sentinel |",
        "Total",
        "End-to-end",
        "\\< 1.5s",
        "99.9%",
        "Appendix C (Monitoring Alert Thresholds)",
        "Distributed Tracing Implementation Across Services:",
        "dependency graph",
        "Correlation ID Propagation Through the Request Chain:",
        "Dependency Tracking Configuration for SQL, Service Bus, and Redis:",
        "Application Map",
        "Performance Baselines and Anomaly Detection:",
        "Alert Rules for Critical Metrics and Forward References:",
        "API response time",
        "error rate",
        "Service Bus DLQ depth",
        "SQL DTU utilization",
        "## 4. Event-Driven Processing\n\n### 4.1 Service Bus Topology\n\n<ZoomableImage src=\"/images/arch/Azure%20Service%20Bus%20Event%20Flow-2026-02-23-165619.png\" alt=\"Azure Service Bus Event Flow Architecture\" caption=\"Service Bus topology with session-based ordering and pub/sub pattern\" />\n\n#### Event-Driven Architecture Analysis\n\nThe Service Bus topology diagram illustrates a mature publish/subscribe (pub/sub) event-driven architecture that decouples microservices and enables asynchronous, scalable processing of RMS operations. This design pattern is fundamental to achieving high availability, fault tolerance, and independent service scaling across the RMS, Routing, and Search domains.",
        "The diagram highlights three primary topics—`case-events`, `route-commands`, and `search-index`—each configured with",
        "to guarantee FIFO (first-in, first-out) ordering within a session context. For `case-events`, the session key is `CaseId`, ensuring all events for Case #12345 are processed sequentially even under high load. Similarly, `route-commands` uses `DestinationId` as the session key, guaranteeing that all messages destined for MNCIS are processed in order, preventing race conditions where a case update could arrive at the state system before the initial case creation. This session-based ordering is critical for maintaining data consistency with external partners who expect deterministic event sequences.",
        "The architecture leverages Azure Service Bus's content-based filtering to route messages from a single `route-commands` topic to multiple specialized subscribers. As shown in the diagram, subscriptions like `mncis-router`, `nibrs-router`, `ecite-router`, `maarc-router`, and `crash-router` each apply a SQL filter expression (`dest = 'MNCIS'`, `dest = 'NIBRS'`, etc.) to receive only relevant messages. This fan-out pattern eliminates the need for hardcoded routing logic in publisher code—the RMS API Service simply publishes a message with a `Destination` property, and Service Bus automatically delivers it to the appropriate consumer. This design supports rapid addition of new integration partners without modifying existing services.",
        "The diagram prominently features the error handling flow where failed messages are routed to a Dead Letter Queue after 10 delivery attempts (configured in the table below). The `DLQ Processor Function` continuously monitors the DLQ depth and triggers an",
        "when the count exceeds 10 messages, indicating a systemic integration failure. Operational procedures for DLQ triage involve inspecting message metadata (exception details, retry count) in the Azure Portal, correcting the root cause (e.g., restoring a downed external API), and manually resubmitting messages via the `ServiceBusAdministrationClient` SDK. This manual gate prevents automatic retry storms that could overwhelm partner systems.",
        "By using Service Bus as an intermediary, producer services (RMS API, Routing API, Scheduled Jobs) remain completely unaware of consumer implementations. If the `func-nibrs-sender` Function experiences a temporary outage, messages accumulate in the `nibrs-router` subscription without blocking other integrations. Each consumer Function scales independently based on queue depth, enabling cost-optimized scaling where high-volume integrations (MNCIS) run on multiple instances while low-volume integrations (MNCrash) use a single instance. This architecture prevents monolithic bottlenecks and supports continuous deployment of individual services without system-wide downtime.\n\nThe",
        "tier (selected for this deployment) provides essential enterprise features: geo-disaster recovery, Private Link network isolation (see Section 2), dedicated compute capacity (1 Messaging Unit = 1 vCPU), and larger message sizes (100 MB vs. 256 KB in Standard). For configuration details, see the property table below. For resilience patterns applied to external API calls within consumer Functions, see Section 5:",
        ".\n\n| Property | Value | Rationale |\r\n|----------|-------|-----------|\r\n|",
        "| Premium | Geo-DR, Private Link, dedicated resources |\r\n|",
        "| Enabled (per topic) | Ordered processing per case/destination |\r\n|",
        "| 10 attempts | Exponential backoff before DLQ |\r\n|",
        "| 5 minutes | Sufficient for external API calls |\r\n|",
        "| 24 hours | Prevent stale message processing |\r\n|",
        "| Alert on count > 10 | Immediate ops notification |\n\n### 4.2 RMS Event Publishing\n\n<ZoomableImage src=\"/images/arch/Azure%20RMS%20Services%20Event-2026-02-23-165517.png\" alt=\"Azure RMS Services Event Publishing\" caption=\"Event publishing architecture showing event types, schemas, and correlation strategy\" />\n\n#### Event Publishing Architecture\n\nThe RMS Event Publishing diagram illustrates the comprehensive event taxonomy and publishing mechanisms used across the RMS, Routing, and Search microservices to maintain eventual consistency and enable reactive workflows throughout the distributed system. This architecture implements the event sourcing pattern for critical state changes, creating an immutable audit trail that can reconstruct system state at any point in time and support future AI/ML pipelines for predictive analytics.",
        "The diagram categorizes published events into four primary types:",
        "(CaseCreated, CaseUpdated, CaseStatusChanged, EvidenceAttached),",
        "(SubmitToMNCIS, SendNIBRSReport, FileCitation),",
        "(IndexCase, UpdateSearchDocument, DeleteFromIndex), and",
        "(UserAction, SystemAction, ComplianceLog). Each event type follows a standardized JSON schema with required properties: `EventId` (GUID for deduplication), `EventType` (fully qualified type name), `AggregateId` (CaseId, EvidenceId, etc.), `Timestamp` (ISO 8601 UTC), `CorrelationId` (distributed tracing identifier), `UserId` (actor for CJIS audit), `Payload` (strongly-typed domain data), and `SchemaVersion` (semantic versioning for backward compatibility). This schema standardization enables generic event processing infrastructure—consumers can deserialize the envelope without knowing payload specifics, logging correlation IDs before payload parsing for observability.",
        "Every event published to Service Bus includes a `CorrelationId` property that propagates through the entire processing chain, enabling end-to-end request tracing across microservice boundaries. When an officer submits a case, the RMS API generates a root `TraceId` (W3C Trace Context standard) and embeds it in the `case-events` message. Downstream consumers (Search indexer, MNCIS router) extract this `CorrelationId`, attach it to their Application Insights telemetry, and include it in subsequent Service Bus messages. This creates a complete dependency graph in Application Insights, allowing operators to visualize the full event cascade triggered by a single user action. For example, querying Application Insights for `CorrelationId = abc123` reveals: API request → case-events published → search indexer invoked → route-commands published → MNCIS Function called → MNCIS API response—with timestamps and latencies at each hop. This tracing capability is essential for troubleshooting production incidents and identifying bottlenecks in the event processing pipeline.",
        "The diagram highlights the `SchemaVersion` property (e.g., `CaseCreated_v2`) used to implement zero-downtime schema evolution. When a new property is added to the `CaseCreated` event payload (e.g., adding `OfficerBadgeNumber` for enhanced audit logging), publishers increment the version to `v2` while consumers maintain support for both `v1` and `v2` schemas using polymorphic deserialization. Older consumers that don't recognize `v2` fall back to processing the common `v1` properties, preventing breaking changes during rolling deployments. This versioning strategy—combined with Azure Service Bus's native support for message properties—enables the RMS team to evolve the event schema incrementally without coordinating simultaneous deployments of all producer and consumer services. The Architecture Decision Record (ADR) for this pattern references Martin Fowler's event versioning guidance and prioritizes additive changes (new optional properties) over breaking changes (renaming/removing properties).",
        "The diagram maps event publishing responsibilities to specific services:",
        "publishes `case-events` and `audit-events` after successful database writes (using the Outbox pattern to guarantee at-least-once delivery even if Service Bus is unavailable),",
        "publishes `route-commands` based on configuration rules (\"new felony cases automatically route to MNCIS\"), and",
        "publishes `search-index` events when document updates are required. Each service uses the Azure Service Bus SDK's `ServiceBusClient` with connection strings retrieved from Key Vault via Managed Identity, publishing to dedicated topics with explicit partition keys (for `case-events`, the partition key is `CaseId % 10` to distribute load across 10 partitions). This topic-per-event-type design (rather than a single monolithic event bus) enables granular access control—the Search Service can publish to `search-index` but cannot publish to `route-commands`, reducing blast radius in the event of a compromised service.\n\n### 4.3 Event Consumption and Processing\n\n<ZoomableImage src=\"/images/arch/Event%20Processing%20and-2026-02-23-170025.png\" alt=\"Event Processing and Consumption Architecture\" caption=\"Event consumption architecture with Azure Functions showing error handling and idempotency patterns\" />\n\n#### Consumer Architecture and Processing Guarantees\n\nThe Event Consumption and Processing diagram illustrates how Azure Functions consume messages from Service Bus subscriptions, implementing robust error handling, idempotency patterns, and performance optimization strategies to guarantee exactly-once processing semantics for critical workflows. This architecture balances throughput requirements (processing 50,000+ events/day during peak hours) with reliability requirements (zero data loss, deterministic retry behavior) while maintaining CJIS audit compliance for all CJI event processing.",
        "The diagram shows dedicated Azure Functions for each event subscription: `func-case-processor` (consumes `case-events` subscription), `func-mncis-router` (consumes `mncis-router` subscription), `func-search-indexer` (consumes `search-index` subscription), and `func-audit-logger` (consumes `audit-events` subscription). Each Function uses the `ServiceBusTrigger` attribute with session-enabled configuration to process messages sequentially per session: `[ServiceBusTrigger(\"case-events\", \"case-processor\", IsSessionsEnabled = true)]`. The `host.json` configuration specifies critical performance parameters: `maxConcurrentSessions = 8` (parallel session processors per instance), `maxConcurrentCalls = 1` (sequential processing within a session for ordering guarantee), `prefetchCount = 32` (message pre-fetching for reduced latency), and `autoCompleteMessages = false` (explicit completion control for error handling). This configuration strikes a balance—8 concurrent sessions provide horizontal scaling while `maxConcurrentCalls = 1` ensures FIFO ordering within each case.",
        "The diagram details the multi-layered error handling strategy. When a Function encounters a transient exception (network timeout, SQL deadlock, external API 503), the Service Bus redelivery mechanism automatically retries the message with exponential backoff: 1st retry after 10 seconds, 2nd after 40 seconds, 3rd after 90 seconds (backoff multiplier = 2.0, capped at 5 minutes). The Function code wraps external calls in Polly policies (see Section 5 code examples for circuit breaker implementation) to handle partner API failures gracefully. For poison messages that fail after 10 retry attempts—such as a malformed JSON payload or a permanent business rule violation—the message is automatically routed to the Dead Letter Queue (DLQ), where the `func-dlq-processor` Function logs the failure details to Application Insights with full context (stack trace, message properties, retry history) and sends an alert to the operations team via Azure Monitor Action Group. This graduated retry strategy prevents transient failures from triggering DLQ alarms while ensuring persistent errors receive immediate attention.",
        "The architecture leverages",
        "for low-traffic Functions (DLQ processor, audit logger) to minimize costs, but deploys high-throughput consumers (case processor, MNCIS router) on",
        "for guaranteed compute capacity and faster cold start times (\\< 1 second vs. 10+ seconds on Consumption Plan). Premium Plan Functions also benefit from VNet integration for Private Link connectivity to Service Bus (avoiding public internet traversal) and from always-ready instances (minimum 1 instance pre-warmed, scaling to 20 instances under load). The diagram shows Azure Functions scaling logic: when Service Bus queue depth exceeds 1,000 messages per instance, the platform automatically provisions additional Function instances (up to the configured maximum of 20). This elastic scaling—combined with Service Bus Premium's dedicated messaging units—ensures the system maintains sub-second processing latency even during incident spikes (e.g., 500 officers simultaneously creating cases after a major event).",
        "To prevent duplicate processing when Service Bus retries a message, each Function implements idempotency checks using distributed caching. Before processing a `CaseCreated` event, `func-case-processor` queries Azure Cache for Redis with the key `processed:{EventId}` (TTL = 7 days, matching Service Bus retention). If the key exists, the Function immediately completes the message without re-execution, logging a \"duplicate message detected\" telemetry event. For new messages, the Function performs a",
        ": (1) write to Redis cache with the processing status \"in-progress\", (2) execute business logic and persist to SQL Database, (3) update Redis to \"completed\" and complete the Service Bus message. If the Function crashes between steps 1 and 3, Service Bus redelivers the message, but the Redis check detects \"in-progress\" status and safely completes the message (the SQL write may have succeeded before the crash). This idempotency pattern—combined with SQL Database's deterministic stored procedures (checking for existing CaseId before INSERT)—guarantees exactly-once processing semantics without requiring distributed transactions or two-phase commit protocols across Service Bus and SQL Database.",
        "The diagram emphasizes Service Bus Sessions as the mechanism for maintaining event ordering within a case context. Each `case-events` message includes a `SessionId` property set to the `CaseId` value. Service Bus guarantees that all messages with the same `SessionId` are delivered to a single Function instance in FIFO order, preventing race conditions where a `CaseUpdated` event could be processed before the corresponding `CaseCreated` event. The Function code accepts the session using `IMessageSession.AcceptSessionAsync(sessionId)`, processes messages sequentially, and releases the session lock upon completion. This session-based ordering is critical for maintaining referential integrity in the search index—if `CaseUpdated` processed before `CaseCreated`, the search indexer would attempt to update a non-existent document. For non-case events (e.g., system health checks), messages are published without a `SessionId`, allowing parallel processing across all available Function instances for maximum throughput.",
        "inbound data",
        "outbound data",
        "Integration Gateway and Security Boundary:",
        "Inbound Processing Pipeline:",
        "MNCIS Inbound",
        "Citation App",
        "ROUTE\\_IN Service",
        "RMS Service Core",
        "RMS Database",
        "Outbound Routing via ROUTE2DEST Service:",
        "ROUTE2DEST Distribution Service",
        "MNCIS\\_OUT",
        "eCitations\\_OUT",
        "eCharging\\_OUT",
        "MNCrash\\_OUT",
        "MAARC\\_OUT",
        "NIBRS\\_OUT",
        "Integration Resilience Patterns",
        "Cross-System Data Lineage and Audit Compliance:",
        "External Systems",
        "Key Capabilities",
        "MNCIS",
        "NIBRS",
        "eCitations",
        "eCharging",
        "MNCrash",
        "MAARC",
        "DPS",
        "Hennepin County",
        "LOGIS",
        "Retry (Exponential Backoff)",
        "Circuit Breaker",
        "Guaranteed Delivery",
        "Dead Letter Queue",
        "Store and Forward",
        "## 6. Defense-in-Depth Security\n\n### Security Controls Matrix\n\n| Layer | Control | CJIS Mapping | Status |\r\n|-------|---------|-------------|--------|\r\n|",
        "| Entra ID + MFA | 5.6.2.2 | Implemented |\r\n|",
        "| FIPS 140 Authenticators | 5.6.2.2 | Needs Validation |\r\n|",
        "| PIM/JIT Access | 5.5.2 | Recommended |\r\n|",
        "| WAF v2 Rules | 5.10.4 | Implemented |\r\n|",
        "| DDoS Protection | 5.10.4 | Implemented |\r\n|",
        "| Private Link | 5.5.4 | Recommended |\r\n|",
        "| VNet + NSGs | 5.5.4 | Implemented |\r\n|",
        "| JWT Validation | 5.5.2 | Implemented |\r\n|",
        "| Rate Limiting | 5.10.4 | Implemented |\r\n|",
        "| Managed Identities | 5.6.1 | Recommended |\r\n|",
        "| TDE + CMK | 5.10.1 | Recommended |\r\n|",
        "| Always Encrypted | 5.10.1 | Recommended |\r\n|",
        "| Sentinel SIEM | 5.4.1 | Recommended |\r\n|",
        "| Audit Logging (7 yr) | 5.4 | Partial |\n\n### Security Recommendations\n\n### Managed Identity Implementation\n\n<ZoomableImage src=\"/images/arch/Managed%20Identity-2026-02-23-165751.png\" alt=\"Managed Identity Authentication Architecture\" caption=\"Managed Identity architecture showing credential-less authentication and RBAC role assignments\" />",
        "The diagram presents the architectural decision framework for selecting between",
        "(lifecycle tied to a specific resource instance) and",
        "(independent lifecycle, reusable across resources). For the RMS architecture, the recommendation follows the principle illustrated in the diagram's decision tree: use",
        "for single-purpose, ephemeral resources like Azure Functions (where each function's identity permissions are tightly scoped to its specific integration partner, e.g., the `func-mncis-sender` Function has only `ServiceBusSender` role on the `route-commands` topic, nothing more), and use",
        "for shared infrastructure components like the RMS API App Service and Routing API App Service that both require identical RBAC permissions to Azure SQL Database, Key Vault, and Service Bus. The diagram shows how a single user-assigned identity named `id-rms-shared-${environment}` can be assigned to multiple App Services, reducing RBAC management overhead from N individual role assignments per service to a single centralized role assignment per target resource.",
        "The architecture diagram illustrates the phased migration strategy (referenced in Priority Recommendation #1 in Section 10) for eliminating stored credentials currently held in Azure Key Vault. The current state, visualized in the diagram's \"Before\" pane, shows App Services retrieving connection strings from Key Vault secrets (`AzureWebJobsStorage`, `SqlConnectionString`, `ServiceBusConnectionString`) at startup and passing them to SDK clients like `ServiceBusClient`. This pattern, while encrypted at rest, still involves credentials existing in memory and configuration, creating breach risk if application code is compromised or misconfigured logging exposes connection strings. The target state, shown in the \"After\" pane, demonstrates managed identity-based authentication where the `ServiceBusClient` constructor receives a `DefaultAzureCredential` token provider instead of a connection string—the Azure SDK automatically obtains an access token from the Azure Instance Metadata Service (IMDS) using the resource's managed identity, authenticates to Service Bus, and handles token refresh without any secrets ever touching application code. The diagram notes that this migration has zero breaking changes to business logic; only the infrastructure-as-code Bicep templates and authentication initialization code require modification.",
        "The diagram meticulously documents the least-privilege RBAC role assignments required for each microservice when using managed identity authentication, directly addressing the \"stored credentials\" security gap identified in the Executive Summary. The",
        "managed identity receives: `Key Vault Crypto User` (to retrieve Always Encrypted column encryption keys without managing secrets), `Azure SQL Database Contributor` (to execute SQL queries via Azure AD authentication), and `Azure Service Bus Data Sender` (to publish case events to the `case-events` topic). The",
        "managed identity receives: `Azure Service Bus Data Receiver` on the `route-commands` subscription and `Azure Service Bus Data Sender` for publishing completion acknowledgments back to status topics. The",
        "receive read-only roles: `Storage Blob Data Reader` for accessing case documents and `Search Index Data Contributor` for updating Azure AI Search indexes. This granular role decomposition, annotated in the diagram with resource scopes, ensures that even if a service is compromised through an application vulnerability, the attacker gains only narrowly scoped permissions—a compromised Search Function cannot modify SQL data or access encryption keys, limiting blast radius.",
        "The diagram highlights one of Managed Identity's strongest security advantages:",
        "handled entirely by the Azure platform. Unlike connection strings or service principal client secrets that require 90-day rotation workflows (with associated risk of expired credentials causing outages), managed identity access tokens are short-lived (1-hour validity) and automatically refreshed by the Azure SDK's credential chain without application involvement. The diagram illustrates the token acquisition flow: (1) Application code calls `serviceBusClient.SendMessageAsync()`, (2) Azure SDK's `DefaultAzureCredential` detects it's running in an Azure managed environment, (3) SDK queries the Instance Metadata Service (IMDS) endpoint `http://169.254.169.254/metadata/identity/oauth2/token` with the resource's managed identity, (4) IMDS authenticates the caller via Azure fabric identity proof and returns a signed JWT token with `aud` claim matching Service Bus's resource ID, (5) SDK includes the token in the `Authorization: Bearer` header of Service Bus API calls. This entire flow completes in milliseconds. When the token nears expiration (50 minutes into its 60-minute lifetime), the SDK proactively refreshes it using the same IMDS mechanism. This lifecycle management eliminates the operational burden of maintaining credential rotation runbooks and removes the risk of developers hardcoding secrets in application configuration \"temporarily\" during troubleshooting.",
        "As emphasized in the diagram's benefits callout and explicitly referenced in Section 10's Priority Recommendations table (Priority #1: \"Implement Managed Identities for all services - 2-3 week effort - Eliminate credential management, reduce breach risk\"), the managed identity architecture achieves the security ideal of",
        ". The diagram contrasts the current Key Vault-based approach (where `appsettings.json` contains `\"KeyVaultUri\": \"https://kv-rms-prod.vault.usgovcloudapi.net/\"`, still a piece of infrastructure knowledge) with the managed identity approach (where configuration contains only `\"ServiceBusNamespace\": \"sb-rms-prod.servicebus.usgovcloudapi.net\"`, a non-sensitive routing target). Even if an attacker gains read-access to application configuration files or environment variables, they obtain zero authentication materials. This architecture satisfies CJIS Security Policy 5.10.1's requirement for Advanced Authentication by eliminating static credentials entirely, replacing them with cryptographically signed identity proof that cannot be exfiltrated or replayed outside the Azure environment. The migration to managed identities is the single highest-impact security improvement the RMS architecture can implement, and the diagram provides the technical blueprint for executing this transformation across all 15+ compute and data services in the topology.\n\n### CJIS Compliance Gaps\n\n| CJIS Policy Area | Status | Priority | Action Required |\r\n|---|---|---|---|\r\n|",
        "| MISSING | Critical | Evaluate Azure Gov CJIS Management Agreement |\r\n|",
        "| MISSING | Critical | Fingerprint background checks for CJI access |\r\n|",
        "| MISSING | Critical | Document FIPS 140 compliance of all MFA methods |\r\n|",
        "| MISSING | Critical | Sign with Microsoft |\r\n|",
        "| Partial | High | Extend to all CJI touchpoints, 7+ year retention |\r\n|",
        "| Partial | High | Session lock, account lockout thresholds |\r\n|",
        "| MISSING | High | Formal training program |\r\n|",
        "| MISSING | High | Baseline configs, change control |\r\n|",
        "| MISSING | High | Vulnerability scanning, integrity monitoring |\r\n|",
        "| MISSING | High | Control Microsoft engineer access |\r\n|",
        "| MISSING | Medium | Deploy built-in CJIS compliance policies |\r\n|",
        "| MISSING | Medium | Formal agreements with external systems |\r\n|",
        "| Partial | Medium | Formal plan with exercise schedule |",
        "Case records (PII)",
        "Evidence files",
        "Audit logs",
        "Integration messages",
        "Aggregated statistics",
        "AI training data",
        "PII Removal and K-Anonymity Implementation:",
        "field-level PII scrubbing",
        "k-anonymity enforcement",
        "Re-identification Risk Assessment Methodology:",
        "CJIS Security Policy 5.4 Audit Requirements Compliance:",
        "Data Masking Layers and AI-Ready Architecture Integration:",
        "Row-level filtering",
        "Field-level redaction",
        "Aggregation-level suppression",
        "## 8. Disaster Recovery Topology\n\n| Component | RPO (Data Loss) | RTO (Downtime) | Replication | Failover |\r\n|-----------|----------------|----------------|-------------|----------|\r\n|",
        "| \\< 5 seconds | \\< 60 minutes | Sync geo-replication | Automatic (failover group) |\r\n|",
        "| Metadata only | \\< 10 minutes | Geo-DR pairing | Manual alias switch |\r\n|",
        "| \\< 15 minutes | \\< 1 hour | RA-GRS | Manual DNS update |\r\n|",
        "| Manual backup | \\< 2 hours | Backup/restore | Manual restore |\r\n|",
        "| N/A (stateless) | \\< 15 minutes | Warm standby | DNS switch + scale up |\r\n|",
        "| N/A | \\< 5 minutes | Global (built-in) | Automatic health probes |\n\n### Azure SQL Failover Group Configuration\n\n<ZoomableImage src=\"/images/arch/Azure%20SQL%20Failover%20and-2026-02-23-170534.png\" alt=\"Azure SQL Failover and Geo-Replication Architecture\" caption=\"Azure SQL failover group configuration with active-passive replication and automatic failover\" />",
        "The diagram illustrates the Azure SQL Database failover group implementation that provides automated geo-redundancy for the RMS transactional database. The architecture deploys an",
        "configuration with the primary database in US Gov Virginia handling all read/write traffic and a continuously synchronized secondary replica in US Gov Arizona maintained in hot standby mode. Unlike active-active configurations that distribute writes across regions (which would introduce complex conflict resolution for case management transactions), the active-passive model ensures strong consistency—every committed transaction on the primary is synchronously replicated to the secondary before the commit acknowledgment is returned to the application, guaranteeing zero data loss (RPO = 0) for committed transactions. The diagram shows the failover group listener endpoints that abstract the physical database locations from application connection strings, enabling transparent failover without application code changes.",
        "The RPO target of \"\\< 5 seconds\" documented in the table above represents the maximum age of the most recent transaction that could be lost during an unplanned primary region outage. Azure SQL's active geo-replication technology, visualized in the diagram's replication flow, achieves this aggressive RPO through a",
        "mechanism that streams transaction log records from the primary to the secondary over the Azure backbone network with typical latency under 1 second. The diagram highlights the asynchronous commit mode used to balance data durability with application performance—transactions commit on the primary after writing to local durable storage, then replication to the secondary occurs in the background. This approach prevents cross-region network latency (approximately 50ms between Virginia and Arizona) from blocking user-facing transactions. In the rare scenario where the primary region fails before recent transactions replicate, the failover process implements",
        ", alerting operators to the last successfully replicated transaction timestamp so business users can manually reconcile any lost case updates.",
        "The diagram presents a critical architectural decision point: configuring the failover group for automatic failover versus manual failover.",
        "(recommended in the diagram with a 60-minute grace period) triggers when the primary database becomes unreachable for longer than the configured detection timeout. Azure's health probe system continuously monitors database availability every 30 seconds, and after 4 consecutive failures (2 minutes of downtime), begins a 60-minute waiting period to distinguish between transient network issues and genuine regional outages. If the primary remains unavailable after this grace period, the system automatically promotes the secondary to primary, updates DNS records for the failover group listener, and sends Azure Monitor alerts to the operations team.",
        ", alternatively, requires an authorized operator to explicitly invoke the failover command via Azure Portal, CLI, or automation runbook. The diagram recommends automatic failover for production RMS environments to minimize downtime during after-hours or weekend regional outages, but notes that manual failover provides greater control for planned maintenance scenarios where operators want to validate application state before cutting over.",
        "Application services (RMS API, Routing Service, Search Service) use the failover group listener connection strings shown in the diagram rather than connecting directly to specific database servers. The architecture provisions two listener endpoints: a",
        "(e.g., `rms-failover-group.database.usgovcloudapi.net`) that always points to the current primary database and automatically updates during failover, and a",
        "(e.g., `rms-failover-group.secondary.database.usgovcloudapi.net`) that explicitly targets the secondary replica for offloading read-intensive reporting queries. The diagram illustrates how the RMS Core API uses the read/write listener for transactional case management operations, while the reporting dashboard and analytics queries connect to the read-only endpoint to prevent report generation from impacting officer productivity. During failover, the read/write listener's DNS record is updated within 5 minutes (contributing to the 60-minute total RTO), and application connection pools automatically reconnect to the newly promoted primary. This listener-based approach eliminates the need for application code to implement region-aware routing logic or maintain multiple connection string configurations per environment.\n\n### RPO/RTO Objectives and Recovery Prioritization\n\n<ZoomableImage src=\"/images/arch/RPO_RTO%20Objectives%20and-2026-02-23-170624.png\" alt=\"RPO/RTO Objectives and Tier-Based Recovery\" caption=\"Recovery objectives with tier-based prioritization for business continuity\" />",
        "The diagram illustrates the comprehensive Recovery Point Objective (RPO) and Recovery Time Objective (RTO) targets mapped to critical RMS business processes, derived from stakeholder interviews with patrol officers, detectives, dispatch supervisors, and IT operations staff. The architecture implements a",
        "(Tier 0: Critical, Tier 1: Important, Tier 2: Normal) that acknowledges not all system components require the same aggressive recovery targets. Tier 0 components—the RMS Core API for active case management, Azure SQL Database for transactional case records, and Azure Front Door for officer access—have the most stringent targets (RPO \\< 5 seconds, RTO \\< 60 minutes) because their unavailability directly prevents officers from documenting incidents in the field or accessing case histories during traffic stops. Tier 1 components like the Routing Service for external integrations and Service Bus message queues have relaxed targets (RPO \\< 15 minutes, RTO \\< 2 hours) since temporary delays in submitting cases to MNCIS or NIBRS do not immediately impact field operations. Tier 2 components such as the reporting dashboard and analytics queries tolerate even longer outages (RTO \\< 8 hours) as they support administrative workflows rather than real-time public safety operations.",
        "The RPO targets annotated in the diagram represent the maximum amount of recent data the organization is willing to lose during a disaster scenario, informed by cost-benefit analysis of replication technology investments versus business impact. For the RMS transactional database, the RPO \\< 5 seconds target means that in a catastrophic primary region failure, officers might need to re-enter up to 5 seconds of case updates manually—potentially affecting 1-2 active case submissions during peak activity hours. This narrow data loss window justifies the investment in Azure SQL active geo-replication (which incurs egress costs for cross-region data transfer and requires doubling database compute/storage costs for the secondary replica). For Service Bus message queues with RPO \\< 15 minutes, the organization accepts that messages published in the 15 minutes before a disaster might be lost, requiring manual resubmission of affected case routing requests identified through Application Insights distributed tracing logs. This decision balances the cost of Service Bus Premium geo-disaster recovery pairing (~$2,500/month) against the operational impact of occasionally reprocessing a small batch of integration messages.",
        "The RTO targets in the diagram directly correlate to quantified downtime costs that justify disaster recovery infrastructure investments. Internal analysis (detailed in the \"DR Cost Model\" section of the operational playbooks) estimates that complete RMS unavailability costs approximately",
        "in officer productivity loss (officers reverting to paper forms, delayed case filings causing court continuances, inability to access warrant information during traffic stops). The Tier 0 RTO \\< 60 minutes target therefore limits worst-case financial exposure to $15,000 for a single regional outage, compared to potential 8-12 hour recovery times without geo-redundancy that could exceed $180,000 in impact. The diagram shows how this cost model drove the decision to implement automatic SQL failover, warm standby App Service deployments in the secondary region, and Azure Front Door's built-in multi-region routing—collectively adding approximately $8,000/month in infrastructure costs but protecting against potentially catastrophic business disruptions.",
        "The diagram references a rigorous DR testing program designed to validate that actual recovery times match the documented RTO targets. The architecture mandates",
        "(scheduled 90 days apart, documented in Azure DevOps work items) where the operations team deliberately fails over to the secondary region during a planned maintenance window, measures time-to-recovery for each component, and documents discrepancies. The diagram illustrates the test procedure: (1) Announce test window to stakeholders, (2) Trigger SQL failover group promotion, (3) Update App Service deployment slots to secondary region, (4) Validate application functionality with smoke tests, (5) Measure and record actual RTO/RPO achieved, (6) Conduct post-mortem to identify process improvements. This testing discipline ensures that DR runbooks remain accurate as the architecture evolves and that operations staff maintain proficiency in failover procedures. Test results are aggregated in the",
        "(visible in the diagram) that tracks failover success rate, average RTO variance from target, and runbook accuracy metrics, providing executive leadership with confidence in disaster recovery preparedness.\n\n### Reliability Recommendations\n\n| Item | Current State | Recommendation | Effort |\r\n|------|--------------|----------------|--------|\r\n|",
        "| No documented plan | Define RTO/RPO, create runbooks | 1 week |\r\n|",
        "| Single-region | Enable geo-replication to secondary | 2 weeks |\r\n|",
        "| Standard tier | Upgrade to Premium for geo-DR | 2 weeks |\r\n|",
        "| Basic monitoring | Comprehensive health checks per service | 1 week |\r\n|",
        "| Limited | Exponential backoff + circuit breakers | 2 weeks |\r\n|",
        "| Never tested | Quarterly failover drills | Ongoing |",
        "Enhanced Search",
        "Form Extraction",
        "Report Writing Assist",
        "Case Duration Prediction",
        "## 10. Implementation Roadmap\n\n| Phase | Focus | Key Deliverables | Dependencies |\r\n|-------|-------|-----------------|-------------|\r\n|",
        "| Planning | Approved roadmap, answered questions, deep-dive sessions | Stakeholder alignment |\r\n|",
        "| Security | Managed Identities, TDE/CMK, Private Link, CJIS addendum | Phase 0 complete |\r\n|",
        "| Reliability | Geo-replication, DR plan, health monitoring, tested failover | Phase 1 foundations |\r\n|",
        "| Operations | Distributed tracing, Sentinel SIEM, dashboards, alerting | Phase 2 health endpoints |\r\n|",
        "| Performance | Redis cache, auto-scaling, load testing, API versioning | Phase 3 monitoring |\r\n|",
        "| AI | Data segregation, anonymization pipeline, AI Search POC | Phase 1 + Phase 3 |",
        "## Appendix\n\n### A. RBAC Role Matrix\n\n<ZoomableImage src=\"/images/arch/User%20Role%20Access%20Management-2026-02-23-171421.png\" alt=\"User Role Access Management\" caption=\"RBAC architecture showing authentication flow, Conditional Access policies, and role-based permissions\" />\n\n#### Visual RBAC Flow and Access Control Architecture\n\nThe User Role Access Management diagram provides a comprehensive visualization of the role-based access control (RBAC) flow across all system layers, from Azure Active Directory (Entra ID) authentication through API Management authorization, application-level permission enforcement, and database-level row security. This end-to-end RBAC architecture implements defense-in-depth access control aligned with",
        "requirements, ensuring that access privileges are validated at every trust boundary and that no single layer's compromise can bypass authorization checks. The diagram directly maps to the RBAC Role Matrix table below, illustrating how organizational roles (Patrol Officer, Detective, Supervisor, Admin) translate into technical permissions across Azure infrastructure, application code, and data storage layers.",
        "The diagram traces the complete authentication and authorization path for a typical user request.",
        ": Officers authenticate using their organizational credentials (`officer.smith@dakotacounty.gov`), with Multi-Factor Authentication (MFA) enforcement via Conditional Access policies that require Authenticator app approval and compliant device check (Azure AD Join or Intune MDM enrollment). Upon successful authentication, Entra ID issues a",
        "containing user claims: `oid` (unique user object ID), `roles` (array of assigned application roles: `[\"PatrolOfficer\", \"CJIUser\"]`), `groups` (Azure AD security group memberships: `[\"RMS-DakotaSheriff-Users\"]`), and `tid` (tenant ID for multi-tenant isolation, referencing Section 1.6). This JWT token serves as the user's identity credential for all subsequent API calls.",
        ": Azure APIM validates the JWT token signature against Entra ID's public signing keys (JWKS endpoint), verifies token expiration and issuer claims, and extracts the `roles` claim for initial authorization checks. APIM policies implement coarse-grained authorization: `<validate-jwt>` policy blocks requests without valid tokens, `<check-header>` policy requires TLS client certificates for API-to-API calls, and `<rate-limit-by-key>` policy enforces per-role quotas (patrol officers limited to 60 requests/minute, detectives allowed 200 requests/minute to support high-volume investigative queries).",
        ": RMS App Service receives the validated JWT and performs fine-grained authorization using ASP.NET Core's `[Authorize(Roles = \"Detective\")]` attributes on controller actions. The application code inspects claims to enforce business rules: patrol officers can read only their own cases (`if (currentUser.OfficerId != case.CreatedByOfficerId) throw new ForbiddenException()`), while detectives can read all cases within their department (`if (currentUser.Department != case.Department) throw new ForbiddenException()`).",
        ": Azure SQL Database enforces row-level security (RLS) policies that automatically filter query results based on the `Managed Identity` or `SQL User` principal executing the query. For tenant isolation, RLS appends `WHERE TenantId = SESSION_CONTEXT('TenantId')` to all SELECT statements, with the application setting session context after authentication. This layered access control ensures that even SQL injection vulnerabilities cannot bypass authorization—the database engine enforces access restrictions independently of application code.",
        "The diagram details the Conditional Access policy evaluation chain that occurs during Entra ID authentication, implementing Zero Trust principles where every authentication request is evaluated against dynamic risk signals. Conditional Access policies are configured with",
        "(Require MFA, Require compliant device, Require hybrid Azure AD joined device) and",
        "(Application enforced restrictions, Conditional Access App Control with Microsoft Defender for Cloud Apps monitoring). The evaluation flow follows a decision tree: (1) user initiates authentication → (2) Entra ID checks user's location (is the request originating from known Dakota County IP ranges or via VPN?) → (3) device compliance check (is the device Intune-managed with required security patches?) → (4) user risk score (has this account been observed in credential leak databases or exhibiting anomalous behavior patterns?) → (5) sign-in risk score (is this login attempt from an impossible travel scenario, e.g., Minneapolis 10 minutes ago, now Moscow?). If any risk signal exceeds thresholds (user risk: High, sign-in risk: Medium), Conditional Access",
        "the authentication and requires security team remediation. If risk signals are acceptable, Conditional Access grants a session token with",
        ": standard users receive 8-hour tokens requiring re-authentication each shift, while external partner accounts receive 1-hour tokens with reauthentication prompts. These session controls are visualized in the diagram as decision gates between Entra ID and the application layer, emphasizing that authentication is continuously evaluated rather than a one-time check.",
        "The diagram prominently features the",
        "for administrative access to production resources, implementing time-bound, approval-gated privilege elevation. Standard operational procedures dictate that database administrators and infrastructure engineers hold",
        "(Contributor on RMS-Core-RG, Owner on RMS-Shared-RG) but do not have",
        "by default. When an engineer requires elevated access for incident response, they initiate a",
        "via the Azure Portal or PowerShell module, specifying: (1) requested role (Contributor on RMS-Core-RG), (2) duration (maximum 4 hours), (3) business justification (\"investigating P1 incident #12345 - API Gateway 502 errors\"), and (4) optionally attaching an approved Change Request ticket ID. The PIM workflow routes the request to designated",
        "(two infrastructure architects must approve), who receive notifications via Microsoft Teams and email with full context (requester identity, requested scope, justification, approval deadline). If approved within 15 minutes, PIM grants the requested role for the specified duration and logs the activation to Azure Activity Log and Microsoft Sentinel. After 4 hours, the role assignment",
        ", requiring reactivation if additional access is needed. This JIT access model—critical for CJIS compliance—ensures that administrative privileges are time-limited, auditable, and require peer approval, drastically reducing the attack surface compared to permanent global administrator assignments. The diagram maps PIM activation to the",
        "row in the RBAC Role Matrix below, showing that full access is gated by \"(via PIM)\" annotations.",
        "The architecture implements a",
        "strategy for emergency scenarios where normal authentication mechanisms fail (Entra ID outage, MFA provider unavailable, Conditional Access policy misconfiguration locking out all administrators). Two break-glass accounts (`bg-admin-001@dakotacounty.onmicrosoft.com`, `bg-admin-002@dakotacounty.onmicrosoft.com`) are provisioned with",
        "privileges and",
        ". These accounts are secured with 64-character randomly-generated passwords stored in a physical safe (with dual-access control requiring two executives) and monitored continuously—any authentication event using break-glass accounts triggers",
        "to the security team and executive leadership. The accounts are tested quarterly during disaster recovery drills to validate they remain functional and passwords are rotated annually with witness verification. The diagram shows break-glass accounts as a separate authentication path bypassing normal RBAC flows, with a direct line to resource access layers marked \"EMERGENCY ONLY - FULLY AUDITED\". This contingency access pattern balances business continuity (preventing lockout scenarios) with security rigor (extensive logging, physical security controls, quarterly accountability reviews).",
        "The RBAC architecture directly implements CJIS requirements for personnel security:",
        "verified through background check flags in Entra ID user profiles (`extensionAttribute1: \"BackgroundCheckCompleted-2025-06-15\"`),",
        "enforced via mandatory annual CJIS training completion records that gate access (Conditional Access policy: `if (user.trainingExpiry < today) deny()`), and",
        "implemented via distinct roles with non-overlapping permissions (patrol officers cannot approve supervisor actions, analysts cannot access PII fields). The diagram cross-references these CJIS controls, annotating each access layer with the applicable policy section. Audit logs—captured at Entra ID sign-ins, APIM gateway requests, application-level authorization decisions, and SQL Database row access—provide",
        "for compliance audits, enabling investigators to reconstruct complete access histories: \"which users accessed Case #12345's evidence photos during the investigation period?\". These logs are exported to Azure Log Analytics, retained for 7 years per CJIS requirements, and protected with immutable storage (Azure Blob WORM policy) to prevent tampering.",
        "The architecture supports",
        "via Entra ID B2B (business-to-business) collaboration, enabling prosecutors from Hennepin County or state investigators from BCA to access shared cases without creating duplicate user accounts. Guest users authenticate with their home organization's credentials (e.g., `@hennepin.us` Entra ID tenant) and receive",
        "scoped to specific cases or evidence items. The RBAC diagram illustrates the guest user flow: external user authenticates to Hennepin County Entra ID → cross-tenant token minted by Dakota County Entra ID (home tenant provides identity, resource tenant provides authorization) → guest user receives restricted permissions (Read-Only access to assigned cases, no download/print rights, watermarked evidence previews). Guest access sessions are limited to",
        "with explicit reauthentication after session expiry, and all guest user activities generate",
        "logged to Microsoft Sentinel for security monitoring. The diagram maps guest users to the",
        "row in the RBAC Role Matrix, specifying \"API Scoped\" and \"Per Agreement\" constraints. This B2B integration pattern—replacing insecure email attachments or FTP file shares—provides secure, auditable, time-limited collaboration with external law enforcement agencies while maintaining tenant isolation (external users never receive native Entra ID accounts in Dakota County's directory).\n\n#### RBAC Role Matrix Table\n\n| Role | Cases | Evidence | Admin | Reports | Integration | CJIS Level |\r\n|------|-------|----------|-------|---------|-------------|------------|\r\n|",
        "| Create/Read Own | Upload | None | Own Dept | None | CJI Access |\r\n|",
        "| Read/Update All in Dept | Full Access | None | Dept-wide | None | CJI Access |\r\n|",
        "| Full Dept Access | Full Access | User Mgmt | All Reports | Config | CJI Access |\r\n|",
        "| All (via PIM) | All (via PIM) | Full | All | Full | CJI + Background Check |\r\n|",
        "| Read (de-identified) | None | None | Aggregated | None | Non-CJI |\r\n|",
        "| API Scoped | None | None | None | Specific API | Per Agreement |\n\n### B. CI/CD Pipeline Stages\n\n<ZoomableImage src=\"/images/arch/Azure%20DevOps%20CI_CD%20Pipeline-2026-02-23-170737.png\" alt=\"Azure DevOps CI/CD Pipeline Architecture\" caption=\"CI/CD pipeline showing build stages, approval gates, and deployment workflow\" />\n\n#### Deployment Pipeline Architecture and Infrastructure as Code\n\nThe Azure DevOps CI/CD pipeline diagram illustrates the comprehensive continuous integration and continuous deployment workflow that automates the delivery of application code and infrastructure changes to the CJN Dakota RMS environment. This pipeline architecture implements best practices for security scanning, approval gates, and automated rollback mechanisms to ensure production deployments meet CJIS compliance requirements while enabling rapid iteration velocity. The pipeline integrates with the Bicep Infrastructure-as-Code (IaC) toolchain referenced in Section 1's",
        "table (\"IaC: Bicep + Azure DevOps\"), providing a declarative, version-controlled approach to managing all Azure resources.",
        "The diagram illustrates the Git branching model: developers work in",
        "(`feature/case-search-enhancement`), which merge to the",
        "via pull requests (PRs) that trigger automated CI builds, unit tests, and Static Application Security Testing (SAST) scans. Once validated in the develop environment, changes are promoted to the",
        "through a gated PR requiring two code reviewer approvals and passing integration tests. The main branch automatically deploys to the",
        "after manual approval from the release manager. Azure Repos enforces branch policies: direct commits to main or develop are blocked, PR authors cannot approve their own PRs, and all PRs must include linked Azure DevOps work items (user stories, bugs) for traceability. This branching strategy—based on GitFlow—prevents untested code from reaching production and maintains a clean audit trail for CJIS compliance (\"who deployed what, when, and why\").",
        "The infrastructure deployment pipeline (triggered by commits to the `infra/` directory) executes a multi-stage workflow visualized in the diagram: (1)",
        ": validate `.bicep` files with `az bicep build` to catch syntax errors, (2)",
        ": run `az deployment group what-if` to preview infrastructure changes without applying them (e.g., \"This will create 3 new resources, modify 1 existing resource, and delete 0 resources\"), (3)",
        ": block deployment until two infrastructure engineers approve the what-if diff, (4)",
        ": execute `az deployment group create --mode Incremental` to apply only the delta changes, preserving existing resources not defined in Bicep templates, (5)",
        ": validate critical resource configurations (e.g., verify App Service has VNet integration enabled, confirm Key Vault has purge protection), and (6)",
        ": publish a summary to the Azure DevOps pipeline run with links to Azure Portal resource groups. This IaC approach eliminates manual Azure Portal clicking, provides disaster recovery capability (re-deploy entire infrastructure from Git history), and enables infrastructure drift detection (comparing actual Azure state to Bicep templates via what-if analysis).",
        "The diagram highlights three critical manual approval stages:",
        "(requires QA team sign-off after smoke tests pass),",
        "(requires release manager approval with mandatory 4-hour delay for business hours deployments), and",
        "(requires dual approval from infrastructure architects for security-sensitive changes like NSG rule modifications or Private Link configurations). Each approval gate integrates with Azure DevOps Approvals API, which sends notifications to Microsoft Teams channels and enforces timeout policies (approvals expire after 24 hours, blocking stale deployments). For emergency hotfixes, the pipeline supports a \"fast-track\" path that bypasses the stage environment and deploys directly to production, but requires dual approval and generates a high-severity audit log entry for post-incident review. These approval gates balance deployment velocity (multiple deployments per day to dev/stage) with production stability (zero unplanned downtime in 6 months, per customer interviews).",
        "The pipeline implements automated rollback capability using Azure App Service deployment slots. Each production deployment first publishes to a",
        ", performs health checks (HTTP 200 responses, Application Insights availability tests, synthetic transaction validation), and then swaps the staging slot to production using `az webapp deployment slot swap`. If post-deployment health checks fail—indicated by error rate exceeding 1% within 5 minutes or Application Insights anomaly detection triggering—the pipeline automatically swaps back to the previous version within 60 seconds, restoring service. The diagram shows the version tagging strategy: every successful deployment tags the Git commit with the semantic version (`v2.3.15`) and deployment timestamp, creating an immutable release history. These tags enable point-in-time rollback: operators can redeploy any previous version by triggering the pipeline with a specific Git tag as the source. For infrastructure changes, Bicep templates are tagged similarly (`infra-v1.2.0`), and Azure Policy assignments enforce tagging requirements on all resources (\"all resources must have tags: Environment, Owner, CostCenter, Version\").",
        "The pipeline includes a nightly scheduled job (visualized in the diagram as a separate pipeline trigger) that runs `az deployment group what-if` against production resource groups to detect configuration drift—manual changes made outside the CI/CD pipeline (e.g., an engineer adjusting NSG rules via Azure Portal). If drift is detected, the pipeline creates a high-priority Azure DevOps work item with a detailed diff and alerts the infrastructure team. This drift detection—combined with Azure Resource Graph queries that identify untagged or non-compliant resources—ensures the production environment matches the declarative Bicep templates. The diagram also highlights",
        "integration, which scans Infrastructure-as-Code templates for security misconfigurations (e.g., storage accounts without encryption, Key Vaults with public network access enabled) and blocks deployments with critical findings. Defender for DevOps extends to application code scanning, integrating SAST tools (Checkmarx, SonarQube) and Software Composition Analysis (SCA) tools (WhiteSource, Snyk) to identify vulnerable dependencies (CVEs in NuGet packages) and code quality issues (SQL injection risks, hardcoded secrets). These security scans run in parallel during the CI build stage, failing the build if critical vulnerabilities are detected, thus preventing vulnerable code from reaching production.\n\n| Stage | Trigger | Gate | Failure Action |\r\n|-------|---------|------|---------------|\r\n|",
        "| PR or merge to main | Automated (compilation) | Block merge |\r\n|",
        "| CI pipeline | 90%+ coverage required | Block merge |\r\n|",
        "| CI pipeline | No critical vulnerabilities | Block merge |\r\n|",
        "| Merge to main | Smoke tests pass | Alert team |\r\n|",
        "| Manual promote | QA approval required | Block promotion |\r\n|",
        "| Manual approval | Error rate \\< 1% | Auto-rollback |\r\n|",
        "| PR to infra/ branch | Peer review + what-if | Block apply |\n\n### C. Monitoring Alert Thresholds\n\n| Metric | Warning | Critical | Response |\r\n|--------|---------|----------|----------|\r\n|",
        "| > 2 seconds | > 5 seconds | Scale out App Service |\r\n|",
        "| > 1% | > 5% | Page on-call, initiate rollback |\r\n|",
        "| > 70% | > 90% | Auto-scale (configured) |\r\n|",
        "| > 5 | > 20 | Investigate failed integrations |\r\n|",
        "| > 70% | > 90% | Scale database tier |\r\n|",
        "| > 5/min | > 20/min | Sentinel auto-block IP |\r\n|",
        "| > 1000 | > 5000 | Scale consumers |\r\n|",
        "| \\< 30 days | \\< 7 days | Auto-renew or page team |\n\n### D. Data Lifecycle Storage Tiers\n\n| Phase | SQL Tier | Blob Tier | Cache | Transition |\r\n|-------|----------|-----------|-------|------------|\r\n|",
        "(0-90 days) | General Purpose | Hot | Redis cached | Manual |\r\n|",
        "(90d - 2y) | General Purpose | Cool (auto at 90d) | Evicted | Lifecycle policy |\r\n|",
        "(2-7 years) | Partitioned archive | Archive (auto at 730d) | None | Lifecycle policy |\r\n|",
        "(7+ years) | Purge (legal hold check) | Purge (WORM check) | N/A | Manual + approval |\n\n### E. Pillar Maturity Assessment\n\n| Pillar | Sub-Area | Current | Target | Gap | Priority |\r\n|--------|----------|---------|--------|-----|----------|\r\n|",
        "| Identity Management | 7/10 | 9/10 | 2 | High |\r\n|",
        "| Data Protection | 6/10 | 9/10 | 3 | Critical |\r\n|",
        "| Network Security | 7/10 | 9/10 | 2 | High |\r\n|",
        "| CJIS Compliance | 6/10 | 9/10 | 3 | Critical |\r\n|",
        "| Disaster Recovery | 4/10 | 9/10 | 5 | Critical |\r\n|",
        "| Health Monitoring | 5/10 | 8/10 | 3 | High |\r\n|",
        "| Resilience Patterns | 6/10 | 8/10 | 2 | Medium |\r\n|",
        "| Observability | 5/10 | 8/10 | 3 | High |\r\n|",
        "| CI/CD Maturity | 7/10 | 9/10 | 2 | Medium |\r\n|",
        "| Incident Response | 4/10 | 8/10 | 4 | High |\r\n|",
        "| Caching Strategy | 3/10 | 8/10 | 5 | High |\r\n|",
        "| Auto-Scaling | 4/10 | 8/10 | 4 | Medium |\r\n|",
        "dependsOn",
        "Stop-AzWebApp",
        "Set-AzSqlDatabase -RequestedServiceObjectiveName 'Basic'",
        "RMS-DakotaSheriff-Users",
        "RMS-DakotaSheriff-Admins",
        "RMS-DakotaSheriff-RG",
        "dakota_sheriff",
        "sb-dakotasheriff-prod",
        "TenantId",
        "DatabaseSchema",
        "ServiceBusNamespace",
        "BillingCode",
        "RMS-DakotaSheriff-AppService-Identity",
        "rate-limit-by-key",
        "ORI Number",
        "dakota-sheriff",
        "city-police-dept",
        "CC-2001-DakotaSheriff",
        "SharedCost * (TenantAPIRequests / TotalAPIRequests)",
        "SELECT * FROM Cases",
        "SELECT * FROM Cases WHERE TenantId = 'dakota-sheriff'",
        "WHERE TenantId",
        "city_police_dept",
        "rms-sql-prod-001",
        "rms-sql-prod-002",
        "snet-data /24",
        "snet-rms-app",
        "snet-route-app",
        "snet-search-app",
        "traceparent",
        "TraceId",
        "SpanId",
        "CorrelationId",
        "CaseCreated",
        "func-search-indexer",
        "func-mncis-router",
        "Operation_ParentId",
        "Operation_Id == '...'",
        "Microsoft.ApplicationInsights.DependencyCollector",
        "case-events",
        "route-commands",
        "search-index",
        "CaseId",
        "DestinationId",
        "mncis-router",
        "nibrs-router",
        "ecite-router",
        "maarc-router",
        "crash-router",
        "dest = 'MNCIS'",
        "dest = 'NIBRS'",
        "Destination",
        "DLQ Processor Function",
        "ServiceBusAdministrationClient",
        "func-nibrs-sender",
        "EventId",
        "EventType",
        "AggregateId",
        "Timestamp",
        "UserId",
        "Payload",
        "SchemaVersion",
        "CorrelationId = abc123",
        "CaseCreated_v2",
        "OfficerBadgeNumber",
        "v2",
        "v1",
        "audit-events",
        "ServiceBusClient",
        "CaseId % 10",
        "func-case-processor",
        "func-audit-logger",
        "ServiceBusTrigger",
        "[ServiceBusTrigger(\"case-events\", \"case-processor\", IsSessionsEnabled = true)]",
        "host.json",
        "maxConcurrentSessions = 8",
        "maxConcurrentCalls = 1",
        "prefetchCount = 32",
        "autoCompleteMessages = false",
        "func-dlq-processor",
        "processed:{EventId}",
        "SessionId",
        "CaseUpdated",
        "IMessageSession.AcceptSessionAsync(sessionId)",
        "WaitAndRetryAsync",
        "CircuitBreakerAsync",
        "func-mncis-sender",
        "ServiceBusSender",
        "id-rms-shared-${environment}",
        "AzureWebJobsStorage",
        "SqlConnectionString",
        "ServiceBusConnectionString",
        "DefaultAzureCredential",
        "Key Vault Crypto User",
        "Azure SQL Database Contributor",
        "Azure Service Bus Data Sender",
        "Azure Service Bus Data Receiver",
        "Storage Blob Data Reader",
        "Search Index Data Contributor",
        "serviceBusClient.SendMessageAsync()",
        "http://169.254.169.254/metadata/identity/oauth2/token",
        "aud",
        "Authorization: Bearer",
        "appsettings.json",
        "\"KeyVaultUri\": \"https://kv-rms-prod.vault.usgovcloudapi.net/\"",
        "\"ServiceBusNamespace\": \"sb-rms-prod.servicebus.usgovcloudapi.net\"",
        "rms-failover-group.database.usgovcloudapi.net",
        "rms-failover-group.secondary.database.usgovcloudapi.net",
        "officer.smith@dakotacounty.gov",
        "oid",
        "roles",
        "[\"PatrolOfficer\", \"CJIUser\"]",
        "groups",
        "[\"RMS-DakotaSheriff-Users\"]",
        "tid",
        "<validate-jwt>",
        "<check-header>",
        "<rate-limit-by-key>",
        "[Authorize(Roles = \"Detective\")]",
        "if (currentUser.OfficerId != case.CreatedByOfficerId) throw new ForbiddenException()",
        "if (currentUser.Department != case.Department) throw new ForbiddenException()",
        "Managed Identity",
        "SQL User",
        "WHERE TenantId = SESSION_CONTEXT('TenantId')",
        "bg-admin-001@dakotacounty.onmicrosoft.com",
        "bg-admin-002@dakotacounty.onmicrosoft.com",
        "extensionAttribute1: \"BackgroundCheckCompleted-2025-06-15\"",
        "if (user.trainingExpiry < today) deny()",
        "@hennepin.us",
        "feature/case-search-enhancement",
        "infra/",
        ".bicep",
        "az bicep build",
        "az deployment group what-if",
        "az deployment group create --mode Incremental",
        "az webapp deployment slot swap",
        "v2.3.15",
        "infra-v1.2.0",
        "br/public:avm/res/managed-identity/user-assigned-identity",
        "br/public:avm/res/sql/server",
        "br/public:avm/res/network/private-endpoint",
        "br/public:avm/res/key-vault/vault",
        "br/public:avm/res/service-bus/namespace",
        "br/public:avm/res/web/site",
        "br/public:avm/res/api-management/service",
        "br/public:avm/res/insights/component",
        "br/public:avm/res/cache/redis",
        "br/public:avm/res/cdn/profile"
      ]
    }
  },
  {
    "slug": "/basic-setup/changelog",
    "title": "Changelog",
    "description": "Changelogs and improvements to the Documents projects.",
    "content": "## Added\n\n**Linting and Formatting**:\n\n* Added `pnpm run lint` and `pnpm run lint:fix` scripts to automate linting tasks.\n* Added `pnpm run format` and `pnpm run format:check` scripts to ensure consistent code formatting.\n\n**SEO Enhancements**:\n\n* Added an SEO component to MDX pages to dynamically include `keywords` and `lastModified` metadata for improved SEO generation.\n\n## Updated\n\n**Next.js Upgrade**:\n\n* Upgraded the project from **Next.js 14** to **Next.js 15**, leveraging the latest features and performance improvements.\n\n**Codebase Improvements**:\n\n* Reordered imports across the project files for better consistency and readability.\n\n**Mermaid Component**:\n\n* Fixed an ID bug that caused rendering issues when multiple Mermaid diagrams were included in MDX pages.\n* Improved initialization and rendering logic to prevent duplicate diagram rendering.\n",
    "_searchMeta": {
      "cleanContent": "added linting and formatting: added pnpm run lint and pnpm run lint:fix scripts to automate linting tasks added pnpm run format and pnpm run format:check scripts to ensure consistent code formatting seo enhancements: added an seo component to mdx pages to dynamically include keywords and lastmodified metadata for improved seo generation updated next js upgrade: upgraded the project from next js 14 to next js 15 leveraging the latest features and performance improvements codebase improvements: reordered imports across the project files for better consistency and readability mermaid component: fixed an id bug that caused rendering issues when multiple mermaid diagrams were included in mdx pages improved initialization and rendering logic to prevent duplicate diagram rendering",
      "headings": [
        "Added",
        "Updated"
      ],
      "keywords": [
        "changelog",
        "guide",
        "nextjs",
        "documents",
        "Added",
        "Updated",
        "Linting and Formatting",
        "SEO Enhancements",
        "Next.js Upgrade",
        "Next.js 14",
        "Next.js 15",
        "Codebase Improvements",
        "Mermaid Component",
        "pnpm run lint",
        "pnpm run lint:fix",
        "pnpm run format",
        "pnpm run format:check",
        "keywords",
        "lastModified"
      ]
    }
  },
  {
    "slug": "/basic-setup",
    "title": "Introduction",
    "description": "This section provides an overview of how to get started with the Documents, Next.js Document Starter Kit.",
    "content": "![Banner](/images/banner.png \"Documents\")\n\n## Documents\n\n**Documents** is a lightweight, modular starter kit built with **Next.js**, **React**, **Tailwind CSS**, and **TypeScript**. It’s designed to help you\r\nlaunch structured, professional documentation without spending time on boilerplate.\n\nWhether you're building product manuals, internal systems guides, or dev documentation, Documents gives you a clean foundation that’s easy to\r\nextend and maintain.\n\n## Why use Documents?\n\nThis kit was built to simplify how teams manage and publish documentation. It works across projects of all sizes—from a single\r\nreadme to enterprise knowledge bases.\n\nWith MDX, reusable components, and Tailwind styling, it keeps your workflow efficient without compromising flexibility.\n\nUse it for:\n\n* **Product Guides** – Setup, usage, and troubleshooting\n* **Internal Docs** – Processes, policies, and team references\n* **Technical Manuals** – APIs, SDKs, architecture walkthroughs\n\nCustomize the UI and structure to match your brand or workflow—no lock-in.\n\n## Core Features\n\n| Feature                              | Description                                                                 |\r\n| ------------------------------------ | --------------------------------------------------------------------------- |\r\n| **Write in Markdown/MDX**            | Combine Markdown with components and Mermaid.js for rich content.           |\r\n| **Flexible Navigation**              | Multi-level menus, page hierarchy, and auto-generated TOCs.                 |\r\n| **Code Support**                     | Syntax highlighting, code tabs, and one-click copy.                         |\r\n| **Search**                           | Fuzzy matching with highlight and instant results.                          |\r\n| **Responsive Design**                | Built-in light/dark mode with mobile support.                               |\r\n| **Math + Tables**                    | LaTeX rendering and clean table styling.                                    |\r\n| **SEO Defaults**                     | Preconfigured meta, Open Graph, and structured data.                        |\r\n| **AI Docs (Upcoming)**               | AI tools for smart search and content generation (coming soon).             |\n\n## Using This Kit\n\nNavigation is on the left. Pages flow from setup to advanced features, but you're free to jump around.\n\nUse the table of contents on the right to skip through sections.\n\nStart with the [Installation Guide](/docs/basic-setup/installation).\n\n## Community Support\n\nGot questions? Reach out via:\n\n* [GitHub](https://github.com/rubixvi/rubix-documents)\n* [Twitter](https://x.com/rubixstory)\n* [Facebook](https://www.facebook.com/rubixstudios)\n",
    "_searchMeta": {
      "cleanContent": "banner documents documents is a lightweight modular starter kit built with next js react tailwind css and typescript it s designed to help you launch structured professional documentation without spending time on boilerplate whether you re building product manuals internal systems guides or dev documentation documents gives you a clean foundation that s easy to extend and maintain why use documents this kit was built to simplify how teams manage and publish documentation it works across projects of all sizes from a single readme to enterprise knowledge bases with mdx reusable components and tailwind styling it keeps your workflow efficient without compromising flexibility use it for: product guides setup usage and troubleshooting internal docs processes policies and team references technical manuals apis sdks architecture walkthroughs customize the ui and structure to match your brand or workflow no lock-in core features feature description ------------------------------------ --------------------------------------------------------------------------- write in markdown mdx combine markdown with components and mermaid js for rich content flexible navigation multi-level menus page hierarchy and auto-generated tocs code support syntax highlighting code tabs and one-click copy search fuzzy matching with highlight and instant results responsive design built-in light dark mode with mobile support math tables latex rendering and clean table styling seo defaults preconfigured meta open graph and structured data ai docs upcoming ai tools for smart search and content generation coming soon using this kit navigation is on the left pages flow from setup to advanced features but you re free to jump around use the table of contents on the right to skip through sections start with the installation guide community support got questions reach out via: github twitter facebook",
      "headings": [
        "Documents",
        "Why use Documents?",
        "Core Features",
        "Using This Kit",
        "Community Support"
      ],
      "keywords": [
        "introduction",
        "guide",
        "nextjs",
        "documents",
        "Documents",
        "Why use Documents?",
        "Core Features",
        "Using This Kit",
        "Community Support",
        "Next.js",
        "React",
        "Tailwind CSS",
        "TypeScript",
        "Product Guides",
        "Internal Docs",
        "Technical Manuals",
        "Write in Markdown/MDX",
        "Flexible Navigation",
        "Code Support",
        "Search",
        "Responsive Design",
        "Math + Tables",
        "SEO Defaults",
        "AI Docs (Upcoming)"
      ]
    }
  },
  {
    "slug": "/basic-setup/installation",
    "title": "Installation",
    "description": "This guide covers the installation of Documents and how to edit your new project.",
    "content": "To install and edit the Documents, you need to have several prerequisites in place. Here's a list of all the essential pre-requisites\r\nfor setting up and working on this project.\n\n[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Frubixvi%2Frubix-documents\\&project-name=my-documents\\&repository-name=my-documents\\&demo-title=Documents\\&demo-description=This%20Document%20Starter%20Kit%20is%20developed%20with%20Next.js%2C%20Tailwind%20CSS%20and%20TypeScript.%20It%20serves%20as%20a%20flexible%20and%20scalable%20foundation%20for%20building%20documentation%20websites%20or%20content-driven%20projects.\\&demo-url=https%3A%2F%2Frubix-documents.vercel.app%2F\\&demo-image=https%3A%2F%2Fgithub.com%2Frubixvi%2Frubix-documents%2Fblob%2Fmain%2Fpublic%2Fscreens%2Fscreen-1.png)\n\n## Prerequisites\n\n## Installation\n\n## Optional\n\n## Important Information\n\nThe project's search functionality relies on the Husky's automation to build `search-data/documents.json` ensure git commit is performed to generate this file.\n",
    "_searchMeta": {
      "cleanContent": "to install and edit the documents you need to have several prerequisites in place here s a list of all the essential pre-requisites for setting up and working on this project deploy with vercel https: vercel com new clone repository-url https 3a 2f 2fgithub com 2frubixvi 2frubix-documents project-name my-documents repository-name my-documents demo-title documents demo-description this 20document 20starter 20kit 20is 20developed 20with 20next js 2c 20tailwind 20css 20and 20typescript 20it 20serves 20as 20a 20flexible 20and 20scalable 20foundation 20for 20building 20documentation 20websites 20or 20content-driven 20projects demo-url https 3a 2f 2frubix-documents vercel app 2f demo-image https 3a 2f 2fgithub com 2frubixvi 2frubix-documents 2fblob 2fmain 2fpublic 2fscreens 2fscreen-1 png prerequisites installation optional important information the project s search functionality relies on the husky s automation to build search-data documents json ensure git commit is performed to generate this file",
      "headings": [
        "Prerequisites",
        "Installation",
        "Optional",
        "Important Information"
      ],
      "keywords": [
        "installation",
        "github",
        "node",
        "guide",
        "nextjs",
        "documents",
        "Prerequisites",
        "Installation",
        "Optional",
        "Important Information",
        "search-data/documents.json"
      ]
    }
  },
  {
    "slug": "/basic-setup/setup",
    "title": "Setup",
    "description": "Setting up and configuring your documentation project",
    "content": "Setting up your new documentation project is straightforward. Most of the essential project settings can be configured within the `settings` folder.\n\n## Settings\n\nThis section provides the core settings for your documentation site, such as defining the site's URL, site icon and title.\n\n```tsx showLineNumbers\nexport const url = \"\"                 // The URL for your documentation site\r\nexport const siteicon = \"\"            // Icon displayed next to the site name in the header\r\nexport const sitename = \"\"            // Title of your documentation site\n```\n\n## Google Tags\n\nThis section allows you to integrate Google Tag Manager into your documentation project. You can add your GTM code and configure whether it's connected.\n\n```tsx showLineNumbers\nexport const gtm = \"\"                 // Add your Google Tag Manager code here\r\nexport const gtmconnected = true      // Set to true if GTM is connected, otherwise set to false\n```\n\n## Search Engine\n\nConfigure essential SEO settings to ensure your documentation site is optimized for search engines. This includes meta descriptions, keywords and social media sharing details like images and alt text.\n\n```tsx showLineNumbers\nexport const description = \"\"         // Description of your documentation site for SEO\r\nexport const keywords = [\"\", \"\"]      // List of SEO keywords for your documentation site\r\nexport const urlimage = \"\"            // The URL of the image used when sharing on social media)\r\nexport const imagealt = \"\"            // Alt text for shared images, helpful for screen readers\r\nexport const twitterhandle = \"\"       // Your company’s Twitter handle for social sharing\n```\n\n## Footer Branding\n\nThe footer settings allow you to customize the company information displayed at the bottom of the site. You can add the company name and the URL that the name will link to.\n\n```tsx showLineNumbers\nexport const companyname = \"\"         // The company name displayed in the copyright section\r\nexport const companylink = \"\"         // The URL your company name should link to\n```\n\n## General Layout\n\nThe layout settings control the appearance and functionality of various elements of the documentation site, such as branding, the right sidebar, feedback options, table of contents, and scroll-to-top functionality.\n\n```tsx showLineNumbers\nexport const branding = true          // Set to true to display our branding elements\r\nexport const rightsidebar = true      // Set to true to enable the right sidebar with feedback, table of contents and scroll-to-top\r\nexport const feedbackedit = true      // Control to enable/disable feedback on GitHub\r\nexport const tableofcontent = true    // Control to enable/disable the generated table of contents\r\nexport const totopscroll = true       // Control to enable/disable scroll-to-top button\n```\n\n## Github Control\n\nIf your MDX files are hosted on GitHub, you can configure the project to load documents directly from there. This option can be useful for syncing documentation updates directly with your repository.\n\n```tsx showLineNumbers\nexport const loadfromgithub = false   // Set to true to load your MDX documents directly from GitHub\n```\n\n## Project Structure\n",
    "_searchMeta": {
      "cleanContent": "setting up your new documentation project is straightforward most of the essential project settings can be configured within the settings folder settings this section provides the core settings for your documentation site such as defining the site s url site icon and title google tags this section allows you to integrate google tag manager into your documentation project you can add your gtm code and configure whether it s connected search engine configure essential seo settings to ensure your documentation site is optimized for search engines this includes meta descriptions keywords and social media sharing details like images and alt text footer branding the footer settings allow you to customize the company information displayed at the bottom of the site you can add the company name and the url that the name will link to general layout the layout settings control the appearance and functionality of various elements of the documentation site such as branding the right sidebar feedback options table of contents and scroll-to-top functionality github control if your mdx files are hosted on github you can configure the project to load documents directly from there this option can be useful for syncing documentation updates directly with your repository project structure",
      "headings": [
        "Settings",
        "Google Tags",
        "Search Engine",
        "Footer Branding",
        "General Layout",
        "Github Control",
        "Project Structure"
      ],
      "keywords": [
        "setup",
        "configuration",
        "layout",
        "Google",
        "SEO",
        "nextjs",
        "documents",
        "Settings",
        "Google Tags",
        "Search Engine",
        "Footer Branding",
        "General Layout",
        "Github Control",
        "Project Structure",
        "settings",
        "tsx showLineNumbers\nexport const url = \"\"                 // The URL for your documentation site\r\nexport const siteicon = \"\"            // Icon displayed next to the site name in the header\r\nexport const sitename = \"\"            // Title of your documentation site",
        "## Google Tags\n\nThis section allows you to integrate Google Tag Manager into your documentation project. You can add your GTM code and configure whether it's connected.",
        "tsx showLineNumbers\nexport const gtm = \"\"                 // Add your Google Tag Manager code here\r\nexport const gtmconnected = true      // Set to true if GTM is connected, otherwise set to false",
        "## Search Engine\n\nConfigure essential SEO settings to ensure your documentation site is optimized for search engines. This includes meta descriptions, keywords and social media sharing details like images and alt text.",
        "tsx showLineNumbers\nexport const description = \"\"         // Description of your documentation site for SEO\r\nexport const keywords = [\"\", \"\"]      // List of SEO keywords for your documentation site\r\nexport const urlimage = \"\"            // The URL of the image used when sharing on social media)\r\nexport const imagealt = \"\"            // Alt text for shared images, helpful for screen readers\r\nexport const twitterhandle = \"\"       // Your company’s Twitter handle for social sharing",
        "## Footer Branding\n\nThe footer settings allow you to customize the company information displayed at the bottom of the site. You can add the company name and the URL that the name will link to.",
        "tsx showLineNumbers\nexport const companyname = \"\"         // The company name displayed in the copyright section\r\nexport const companylink = \"\"         // The URL your company name should link to",
        "## General Layout\n\nThe layout settings control the appearance and functionality of various elements of the documentation site, such as branding, the right sidebar, feedback options, table of contents, and scroll-to-top functionality.",
        "tsx showLineNumbers\nexport const branding = true          // Set to true to display our branding elements\r\nexport const rightsidebar = true      // Set to true to enable the right sidebar with feedback, table of contents and scroll-to-top\r\nexport const feedbackedit = true      // Control to enable/disable feedback on GitHub\r\nexport const tableofcontent = true    // Control to enable/disable the generated table of contents\r\nexport const totopscroll = true       // Control to enable/disable scroll-to-top button",
        "## Github Control\n\nIf your MDX files are hosted on GitHub, you can configure the project to load documents directly from there. This option can be useful for syncing documentation updates directly with your repository.",
        "tsx showLineNumbers\nexport const loadfromgithub = false   // Set to true to load your MDX documents directly from GitHub"
      ]
    }
  },
  {
    "slug": "/markdown/cards",
    "title": "Cards",
    "description": "Explore and implement various card styles, including small, large and image cards.",
    "content": "This section introduces the different card styles available in the system, from compact small cards to visually rich image cards. Each example is paired with JSX code snippets, providing you with a practical guide to incorporate these components seamlessly into your project.\n\n## Small Card\n\n```jsx\n<CardGrid>\r\n  <Card\r\n    title=\"Instructions\"\r\n    href=\"/docs/basic-setup/installation\"\r\n    icon=\"alignJustify\"\r\n    variant=\"small\"\r\n    description=\"test description\"\r\n  />\r\n  <Card\r\n    title=\"Setup\"\r\n    href=\"/docs/basic-setup/setup\"\r\n    icon=\"alignJustify\"\r\n    variant=\"small\"\r\n  />\r\n  <Card\r\n    title=\"Rubix Studios\"\r\n    href=\"https://rubixstudios.com.au\"\r\n    icon=\"alignJustify\"\r\n    external={true}\r\n    variant=\"small\"\r\n  />\r\n</CardGrid>\n```\n\n## Large Card\n\n```jsx\n<CardGrid>\r\n  <Card\r\n    subtitle=\"Instructions\"\r\n    title=\"Installation\"\r\n    description=\"Get started with Documents using our quick start installation guide to get your project started.\"\r\n    href=\"/docs/basic-setup/installation\"\r\n  />\r\n  <Card\r\n    subtitle=\"Setup\"\r\n    title=\"Site Settings\"\r\n    description=\"Setting up your Documents projects layout, links and search engine optimisation.\"\r\n    href=\"/docs/basic-setup/setup\"\r\n  />\r\n  <Card\r\n    subtitle=\"Support\"\r\n    title=\"Rubix Studios\"\r\n    description=\"Australia's leading branding, marketing and web development company.\"\r\n    href=\"https://rubixstudios.com.au\"\r\n    external={true}\r\n  />\r\n</CardGrid>\n```\n\n## Image Card\n\n```jsx\n<CardGrid>\r\n  <Card\r\n    title=\"Instructions\"\r\n    href=\"/docs/introduction/installation\"\r\n    image=\"/images/og-image.png\"\r\n    variant=\"image\"\r\n  />\r\n  <Card\r\n    title=\"Setup\"\r\n    href=\"/docs/introduction/setup\"\r\n    image=\"/images/og-image.png\"\r\n    variant=\"image\"\r\n  />\r\n  <Card\r\n    title=\"Rubix Studios\"\r\n    href=\"https://www.rubixstudios.com.au\"\r\n    image=\"/images/og-image.png\"\r\n    external={true}\r\n    variant=\"image\"\r\n  />\r\n</CardGrid>\n```\n",
    "_searchMeta": {
      "cleanContent": "this section introduces the different card styles available in the system from compact small cards to visually rich image cards each example is paired with jsx code snippets providing you with a practical guide to incorporate these components seamlessly into your project small card large card image card",
      "headings": [
        "Small Card",
        "Large Card",
        "Image Card"
      ],
      "keywords": [
        "Small Card",
        "Large Card",
        "Image Card",
        "jsx\n<CardGrid>\r\n  <Card\r\n    title=\"Instructions\"\r\n    href=\"/docs/basic-setup/installation\"\r\n    icon=\"alignJustify\"\r\n    variant=\"small\"\r\n    description=\"test description\"\r\n  />\r\n  <Card\r\n    title=\"Setup\"\r\n    href=\"/docs/basic-setup/setup\"\r\n    icon=\"alignJustify\"\r\n    variant=\"small\"\r\n  />\r\n  <Card\r\n    title=\"Rubix Studios\"\r\n    href=\"https://rubixstudios.com.au\"\r\n    icon=\"alignJustify\"\r\n    external={true}\r\n    variant=\"small\"\r\n  />\r\n</CardGrid>",
        "## Large Card",
        "jsx\n<CardGrid>\r\n  <Card\r\n    subtitle=\"Instructions\"\r\n    title=\"Installation\"\r\n    description=\"Get started with Documents using our quick start installation guide to get your project started.\"\r\n    href=\"/docs/basic-setup/installation\"\r\n  />\r\n  <Card\r\n    subtitle=\"Setup\"\r\n    title=\"Site Settings\"\r\n    description=\"Setting up your Documents projects layout, links and search engine optimisation.\"\r\n    href=\"/docs/basic-setup/setup\"\r\n  />\r\n  <Card\r\n    subtitle=\"Support\"\r\n    title=\"Rubix Studios\"\r\n    description=\"Australia's leading branding, marketing and web development company.\"\r\n    href=\"https://rubixstudios.com.au\"\r\n    external={true}\r\n  />\r\n</CardGrid>",
        "## Image Card",
        "jsx\n<CardGrid>\r\n  <Card\r\n    title=\"Instructions\"\r\n    href=\"/docs/introduction/installation\"\r\n    image=\"/images/og-image.png\"\r\n    variant=\"image\"\r\n  />\r\n  <Card\r\n    title=\"Setup\"\r\n    href=\"/docs/introduction/setup\"\r\n    image=\"/images/og-image.png\"\r\n    variant=\"image\"\r\n  />\r\n  <Card\r\n    title=\"Rubix Studios\"\r\n    href=\"https://www.rubixstudios.com.au\"\r\n    image=\"/images/og-image.png\"\r\n    external={true}\r\n    variant=\"image\"\r\n  />\r\n</CardGrid>"
      ]
    }
  },
  {
    "slug": "/markdown/diagrams",
    "title": "Diagrams",
    "description": "Add various diagram types, including flowcharts, decision trees and entity-relationship diagrams.",
    "content": "Diagrams are powerful tools for visualizing processes, relationships, and decisions. This section showcases different types of diagrams created using **Mermaid**, complete with examples and reusable code snippets to integrate into your projects.\n\n## Flowchart\n\nA flowchart represents a sequence of steps or processes in a visual format. Use this diagram to map workflows, decision-making processes, or operational flows.\n\n```jsx\n<Mermaid\r\n  chart={\\`\r\n    graph TD;\r\n    Start --> Task1;\r\n    Task1 --> Task2;\r\n    Task2 --> End;\r\n  \\`}\r\n/>\n```\n\n## Decision Tree\n\nDecision trees illustrate choices and possible outcomes, making them ideal for decision-making workflows or processes involving multiple paths.\n\n```jsx\n<Mermaid\r\n  chart={\\`\r\n    graph TD;\r\n    A[Start] --> B{Is it raining?};\r\n    B -->|Yes| C[Take an umbrella];\r\n    B -->|No| D[Enjoy the weather];\r\n    C --> E[Go outside];\r\n    D --> E;\r\n  \\`}\r\n/>\n```\n\n## Entity-Relationship Diagram\n\nEntity-relationship diagrams (ERDs) are used to model relationships between entities in a system. They are widely used in database design and system architecture planning.\n\n```jsx\n<Mermaid\r\n  chart={\\`\r\n    erDiagram\r\n    CUSTOMER ||--o{ ORDER : places\r\n    ORDER ||--|{ LINE-ITEM : contains\r\n    PRODUCT ||--o{ LINE-ITEM : \"included in\"\r\n    CUSTOMER {\r\n        string name\r\n        string email\r\n    }\r\n    ORDER {\r\n        int orderNumber\r\n        date orderDate\r\n    }\r\n    LINE-ITEM {\r\n        int quantity\r\n        float price\r\n    }\r\n    PRODUCT {\r\n        int productId\r\n        string name\r\n        float price\r\n    }\r\n  \\`}\r\n/>\n```\n\nEach of these diagrams serves a specific purpose and Mermaid makes it easy to generate them dynamically. Feel free to experiment with the provided code snippets and adapt them to your needs.\n",
    "_searchMeta": {
      "cleanContent": "diagrams are powerful tools for visualizing processes relationships and decisions this section showcases different types of diagrams created using mermaid complete with examples and reusable code snippets to integrate into your projects flowchart a flowchart represents a sequence of steps or processes in a visual format use this diagram to map workflows decision-making processes or operational flows decision tree decision trees illustrate choices and possible outcomes making them ideal for decision-making workflows or processes involving multiple paths entity-relationship diagram entity-relationship diagrams erds are used to model relationships between entities in a system they are widely used in database design and system architecture planning each of these diagrams serves a specific purpose and mermaid makes it easy to generate them dynamically feel free to experiment with the provided code snippets and adapt them to your needs",
      "headings": [
        "Flowchart",
        "Decision Tree",
        "Entity-Relationship Diagram"
      ],
      "keywords": [
        "Flowchart",
        "Decision Tree",
        "Entity-Relationship Diagram",
        "Mermaid",
        "jsx\n<Mermaid\r\n  chart={\\",
        "}\r\n/>",
        "## Decision Tree\n\nDecision trees illustrate choices and possible outcomes, making them ideal for decision-making workflows or processes involving multiple paths.",
        "## Entity-Relationship Diagram\n\nEntity-relationship diagrams (ERDs) are used to model relationships between entities in a system. They are widely used in database design and system architecture planning."
      ]
    }
  },
  {
    "slug": "/markdown/filetree",
    "title": "Filetree",
    "description": "This section provides an overview of file structures and their implementation using the FileTree component.",
    "content": "This section demonstrates the structure of a file tree using the `FileTree` component. Below is an example showcasing folders and files organized hierarchically for a project setup.\n\n## How to Use\n\nIntegrate the `FileTree` component into your project to visually represent file and folder structures. This is particularly useful for documentation, tutorials, or providing users with an overview of your project's architecture.\n\n### JSX Code Example\n\nHere is how you can define the file tree structure in for use in your project:\n\n```jsx\n<FileTree>\r\n  <Folder name=\"src\" label=\"Source Code\">\r\n    <File name=\"index.tsx\" label=\"Index File\" />\r\n    <Folder name=\"components\" label=\"Components\">\r\n      <File name=\"button.tsx\" label=\"Button Component\" />\r\n      <File name=\"input.tsx\" label=\"Input Component\" />\r\n    </Folder>\r\n    <Folder name=\"pages\" label=\"Pages\">\r\n      <File name=\"home.tsx\" label=\"Home Page\" />\r\n      <File name=\"about.tsx\" label=\"About Page\" />\r\n    </Folder>\r\n  </Folder>\r\n</FileTree>\n```\n\nUse this code as a template to set up your own file tree structure and customize it as needed.\n",
    "_searchMeta": {
      "cleanContent": "this section demonstrates the structure of a file tree using the filetree component below is an example showcasing folders and files organized hierarchically for a project setup how to use integrate the filetree component into your project to visually represent file and folder structures this is particularly useful for documentation tutorials or providing users with an overview of your project s architecture jsx code example here is how you can define the file tree structure in for use in your project: use this code as a template to set up your own file tree structure and customize it as needed",
      "headings": [
        "How to Use"
      ],
      "keywords": [
        "How to Use",
        "FileTree",
        "jsx\n<FileTree>\r\n  <Folder name=\"src\" label=\"Source Code\">\r\n    <File name=\"index.tsx\" label=\"Index File\" />\r\n    <Folder name=\"components\" label=\"Components\">\r\n      <File name=\"button.tsx\" label=\"Button Component\" />\r\n      <File name=\"input.tsx\" label=\"Input Component\" />\r\n    </Folder>\r\n    <Folder name=\"pages\" label=\"Pages\">\r\n      <File name=\"home.tsx\" label=\"Home Page\" />\r\n      <File name=\"about.tsx\" label=\"About Page\" />\r\n    </Folder>\r\n  </Folder>\r\n</FileTree>"
      ]
    }
  },
  {
    "slug": "/markdown",
    "title": "Introduction",
    "description": "This section provides an overview of Introduction.",
    "content": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime, molestiae, facilis aperiam et, error illum vel ullam? Quis architecto dolore ullam\n\n* \\[x] Write the press release\n* \\[ ] Update the website\n* \\[ ] Contact the media\n\n| Syntax        | Description |   Test Text |\r\n| :------------ | :---------: | ----------: |\r\n| Header        |    Title    | Here's this |\r\n| Paragraph     |    Text     |    And more |\r\n| Strikethrough |             |    ~~Text~~ |\n\n## Sample Document with Mermaid\n\nHere is a Mermaid diagram:\n\nThis diagram should render automatically without any extra imports.\n\n## Getting Started\n\nTo begin using the Documentation Template, follow these simple steps:\n\n* Start by cloning the repository to your local machine.\n\nLorem ipsum dolor sit amet consectetur adipisicing elit. Reprehenderit quae iure nulla deserunt dolore quam pariatur minus sapiente accusantium. Optio, necessitatibus sequi. Veritatis, aspernatur? Possimus quis repellat eum vitae eveniet.\n\n## Blockquotes\n\nBlockquotes are useful for emphasizing key points or quoting external sources:\n\n> \"Documentation is a love letter that you write to your future self.\" - Damian Conway\n\nFeel free to use blockquotes to highlight important information or quotes relevant to your documentation.\n\n## Code Examples with switch\n\nHere a custom tab component from shadcn ui is used.\n\n## Conclusion\n\nThank you for choosing the Documentation Template for your project. Whether you're documenting software, APIs, or processes, we're here to support you in creating clear and effective documentation. Happy documenting!\n",
    "_searchMeta": {
      "cleanContent": "lorem ipsum dolor sit amet consectetur adipisicing elit numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime molestiae facilis aperiam et error illum vel ullam quis architecto dolore ullam x write the press release update the website contact the media syntax description test text :------------ :---------: ----------: header title here s this paragraph text and more strikethrough text sample document with mermaid here is a mermaid diagram: this diagram should render automatically without any extra imports getting started to begin using the documentation template follow these simple steps: start by cloning the repository to your local machine lorem ipsum dolor sit amet consectetur adipisicing elit reprehenderit quae iure nulla deserunt dolore quam pariatur minus sapiente accusantium optio necessitatibus sequi veritatis aspernatur possimus quis repellat eum vitae eveniet blockquotes blockquotes are useful for emphasizing key points or quoting external sources: documentation is a love letter that you write to your future self - damian conway feel free to use blockquotes to highlight important information or quotes relevant to your documentation code examples with switch here a custom tab component from shadcn ui is used conclusion thank you for choosing the documentation template for your project whether you re documenting software apis or processes we re here to support you in creating clear and effective documentation happy documenting",
      "headings": [
        "Sample Document with Mermaid",
        "Getting Started",
        "Blockquotes",
        "Code Examples with switch",
        "Conclusion"
      ],
      "keywords": [
        "Sample Document with Mermaid",
        "Getting Started",
        "Blockquotes",
        "Code Examples with switch",
        "Conclusion"
      ]
    }
  },
  {
    "slug": "/markdown/lists",
    "title": "Lists",
    "description": "This section provides an overview of creating and using lists in the Documents boilerplate.",
    "content": "Learn how to create and render different types of lists in the Documents boilerplate. Examples include checklists, ordered lists, unordered lists and nested lists.\n\n## Checklist\n\n* \\[x] Write the press release\n* \\[ ] Update the website\n* \\[ ] Contact the media\n\n```jsx\n- [x] Write the press release\r\n- [ ] Update the website\r\n- [ ] Contact the media\n```\n\n## Simple List\n\n* Item 1\n* Item 2\n* Item 3\n\n```jsx\n- Item 1\r\n- Item 2\r\n- Item 3\n```\n\n## Number List\n\n1. Research\n2. Draft the content\n3. Review and edit\n4. Publish\n\n```jsx\n1. Research\r\n2. Draft the content\r\n3. Review and edit\r\n4. Publish\n```\n\n## Nested List\n\n* Main Category 1\n  * Sub Item 1.1\n  * Sub Item 1.2\n* Main Category 2\n  * Sub Item 2.1\n  * Sub Item 2.2\n\n```jsx\n- Main Category 1\r\n  - Sub Item 1.1\r\n  - Sub Item 1.2\r\n- Main Category 2\r\n  - Sub Item 2.1\r\n  - Sub Item 2.2\n```\n\nUse these examples as a foundation to create and customize lists that fit your project's needs.\n",
    "_searchMeta": {
      "cleanContent": "learn how to create and render different types of lists in the documents boilerplate examples include checklists ordered lists unordered lists and nested lists checklist x write the press release update the website contact the media simple list item 1 item 2 item 3 number list research draft the content review and edit publish nested list main category 1 sub item 1 1 sub item 1 2 main category 2 sub item 2 1 sub item 2 2 use these examples as a foundation to create and customize lists that fit your project s needs",
      "headings": [
        "Checklist",
        "Simple List",
        "Number List",
        "Nested List"
      ],
      "keywords": [
        "Checklist",
        "Simple List",
        "Number List",
        "Nested List",
        "jsx\n- [x] Write the press release\r\n- [ ] Update the website\r\n- [ ] Contact the media",
        "## Simple List\n\n* Item 1\n* Item 2\n* Item 3",
        "jsx\n- Item 1\r\n- Item 2\r\n- Item 3",
        "## Number List\n\n1. Research\n2. Draft the content\n3. Review and edit\n4. Publish",
        "jsx\n1. Research\r\n2. Draft the content\r\n3. Review and edit\r\n4. Publish",
        "## Nested List\n\n* Main Category 1\n  * Sub Item 1.1\n  * Sub Item 1.2\n* Main Category 2\n  * Sub Item 2.1\n  * Sub Item 2.2",
        "jsx\n- Main Category 1\r\n  - Sub Item 1.1\r\n  - Sub Item 1.2\r\n- Main Category 2\r\n  - Sub Item 2.1\r\n  - Sub Item 2.2"
      ]
    }
  },
  {
    "slug": "/markdown/maths",
    "title": "Maths",
    "description": "This section provides an overview of Introduction.",
    "content": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime, molestiae, facilis aperiam et, error illum vel ullam? Quis architecto dolore ullam\n\n## Basic Algebra\n\nThe area of a circle ($$A$$) can be calculated using the radius ($$r$$) as follows:\n\n```math\nA = \\pi r^2\n```\n\n## Quadratic Formula\n\nThe quadratic formula for solving an equation of the form $$ax^2 + bx + c = 0$$ is:\n\n```math\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n```\n\n## Newton's Second Law of Motion\n\nNewton's second law of motion states that force ($$F$$) is the product of mass ($$m$$) and acceleration ($$a$$):\n\n```math\nF = ma\n```\n\n## Pythagorean Theorem\n\nThe Pythagorean theorem relates the lengths of the sides of a right triangle:\n\n```math\na^2 + b^2 = c^2\n```\n\n## Einstein's Mass-Energy Equivalence\n\nEinstein's famous equation relates energy ($$E$$), mass ($$m$$), and the speed of light ($$c$$):\n\n```math\nE = mc^2\n```\n",
    "_searchMeta": {
      "cleanContent": "lorem ipsum dolor sit amet consectetur adipisicing elit numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime molestiae facilis aperiam et error illum vel ullam quis architecto dolore ullam basic algebra the area of a circle a can be calculated using the radius r as follows: quadratic formula the quadratic formula for solving an equation of the form ax 2 bx c 0 is: newton s second law of motion newton s second law of motion states that force f is the product of mass m and acceleration a : pythagorean theorem the pythagorean theorem relates the lengths of the sides of a right triangle: einstein s mass-energy equivalence einstein s famous equation relates energy e mass m and the speed of light c :",
      "headings": [
        "Basic Algebra",
        "Quadratic Formula",
        "Newton's Second Law of Motion",
        "Pythagorean Theorem",
        "Einstein's Mass-Energy Equivalence"
      ],
      "keywords": [
        "Basic Algebra",
        "Quadratic Formula",
        "Newton's Second Law of Motion",
        "Pythagorean Theorem",
        "Einstein's Mass-Energy Equivalence",
        "math\nA = \\pi r^2",
        "## Quadratic Formula\n\nThe quadratic formula for solving an equation of the form $$ax^2 + bx + c = 0$$ is:",
        "math\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}",
        "## Newton's Second Law of Motion\n\nNewton's second law of motion states that force ($$F$$) is the product of mass ($$m$$) and acceleration ($$a$$):",
        "math\nF = ma",
        "## Pythagorean Theorem\n\nThe Pythagorean theorem relates the lengths of the sides of a right triangle:",
        "math\na^2 + b^2 = c^2",
        "## Einstein's Mass-Energy Equivalence\n\nEinstein's famous equation relates energy ($$E$$), mass ($$m$$), and the speed of light ($$c$$):",
        "math\nE = mc^2"
      ]
    }
  },
  {
    "slug": "/markdown/notes",
    "title": "Notes",
    "description": "This section provides an overview of Introduction.",
    "content": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime, molestiae, facilis aperiam et, error illum vel ullam? Quis architecto dolore ullam\n\n## Standard Note\n\n## Success Note\n\n## Warning Note\n\n## Danger Note\n",
    "_searchMeta": {
      "cleanContent": "lorem ipsum dolor sit amet consectetur adipisicing elit numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime molestiae facilis aperiam et error illum vel ullam quis architecto dolore ullam standard note success note warning note danger note",
      "headings": [
        "Standard Note",
        "Success Note",
        "Warning Note",
        "Danger Note"
      ],
      "keywords": [
        "Standard Note",
        "Success Note",
        "Warning Note",
        "Danger Note"
      ]
    }
  },
  {
    "slug": "/markdown/steps",
    "title": "Steps",
    "description": "This section provides an overview of Introduction.",
    "content": "The `<Step>` and `<StepItem>` components allow you to create structured step-by-step guides in your documentation. These components are particularly useful when you want to break down a process or tutorial into easy-to-follow stages.\n\n## Steps\n\nTo create a step-by-step guide in your MDX, you can use the following structure:\n",
    "_searchMeta": {
      "cleanContent": "the step and stepitem components allow you to create structured step-by-step guides in your documentation these components are particularly useful when you want to break down a process or tutorial into easy-to-follow stages steps to create a step-by-step guide in your mdx you can use the following structure:",
      "headings": [
        "Steps"
      ],
      "keywords": [
        "Steps",
        "<Step>",
        "<StepItem>"
      ]
    }
  },
  {
    "slug": "/markdown/table",
    "title": "Table",
    "description": "This section provides an overview of Introduction.",
    "content": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime, molestiae, facilis aperiam et, error illum vel ullam? Quis architecto dolore ullam\n\n| Syntax        | Description |   Test Text |\r\n| :------------ | :---------: | ----------: |\r\n| Header        |    Title    | Here's this |\r\n| Paragraph     |    Text     |    And more |\r\n| Strikethrough |             |    ~~Text~~ |\n\n| Feature       | Documentation Link |                    Notes |\r\n| :------------ | :----------------: | -----------------------: |\r\n| **Feature A** |     [Docs](#)      | For more info click here |\r\n| **Feature B** |     [Guide](#)     |  See the full guide here |\r\n| **Feature C** |     [Setup](#)     |       Setup instructions |\n",
    "_searchMeta": {
      "cleanContent": "lorem ipsum dolor sit amet consectetur adipisicing elit numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime molestiae facilis aperiam et error illum vel ullam quis architecto dolore ullam syntax description test text :------------ :---------: ----------: header title here s this paragraph text and more strikethrough text feature documentation link notes :------------ :----------------: -----------------------: feature a docs for more info click here feature b guide see the full guide here feature c setup setup instructions",
      "headings": [],
      "keywords": [
        "Feature A",
        "Feature B",
        "Feature C"
      ]
    }
  },
  {
    "slug": "/markdown/tabs",
    "title": "Tabs",
    "description": "This section provides an overview of Introduction.",
    "content": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime, molestiae, facilis aperiam et, error illum vel ullam? Quis architecto dolore ullam\n\n## Code Examples with switch\n\nHere a custom tab component from shadcn ui is used.\n",
    "_searchMeta": {
      "cleanContent": "lorem ipsum dolor sit amet consectetur adipisicing elit numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime molestiae facilis aperiam et error illum vel ullam quis architecto dolore ullam code examples with switch here a custom tab component from shadcn ui is used",
      "headings": [
        "Code Examples with switch"
      ],
      "keywords": [
        "Code Examples with switch"
      ]
    }
  },
  {
    "slug": "/navigation",
    "title": "Navigation",
    "description": "How to build our your documents menu and navigations.",
    "content": "",
    "_searchMeta": {
      "cleanContent": "",
      "headings": [],
      "keywords": [
        "navigation",
        "sidebar",
        "menus",
        "mdx",
        "nextjs",
        "documents"
      ]
    }
  },
  {
    "slug": "/priority-matrix",
    "title": "Priority Matrix",
    "description": "Interactive implementation priority matrix for CJN Dakota County RMS modernization project",
    "content": "import PriorityMatrixClient from '@/components/priority-matrix-client';\n\n# Implementation Priority Matrix\n\n**Customer:** CJN Dakota County (Tim Anderberg, Nathan Noll)\\\n**Project:** Azure RMS Modernization\n\n***\n\n## Overview\n\nThis interactive priority matrix tracks the implementation progress of architectural recommendations for the CJN Dakota County Records Management System (RMS) modernization project.\n\nCheck off items as they are completed. Your progress is automatically saved.\n\n***\n\n## Priority Categories\n\nThe recommendations are organized into four priority levels based on business impact, compliance requirements, and implementation urgency:\n\n* 🔴 **CRITICAL PRIORITY (0-30 Days)** - Immediate action required for security, compliance, or business continuity\n* 🟠 **HIGH PRIORITY (30-60 Days)** - Important improvements with significant business value\n* 🟡 **MEDIUM PRIORITY (60-90 Days)** - Performance optimizations and cost management\n* 🟢 **LOW PRIORITY (90+ Days)** - Long-term improvements and advanced features\n\n***\n\n## Interactive Checklist\n\n<PriorityMatrixClient />\n\n***\n\n## Summary Metrics\n\n### Critical Priority Items\n\n* **Total Effort:** 10-11 person-weeks\n* **Calendar Time:** ~5-6 weeks (with 3 parallel work streams)\n* **Monthly Cost Impact:** +$450-500 + 15-25% for geo-replication\n* **Focus Areas:** Security, Compliance, Disaster Recovery\n\n### High Priority Items\n\n* **Total Effort:** 14-17 person-weeks\n* **Monthly Cost Impact:** +$300-600 + 10% infrastructure\n* **Focus Areas:** Enhanced security, Operational visibility, Performance\n\n### Medium Priority Items\n\n* **Focus Areas:** Advanced security, Cost optimization, Global performance\n\n### Low Priority Items\n\n* **Focus Areas:** Resilience testing, Hybrid management, Advanced cost optimization\n\n***\n\n## Related Documentation\n\n* [Architectural Analysis](/docs/architecture) - Detailed technical recommendations\n* [Implementation Guide](/docs/basic-setup) - Getting started with the platform\n\n***\n\n## Notes\n\nAll changes to checkbox states are automatically persisted to the database. Your progress is saved in real-time and will be available the next time you visit this page.\n\nFor questions about specific recommendations, refer to the detailed [Architectural Analysis](/docs/architecture) or contact the project team.\n",
    "_searchMeta": {
      "cleanContent": "import prioritymatrixclient from components priority-matrix-client implementation priority matrix customer: cjn dakota county tim anderberg nathan noll project: azure rms modernization overview this interactive priority matrix tracks the implementation progress of architectural recommendations for the cjn dakota county records management system rms modernization project check off items as they are completed your progress is automatically saved priority categories the recommendations are organized into four priority levels based on business impact compliance requirements and implementation urgency: critical priority 0-30 days - immediate action required for security compliance or business continuity high priority 30-60 days - important improvements with significant business value medium priority 60-90 days - performance optimizations and cost management low priority 90 days - long-term improvements and advanced features interactive checklist prioritymatrixclient summary metrics critical priority items total effort: 10-11 person-weeks calendar time: 5-6 weeks with 3 parallel work streams monthly cost impact: 450-500 15-25 for geo-replication focus areas: security compliance disaster recovery high priority items total effort: 14-17 person-weeks monthly cost impact: 300-600 10 infrastructure focus areas: enhanced security operational visibility performance medium priority items focus areas: advanced security cost optimization global performance low priority items focus areas: resilience testing hybrid management advanced cost optimization related documentation architectural analysis - detailed technical recommendations implementation guide - getting started with the platform notes all changes to checkbox states are automatically persisted to the database your progress is saved in real-time and will be available the next time you visit this page for questions about specific recommendations refer to the detailed architectural analysis or contact the project team",
      "headings": [
        "Overview",
        "Priority Categories",
        "Interactive Checklist",
        "Summary Metrics",
        "Related Documentation",
        "Notes"
      ],
      "keywords": [
        "priority",
        "implementation",
        "roadmap",
        "CJN Dakota",
        "Overview",
        "Priority Categories",
        "Interactive Checklist",
        "Summary Metrics",
        "Related Documentation",
        "Notes",
        "Customer:",
        "Project:",
        "## Overview\n\nThis interactive priority matrix tracks the implementation progress of architectural recommendations for the CJN Dakota County Records Management System (RMS) modernization project.\n\nCheck off items as they are completed. Your progress is automatically saved.",
        "CRITICAL PRIORITY (0-30 Days)",
        "HIGH PRIORITY (30-60 Days)",
        "MEDIUM PRIORITY (60-90 Days)",
        "LOW PRIORITY (90+ Days)",
        "## Interactive Checklist\n\n<PriorityMatrixClient />",
        "Total Effort:",
        "Calendar Time:",
        "Monthly Cost Impact:",
        "Focus Areas:"
      ]
    }
  },
  {
    "slug": "/random",
    "title": "Introduction",
    "description": "This section provides an overview of Introduction.",
    "content": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime, molestiae, facilis aperiam et, error illum vel ullam? Quis architecto dolore ullam\n\n* \\[x] Write the press release\n* \\[ ] Update the website\n* \\[ ] Contact the media\n\n| Syntax        | Description |   Test Text |\r\n| :------------ | :---------: | ----------: |\r\n| Header        |    Title    | Here's this |\r\n| Paragraph     |    Text     |    And more |\r\n| Strikethrough |             |    ~~Text~~ |\n\n## Getting Started\n\nTo begin using the Documentation Template, follow these simple steps:\n\n* Start by cloning the repository to your local machine.\n\nLorem ipsum dolor sit amet consectetur adipisicing elit. Reprehenderit quae iure nulla deserunt dolore quam pariatur minus sapiente accusantium. Optio, necessitatibus sequi. Veritatis, aspernatur? Possimus quis repellat eum vitae eveniet.\n\n## Blockquotes\n\nBlockquotes are useful for emphasizing key points or quoting external sources:\n\n> \"Documentation is a love letter that you write to your future self.\" - Damian Conway\n\nFeel free to use blockquotes to highlight important information or quotes relevant to your documentation.\n\n## Code Examples with switch\n\nHere a custom tab component from shadcn ui is used.\n\n## Conclusion\n\nAdding some random stuff to change the code\n",
    "_searchMeta": {
      "cleanContent": "lorem ipsum dolor sit amet consectetur adipisicing elit numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime molestiae facilis aperiam et error illum vel ullam quis architecto dolore ullam x write the press release update the website contact the media syntax description test text :------------ :---------: ----------: header title here s this paragraph text and more strikethrough text getting started to begin using the documentation template follow these simple steps: start by cloning the repository to your local machine lorem ipsum dolor sit amet consectetur adipisicing elit reprehenderit quae iure nulla deserunt dolore quam pariatur minus sapiente accusantium optio necessitatibus sequi veritatis aspernatur possimus quis repellat eum vitae eveniet blockquotes blockquotes are useful for emphasizing key points or quoting external sources: documentation is a love letter that you write to your future self - damian conway feel free to use blockquotes to highlight important information or quotes relevant to your documentation code examples with switch here a custom tab component from shadcn ui is used conclusion adding some random stuff to change the code",
      "headings": [
        "Getting Started",
        "Blockquotes",
        "Code Examples with switch",
        "Conclusion"
      ],
      "keywords": [
        "Getting Started",
        "Blockquotes",
        "Code Examples with switch",
        "Conclusion"
      ]
    }
  },
  {
    "slug": "/structure/deep/deeper/even-deeper",
    "title": "Introduction",
    "description": "This section provides an overview of Introduction.",
    "content": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime, molestiae, facilis aperiam et, error illum vel ullam? Quis architecto dolore ullam\n\n* \\[x] Write the press release\n* \\[ ] Update the website\n* \\[ ] Contact the media\n\n| Syntax        | Description |   Test Text |\r\n| :------------ | :---------: | ----------: |\r\n| Header        |    Title    | Here's this |\r\n| Paragraph     |    Text     |    And more |\r\n| Strikethrough |             |    ~~Text~~ |\n",
    "_searchMeta": {
      "cleanContent": "lorem ipsum dolor sit amet consectetur adipisicing elit numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime molestiae facilis aperiam et error illum vel ullam quis architecto dolore ullam x write the press release update the website contact the media syntax description test text :------------ :---------: ----------: header title here s this paragraph text and more strikethrough text",
      "headings": [],
      "keywords": []
    }
  },
  {
    "slug": "/structure/deep/deeper",
    "title": "Introduction",
    "description": "This section provides an overview of Introduction.",
    "content": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime, molestiae, facilis aperiam et, error illum vel ullam? Quis architecto dolore ullam\n\n* \\[x] Write the press release\n* \\[ ] Update the website\n* \\[ ] Contact the media\n\n| Syntax        | Description |   Test Text |\r\n| :------------ | :---------: | ----------: |\r\n| Header        |    Title    | Here's this |\r\n| Paragraph     |    Text     |    And more |\r\n| Strikethrough |             |    ~~Text~~ |\n\n## Getting Started\n\nTo begin using the Documentation Template, follow these simple steps:\n\n* Start by cloning the repository to your local machine.\n\nLorem ipsum dolor sit amet consectetur adipisicing elit. Reprehenderit quae iure nulla deserunt dolore quam pariatur minus sapiente accusantium. Optio, necessitatibus sequi. Veritatis, aspernatur? Possimus quis repellat eum vitae eveniet.\n\n## Blockquotes\n\nBlockquotes are useful for emphasizing key points or quoting external sources:\n\n> \"Documentation is a love letter that you write to your future self.\" - Damian Conway\n\nFeel free to use blockquotes to highlight important information or quotes relevant to your documentation.\n\n## Code Examples with switch\n\nHere a custom tab component from shadcn ui is used.\n\n## Conclusion\n\nThank you for choosing the Documentation Template for your project. Whether you're documenting software, APIs, or processes, we're here to support you in creating clear and effective documentation. Happy documenting!\n\n## Tabs Example\n",
    "_searchMeta": {
      "cleanContent": "lorem ipsum dolor sit amet consectetur adipisicing elit numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime molestiae facilis aperiam et error illum vel ullam quis architecto dolore ullam x write the press release update the website contact the media syntax description test text :------------ :---------: ----------: header title here s this paragraph text and more strikethrough text getting started to begin using the documentation template follow these simple steps: start by cloning the repository to your local machine lorem ipsum dolor sit amet consectetur adipisicing elit reprehenderit quae iure nulla deserunt dolore quam pariatur minus sapiente accusantium optio necessitatibus sequi veritatis aspernatur possimus quis repellat eum vitae eveniet blockquotes blockquotes are useful for emphasizing key points or quoting external sources: documentation is a love letter that you write to your future self - damian conway feel free to use blockquotes to highlight important information or quotes relevant to your documentation code examples with switch here a custom tab component from shadcn ui is used conclusion thank you for choosing the documentation template for your project whether you re documenting software apis or processes we re here to support you in creating clear and effective documentation happy documenting tabs example",
      "headings": [
        "Getting Started",
        "Blockquotes",
        "Code Examples with switch",
        "Conclusion",
        "Tabs Example"
      ],
      "keywords": [
        "Getting Started",
        "Blockquotes",
        "Code Examples with switch",
        "Conclusion",
        "Tabs Example"
      ]
    }
  },
  {
    "slug": "/structure/deep",
    "title": "Introduction",
    "description": "This section provides an overview of Introduction.",
    "content": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime, molestiae, facilis aperiam et, error illum vel ullam? Quis architecto dolore ullam\n\n* \\[x] Write the press release\n* \\[ ] Update the website\n* \\[ ] Contact the media\n\n| Syntax        | Description |   Test Text |\r\n| :------------ | :---------: | ----------: |\r\n| Header        |    Title    | Here's this |\r\n| Paragraph     |    Text     |    And more |\r\n| Strikethrough |             |    ~~Text~~ |\n\n## Getting Started\n\nTo begin using the Documentation Template, follow these simple steps:\n\n* Start by cloning the repository to your local machine.\n\nLorem ipsum dolor sit amet consectetur adipisicing elit. Reprehenderit quae iure nulla deserunt dolore quam pariatur minus sapiente accusantium. Optio, necessitatibus sequi. Veritatis, aspernatur? Possimus quis repellat eum vitae eveniet.\n\n## Blockquotes\n\nBlockquotes are useful for emphasizing key points or quoting external sources:\n\n> \"Documentation is a love letter that you write to your future self.\" - Damian Conway\n\nFeel free to use blockquotes to highlight important information or quotes relevant to your documentation.\n\n## Code Examples with switch\n\nHere a custom tab component from shadcn ui is used.\n\n## Conclusion\n\nThank you for choosing the Documentation Template for your project. Whether you're documenting software, APIs, or processes, we're here to support you in creating clear and effective documentation. Happy documenting!\n\n## Tabs Example\n",
    "_searchMeta": {
      "cleanContent": "lorem ipsum dolor sit amet consectetur adipisicing elit numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime molestiae facilis aperiam et error illum vel ullam quis architecto dolore ullam x write the press release update the website contact the media syntax description test text :------------ :---------: ----------: header title here s this paragraph text and more strikethrough text getting started to begin using the documentation template follow these simple steps: start by cloning the repository to your local machine lorem ipsum dolor sit amet consectetur adipisicing elit reprehenderit quae iure nulla deserunt dolore quam pariatur minus sapiente accusantium optio necessitatibus sequi veritatis aspernatur possimus quis repellat eum vitae eveniet blockquotes blockquotes are useful for emphasizing key points or quoting external sources: documentation is a love letter that you write to your future self - damian conway feel free to use blockquotes to highlight important information or quotes relevant to your documentation code examples with switch here a custom tab component from shadcn ui is used conclusion thank you for choosing the documentation template for your project whether you re documenting software apis or processes we re here to support you in creating clear and effective documentation happy documenting tabs example",
      "headings": [
        "Getting Started",
        "Blockquotes",
        "Code Examples with switch",
        "Conclusion",
        "Tabs Example"
      ],
      "keywords": [
        "Getting Started",
        "Blockquotes",
        "Code Examples with switch",
        "Conclusion",
        "Tabs Example"
      ]
    }
  },
  {
    "slug": "/structure",
    "title": "Structure",
    "description": "This section provides an overview of Introduction.",
    "content": "Lorem ipsum dolor sit amet consectetur adipisicing elit. Numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime, molestiae, facilis aperiam et, error illum vel ullam? Quis architecto dolore ullam\n\n* \\[x] Write the press release\n* \\[ ] Update the website\n* \\[ ] Contact the media\n\n| Syntax        | Description |   Test Text |\r\n| :------------ | :---------: | ----------: |\r\n| Header        |    Title    | Here's this |\r\n| Paragraph     |    Text     |    And more |\r\n| Strikethrough |             |    ~~Text~~ |\n\n## Getting Started\n\nTo begin using the Documentation Template, follow these simple steps:\n\n* Start by cloning the repository to your local machine.\n\nLorem ipsum dolor sit amet consectetur adipisicing elit. Reprehenderit quae iure nulla deserunt dolore quam pariatur minus sapiente accusantium. Optio, necessitatibus sequi. Veritatis, aspernatur? Possimus quis repellat eum vitae eveniet.\n\n## Blockquotes\n\nBlockquotes are useful for emphasizing key points or quoting external sources:\n\n> \"Documentation is a love letter that you write to your future self.\" - Damian Conway\n\nFeel free to use blockquotes to highlight important information or quotes relevant to your documentation.\n\n## Code Examples with switch\n\nHere a custom tab component from shadcn ui is used.\n\n## Conclusion\n\nThank you for choosing the Documentation Template for your project. Whether you're documenting software, APIs, or processes, we're here to support you in creating clear and effective documentation. Happy documenting!\n",
    "_searchMeta": {
      "cleanContent": "lorem ipsum dolor sit amet consectetur adipisicing elit numquam iste dolorum tempore consectetur explicabo tempora provident quia maxime molestiae facilis aperiam et error illum vel ullam quis architecto dolore ullam x write the press release update the website contact the media syntax description test text :------------ :---------: ----------: header title here s this paragraph text and more strikethrough text getting started to begin using the documentation template follow these simple steps: start by cloning the repository to your local machine lorem ipsum dolor sit amet consectetur adipisicing elit reprehenderit quae iure nulla deserunt dolore quam pariatur minus sapiente accusantium optio necessitatibus sequi veritatis aspernatur possimus quis repellat eum vitae eveniet blockquotes blockquotes are useful for emphasizing key points or quoting external sources: documentation is a love letter that you write to your future self - damian conway feel free to use blockquotes to highlight important information or quotes relevant to your documentation code examples with switch here a custom tab component from shadcn ui is used conclusion thank you for choosing the documentation template for your project whether you re documenting software apis or processes we re here to support you in creating clear and effective documentation happy documenting",
      "headings": [
        "Getting Started",
        "Blockquotes",
        "Code Examples with switch",
        "Conclusion"
      ],
      "keywords": [
        "Getting Started",
        "Blockquotes",
        "Code Examples with switch",
        "Conclusion"
      ]
    }
  }
]